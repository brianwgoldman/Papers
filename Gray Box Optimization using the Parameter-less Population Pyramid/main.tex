
\documentclass{sig-alternate}
%\linespread{2.5}
\usepackage{url}
\usepackage{verbatim}
\usepackage[noend]{algpseudocode}
\newcommand{\includegraphicsfit}[1]
{\includegraphics[width=.9\columnwidth,height=.4\textheight,keepaspectratio]{#1}}

\newcommand{\includegraphicswide}[1]
{\includegraphics[width=.9\textwidth,height=\textheight,keepaspectratio]{#1}}

\newcommand{\BigO}[1]{$\mathcal{O}{(#1)}$}

\usepackage{bm}

\newfont{\mycrnotice}{ptmr8t at 7pt}
\newfont{\myconfname}{ptmri8t at 7pt}
\let\crnotice\mycrnotice%
\let\confname\myconfname%

\permission{Permission to make digital or hard copies of all or part of this work
for personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear this
notice and the full citation on the first page. Copyrights for components of this
work owned by others than ACM must be honored. Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists,
requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.}
\conferenceinfo{GECCO'15,} {July 11-15, 2015, Madrid, Spain.}
\CopyrightYear{2015}
\crdata{TBA}
\clubpenalty=10000
\widowpenalty = 10000

\begin{document}
\title{Gray-Box Optimization using the Parameter-less Population Pyramid}
%\subtitle{[Genetic Algorithms Track]}

\numberofauthors{2} %
\begin{comment}
\author{
% 1st. author
\alignauthor
Brian W. Goldman\\
       \affaddr{BEACON Center for the Study of Evolution in Action}\\
       \affaddr{Michigan State University, U.S.A.}\\
       \email{brianwgoldman@acm.org}
% 2nd. author
\alignauthor
William F. Punch\\
       \affaddr{BEACON Center for the Study of Evolution in Action}\\
       \affaddr{Michigan State University, U.S.A.}\\
       \email{punch@msu.edu}
}
%\end{comment}
%\begin{comment}
\author{
% 1st. author
\alignauthor
Anonymous\\
       \affaddr{Group}\\
       \affaddr{Group}\\
       \affaddr{Organization}\\
       \email{email@site.com}
% 2nd. author
\alignauthor
Anonymous\\
       \affaddr{Group}\\
       \affaddr{Group}\\
       \affaddr{Organization}\\
       \email{email@site.com}
}
%\end{comment}

\maketitle
\begin{abstract}
%Maximum 200 Words

Unlike black-box optimization problems, gray-box optimization problems have known,
limited-cardinality non-linear relationships between variables. This domain contains many
real world problems with examples in network security, computational biology, VLSI design, and statistical physics.
Leveraging these restrictions, the Hamming-Ball Hill Climber
(HBHC) can efficiently find r-bit local optimal. We show how a
simple memetic algorithm in conjunction with HBHC can find \emph{global}
optima for gray-box problems. We also develop a gray-box version of the Parameter-less
Population Pyramid (P3) utilizing both the HBHC and the known information about variable relationships
which outperforms all of the examined algorithms.


We provide experimental evidence on both NKq-Landscapes and Ising Spin Glasses
that Gray-Box P3 is effective at finding the global optima even for problems with
thousands of variables. This capability is complemented by its efficiency, with
running time and memory usage decreased by up to a linear factor from Black-Box P3.
On NKq this results in a x375 speedup for problems with at least 1,000 variables.
While local search introduces a parameter, we experimentally show this parameter
can likely be fixed to 1 without significant loss in search quality.
\end{abstract}

% A category with the (minimum) three required fields
%\category{Computing Methodologies}{Artificial Intelligence}{Search Methodologies}
\category{I.2.8}{Artificial Intelligence}{Problem Solving, Control Methods, and Search}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{Algorithms, Performance, Experimentation}

\keywords{Local Search; Global Search; Parameter-less}

\newpage

\section{Introduction}

Recent work~\cite{whitley:2013:greedy,chicano:2014:ball} has shown that by
providing local search with more than just an evaluation function can lead
to extraordinary improvements search power and efficiency. These improvements
require information easily derived for a broad range of interesting NP-Hard
problems.

Here we set out to extend these benefits to global optimization by integrating
this local search with additional heuristics~\cite{chen:2011:memetic}.
We introduce a novel algorithm designed to combine local
and global search as simply as possible. To test the true power of this
process we also extend the Parameter-less Population Pyramid~\cite{goldman:2014:p3},
current state-of-the-art in black-box optimization. This ``Gray-Box P3''
utilizes both efficient local search and the additional problem information
to drastically improve performance and reduce memory usage.

\section{Gray-Box Domain}
\label{sec-gray-box}
In black-box optimization, the only information available is a specification
for what constitutes a valid solution and a function which returns the quality
of a given solution. While these very simple requirements allow almost any
optimization task to fit into this domain, it may prevent additional knowledge
about a problem from being provided to search algorithms. At the other end of
the spectrum is white box optimization, in which everything about the problem
is known allowing search techniques to specialize at the cost of generality.
Gray-box optimization exists between these two extremes, exposing additional
information to be exploited by search and which is available for a variety of problems.

Here we shall consider the gray-box optimization domain with the following
characteristics. The function which evaluates the quality of a solution is determined by the summation
of subfunctions. Each subfunction uses at most $k$ variables in the given solution,
such that as the total number of solution variables $N$ increases, $k$ remains constant.
Each subfunction must be independently evaluable, and the variables each uses are known.

While more restrictive than black-box optimization, this domain is still very general.
MAX-SAT, and by extension all NP-hard problems, can be represented
as a summation of subfunctions to evaluate each clause~\cite{whitley:2013:greedy}.
Previous approximation studies of Vertex Cover~\cite{oliveto:2009:vertexcover},
Set Cover~\cite{yu:2010:setcover}, MAX-CUT~\cite{festa:2002:maxcut}, and
Ising Spin Glasses~\cite{pelikan:2003:hboaising} all work with problems which fit
in the gray-box domain. These relate back to problems of real world interest such
as network security, computational biology, VLSI design, and statistical physics.

In order to obtain efficiency bounds for optimization algorithms, the following
assertions are also included. The total number of subfunctions grows no more than
linearly with $N$, which holds true for randomized MAX-SAT, mesh spin glasses, and NK Landscapes.
Furthermore, each variable participates in at most $c$ subfunctions, which holds true
for mesh spin glasses and Nearest Neighbor NK. If violated, these assertions do not
necessarily prevent the gray-box optimization algorithms from solving the problem, but may result
in slower than predicted performance.
We also include the trivial requirements that all problem variables must participate
in at least one subfunction and that the problem is not separable. Any problem which
violates these requirements can be restated either using less variables or as multiple separate problems.

\section{Hamming-Ball Hill Climbing}
\label{sec-hamming}
The first algorithm to rigorously exploit the features of the gray-box domain
described in Section~\ref{sec-gray-box} was \cite{whitley:2013:greedy}. In this study
a hill climber was developed which found the approximate next best improving move in \BigO{1} time.
This is achieved by first determining the fitness effect $delta$ of making each move, and then updating
only effected moves each time a change to the solution is made. Due to the requirements of the domain,
at most \BigO{ck} moves can be effected, with each requiring at most \BigO{1} subfunction calls
to update their $delta$. Combined with move binning, this technique is able to perform both
first improvement and next best hill climbing in \BigO{I+N}, where $I$ is the number of improving
moves required to reach a local optimum. In comparison, the black-box approach for these searches can require
\BigO{IN^2}.

By again leveraging the properties of this domain, the Hamming-Ball Hill Climber (HBHC)~\cite{chicano:2014:ball} extends this
method to find $r$-bit local optima. While na\"ively this would require testing \BigO{N^r} moves, in the gray-box domain only
\BigO{(3ck)^rN} must be checked. This is due to the bounded relationships between variables.
If $i$ and $j$ do not share a subfunction, the effect of flipping both variables
must be equal to the sum of flipping both separately. Therefore only variables which share
a subfunction must be flipped together when checking $r=2$. The problem of determining
which variables must be flipped together is equivalent to finding the connected induced
subgraphs of $G$ with $r$ or fewer vertices, such that each vertex in $G$ is a variable
and an edge exists between two vertices if and only if those variables share a subfunction.
In \cite{chicano:2014:ball} an upper bound is derived for how many moves this could create,
but no algorithm was given to efficiently discover these moves. This process was not included
in their timing calculations as it only has to be performed once per problem.

Under the assertion that $r \ll N$ and that $r$ does not increase with $N$, the Hamming
Ball Hill Climber requires only \BigO{I+N} time to find $r$-bit local optimum starting
from a random solution. As $I$ is likely in \BigO{N} this means finding random $r$-bit local optima
is no more than a constant amount slower than generating random solutions.

While these techniques make it possible to choose the best improving move just as efficiently
as choosing any random improving move, the findings of~\cite{whitley:2013:greedy} suggest that,
especially when paired with subsequent search heuristics, using random improving moves is more effective.
In \cite{chicano:2014:ball} this decision was amended slightly to include the requirement that smaller
distance moves are chosen before larger distance moves.

\subsection{Novel r-order Subgraphs Algorithm}
\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{ConnectedInducedSubgraphs}{}
    \State $closed \leftarrow \emptyset$
    \State $found \leftarrow []$
    \ForAll{$v \in V$}
      \State $closed \leftarrow closed \cup \{v\}$
      \State $found \leftarrow found + $\Call{CISG}{$v$, $\emptyset$, $closed$, $\emptyset$}
    \EndFor
    \State \Return $found$
  \EndProcedure
  \Procedure{CISG}{$v$, $subset$, $closed$, $open$}
    \State $subset' \leftarrow subset \cup \{v\}$
    \State $found \leftarrow [subset']$
    \If{$|subset'| \geq r$}
      \Return $found$
    \EndIf
    \State $closed\_here \leftarrow \emptyset$
    \State $open' \leftarrow open \cup adjacent(v)$
    \ForAll{$v' \in open'$ such that $v' \notin closed$}
        \State $closed\_here \leftarrow closed\_here \cup \{v'\}$
        \State $closed \leftarrow closed \cup \{v'\}$
        \State $recurse \leftarrow $\Call{CISG}{$v'$, $subset'$, $closed$, $open'$}
        \State $found \leftarrow found + recurse$
    \EndFor
    \State $closed \leftarrow closed - closed\_here$
    \State \Return $found$
  \EndProcedure
\end{algorithmic}
  \caption{Algorithm to recursively find all connected induced subgraphs of size $r$ or fewer.}
  \label{fig-connected-subgraphs}
\end{figure}

In order to determine which moves in the hamming-ball must be evaluated,
we developed \Call{ConnectedInducedSubgraphs}{} given in Figure~\ref{fig-connected-subgraphs}.
\Call{CISG}{} is a recursive helper function which finds all subgraphs
which contain a given $subset$ and a given vertex $v$, while excluding
any other vertices added to $closed$. To find all subgraphs, \Call{CISG}{}
is called once for each vertex in the graph, such that $closed$ contains
all previously searched vertices, and $subset=open=\emptyset$. In the initial
call all desired subgraphs which contain $v$ are found, which is why $v$ remains
in $closed$ to prevent duplicate subgraphs from being returned.

At each recursive level \Call{CISG}{} expands $open$ to include any vertices
adjacent to $v$ in the graph. By construction this means that $open$ contains
all possible ways of adding a single vertex to the current $subset'$. As $v'$
are tested they are temporarily added to $closed$ to prevent recursive calls
from creating duplicates.

When applied to the sparse graphs inherent in the gray-box domain, this algorithm
requires \BigO{r!(c(k-1))^rN} time, which reduces to \BigO{N}. The time spent
in each call is dominated by the loop over $open'$. In the worst case, $open'$
increases in size by the full adjacency of $v$, which is bounded by $c(k-1)$.
This creates a worse case complexity for a single top level call of
$\prod_{i}^{r} ic(k-1) = r!(c(k-1))^r$. This must be called once for each
of the $N$ variables resulting in \BigO{r!(c(k-1))^rN}.

\section{Tournament Uniform Crossover: TUX}
\label{sec-tux}
\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{Iterate-TUX}{}
    \State Create random $solution$
    \State Hamming-Ball Hill Climb $solution$
    \ForAll{$T_i \in T$}
      \If{$T_i$ is empty}
        \State $T_i \leftarrow solution$
        \State \Return
      \EndIf
      \State Cross $solution$ with $T_i$ to create $2^{i+1}$ offspring
      \State Hamming-Ball Hill Climb each offspring
      \State $solution \leftarrow$ best of offspring, $solution$, and $T_i$
      \State $T_i \leftarrow$ empty
    \EndFor
    \State Add $solution$ to end of $T$
  \EndProcedure
\end{algorithmic}
  \caption{One iteration of TUX optimization. $T$ is an
           ordered list of solution, each of which could be empty,
           awaiting a crossover partner.}
  \label{fig-TUX}
\end{figure}

Hamming-Ball Hill Climbing is not sufficient to efficiently find the global optimum
on problems with even moderate epistasis~\cite{chicano:2014:ball}. This is because,
like all random restart hill climbers, it relies on random initialization to fall
inside the global optimum's basin of attraction.

To remedy this limitation, we set out to develop a minimally complex memetic
algorithm to help increase this probability. Figure~\ref{fig-TUX} presents
the Tournament Uniform Crossover (TUX) algorithm, which combines simplistic
selection with equal probability uniform crossover to generate starting
solutions likely to be in the global optimum's basin of attraction.

Conceptually TUX iteratively builds a structure similar to a single elimination
bracket for solutions. Each ``match'' in the tournament takes in two candidate solutions,
produces offspring via uniform crossover, applies hill climbing to each offspring, with
the ``winner'' being the best of all those solutions. The tournament ``bracket'' is constructed
iteratively, storing a single list of solutions $T$, such that $|T|$ is equal to the height
of the tournament. This is possible because when a sub-bracket is complete only a single solution
emerges and solutions only need to be stored until their partner is found.
TUX is fully elitist but does not prematurely converge. This is because search continuously
integrates new randomly generated solutions through other parts of the bracket. Whenever the
top of the current bracket is reached, TUX doubles the size of the virtual tournament.

When crossing solutions at $T_i$, TUX produces $2^{i+1}$ offspring. This relationship
ensures that in total all levels of the tournament, including random initialization,
perform the same number of hill climbing steps. It also shifts the focus of search toward
areas expected to be of higher fitness. The expectation is also that it becomes progressively
harder to improve solutions the higher up the tournament you advance, so more attempts
are necessary to create new useful solutions.

The primary advantages of TUX is that it does not introduce any new parameters (still
requires an $r$ for the hill climber) and is relatively simple to implement. Even so
it allows for learning from previous local optima and as Section~\ref{sec-experiments}
will show it is quite effective at optimization.

\section{Parameter-less Population Pyramid: P3}
\subsection{Origins}
\begin{figure}
  \begin{algorithmic}
  \Procedure{Iterate-P3}{}
    \State Create random solution
    \State Apply hill climber
    \If{solution $\notin hashset$}
      \State Add solution to $P_0$
      \State Add solution to $hashset$
    \EndIf

    \ForAll{$P_i \in pyramid$}
      \State Mix solution with $P_i$
      \If{solution's fitness has improved}
        \If{solution $\notin hashset$}
          \State Add solution to $P_{i+1}$
          \State Add solution to $hashset$
        \EndIf
      \EndIf
    \EndFor
  \EndProcedure
\end{algorithmic}
  \caption{One iteration of P3 optimization. $pyramid$ is an
           ordered set of populations and $hashset$ is a set
           of all solutions in $pyramid$.}
  \label{fig-p3}
\end{figure}

The Parameter-less Population Pyramid (P3) is a recently introduced
black-box optimization method which requires no problem specific configuration~\cite{goldman:2014:p3}.
Unlike previous parameter-less methods it was shown to be more efficient than
competing state-of-the-art algorithms across a number of problem classes.

P3 combines hill climbing and model building using a novel, iteratively constructed, pyramid
of populations. Figure~\ref{fig-p3} provides the high level description of how the algorithm
works. To exploit information from multiple solutions, P3 performs global optimal mixing~\cite{thierens:2011:gomea}.
Each time a solution is added to a level of the pyramid $P_i$, linkage learning is performed to
create a collection of variable clusters. These clusters, collectively referred to as a linkage tree,
are learned from the pairwise variable entropy of $P_i$. When a solution is mixed with $P_i$
each cluster is used to donate variable values from a random donor in $P_i$ into the solution.
After each donation the modified solution is evaluated,
with the change being reverted if solution quality decreased. In this way P3 performs
multiple evaluations per mixing event. This also means that unlike TUX, which uses information from only two
solutions to perform crossover, P3 uses information from an entire population.
Due to this model building, P3 requires \BigO{N} amortized time per evaluation and \BigO{N^2}
memory usage.

\subsection{Gray-Box Specialization}
\begin{comment}
\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{SubfunctionTree}{}
    \State $clusters \leftarrow [\{0\}, \{1\}, \{2\}, \dots, \{N-1\}]$
    \State $cluster\_number \leftarrow [0 .. N-1]$
    \ForAll{$subfunction \in shuffled(subfunctions)$}
      \State $to\_merge \leftarrow \emptyset$
      \ForAll{$b \in subfunction$}
        \State $to\_merge \leftarrow to\_merge \cup \{cluster\_number[b]\}$
      \EndFor
      \If{$|to\_merge| > 1$}
        \State $new\_cluster \leftarrow \emptyset$
        \ForAll{$i \in to\_merge$}
          \State $new\_cluster \leftarrow new\_cluster \cup clusters[i]$
        \EndFor
        \ForAll{$b \in new\_cluster$}
          \State $cluster\_number[b] \leftarrow |clusters|$
        \EndFor
        \State $clusters \leftarrow clusters + new\_cluster$
      \EndIf
    \EndFor
    \State Remove first $N~clusters$
    \State Remove any cluster containing all variables
  \EndProcedure
\end{algorithmic}
  \caption{Algorithm used to convert a list of subfunctions into linkage tree clusters.}
  \label{fig-sfx-tree}
\end{figure}
\end{comment}

P3 represents a natural method for integrating the HBHC into
a global optimization algorithm as P3 already utilizes local search. However, there
are also a number of ways in which P3 can be made more efficient by leveraging the
additional information available in the gray-box domain.

First and foremost, linkage learning is no longer necessary. By definition
the direct non-linear relationships between variables are known. As a result
P3 no longer needs to store the pairwise frequency information which leads
the black-box version to require \BigO{N^2} memory. Instead,
we have developed a method for creating a linkage tree which learns clusters
from the same graph defined in Section~\ref{sec-hamming}. The goal is for each
cluster to be a connected induced subgraph, with the size of clusters
mirroring those produced by the agglomerative linkage learning process normally
used with P3. To form a single cluster, a random graph search is performed from
a random starting vertex until a desired number of unique vertices have been explored.
Cluster sizes are set recursively. For each cluster of size $l>1$
a cluster of size $a$ and a cluster of size $l-a$ are also created, with $a$ chosen uniformly
from the range $[1..l-1]$. This recursive process begins by similarly splitting $l=N$.

This linking algorithm has a number of useful properties. First, it creates exactly
$2N-2$ clusters, distributed in size similarly to the black-box clustering algorithm.
Performing a random graph search to find $l$ unique vertices requires \BigO{lck} time,
meaning cluster creation is optimally efficient.
The cluster splitting process has identical properties as random pivot quicksort,
meaning the sum of cluster sizes is \BigO{N\log N} in the average case.
This efficiency allows new clusters to be created before every mixing event,
unlike Black-Box P3 where they are created only when new solutions are added to the population.
For simplicity the clusters are shuffled after the are created, not sorted on size like in
Black-Box P3.

Beyond efficiency, there are good reasons to believe these clusters will be useful
to search. The closer two variables are in the dependency graph, the more likely
they are to appear in the same cluster. All variables on average are expected to appear
in at least one cluster, but variables which are central in the graph will appear in more
clusters than those on the periphery. If all else is equal, the more paths of a given
length between two variables, the higher the probability of them being in the same cluster.
Unlike Black-Box P3, this linkage tree does not require clusters to be nested, allowing
more diversity in the types of clusters appearing in a single tree.

In effect the clusters are sampling moves which the HBHC
would make if $r \ge l$. As clusters are used to move values between solutions, these
moves are restricted to moving in the direction of previously found high quality solutions.
As a result if the density of high quality solutions is higher between good solutions than
outside of good solutions, this method will perform better than random search or sampling from
all possible moves of size $l$.

\begin{comment}
Figure~\ref{fig-sfx-tree} provides an efficient method for creating a linkage
tree similar to that used in Black-Box P3 given subfunction information.
Each variable starts in its own cluster. Each subfunction in a random order
is used to determine how to link existing clusters. If a subfunction overlaps
multiple top level clusters, all overlapped clusters are merged to create a new
top level cluster. This process creates a linkage tree similar to that learned
for P3, with the difference that a node in the tree can have up to $k$ children.

\Call{SubfunctionTree}{} requires \BigO{|cluster|} time to construct each $cluster$
in the linkage tree. In the gray-box domain the total number of subfunctions is required
to be $\Theta(N)$ in order to ensure the problem is not separable. As all variables must
participate in a subfunction, $\Theta(N)$ clusters must be created. Therefore
the only cost which cannot be amortized over the clusters to \BigO{1} is the creation
of each new $cluster$, leading to a time of \BigO{|cluster|} per $cluster$.

This method of constructing clusters has a number of desirable properties beyond its
efficiency. As all non-linear relationships are denoted by subfunctions, mixing
complete subfunctions between individuals has a high likelihood of preserving quality.
Each cluster contains at least one entire subfunction, and two
clusters must differ by at least one entire subfunction. The probability two
variables appear in the same cluster increases with the number of subfunctions
they share. The more paths that exist between two variables in the subfunction
connectivity graph, the more likely those variables will appear in the same cluster.
\end{comment}

Another efficiency gain possible due to the gray-box domain is that each time a
donation is made, only the effected part of the solution's fitness needs to be
recalculated. As a result the number of subfunction evaluations required
to determine the change in fitness is only \BigO{l}. This also
allows for Gray-Box P3 to efficiently reapply hill climbing after each
donation as only effected moves need to be rechecked. As a result a donation,
and its resulting modifications from hill climbing, are kept only if the
new local optima is at least as fit as the solution before the donation occurred.
All combined a single donation plus returning to a local optimum requires \BigO{l + I} time,
while just the donation in Black-Box P3 requires \BigO{N}.

\section{Experimentation}
\label{sec-experiments}
To compare these gray-box optimization techniques we have chosen
NKq-Landscapes~\cite{chicano:2014:ball} and Ising Spin Glasses~\cite{saul:1994:spinglass}. NKq-Landscapes create
a collection of randomly generated problem instances given a
higher level problem class description. Each instance is described
by a series of $N$ subfunctions, each corresponding to a variable
in the solution. This subfunction uses its variable and $K$ other
variables in the solution to calculate a fitness value. Fitness values
are represented as a randomly generated lookup table, such that table
entries are integers in the range $[0..q-1]$. As each subfunction reads
$K+1$ variables, the table's size and $q$ are set to $2^{K+1}$. The quality
of a solution is equal to the sum of the values returned by these subfunctions.

In this work we shall consider two methods for choosing the $K$ variables
each subfunction depends on: Nearest Neighbor NKq and Unrestricted NKq.
In Nearest Neighbor NKq each variable depends on the $K$ variables which immediately follow
it in the solution, with dependencies wrapping around the end of the solution.
Landscapes of this form can be solved in polynomial
time~\cite{wright:2000:solvingnk}, allowing comparisons of how quickly each optimization
algorithm can find the global optima. Nearest Neighbor NKq also ensures that $c=k=K+1$
and that both $c$ and $k$ do not increase as $N$ increases, meaning the efficiency
conclusions made in Section~\ref{sec-hamming} are applicable.

Unrestricted NKq landscapes draw the $K$ dependencies at random. For $K > 1$ it is
NP-Hard to find the global optimum of these landscapes. This also means that while
$k$ remains fixed, the maximum number of subfunctions a variable appears in ($c$) can increase
as $N$ increases. As a result some of the efficiency claims in Section~\ref{sec-hamming}
may not be applicable.

Ising Spin Glasses are a type of MAX-CUT problem relevant in statistical physics. Each spin glass
encodes spins (vertices) and their relationships (edges) with the goal of assigning each spin a direction
which minimizes relationship energy. Just as with NKq-Landscapes, Ising Spin Glasses as a whole
are NP-Hard, but the $2D\pm J$ subset is polynomially solvable~\cite{saul:1994:spinglass}\footnote{\url{http://www.informatik.uni-koeln.de/spinglass/}}. In this
subset the graph is a 2D toroidal grid, with each edge's weight either -1 or 1. In gray-box terms
problems of this subset have $k=2$ and $c=4$ regardless of $N$. While Ising Spin Glasses are traditionally
a minimization problem, here we present them as a maximization problem by negating the normal fitness.

For each problem class tested, we generated 50 instances.
Each method was run once on each instance, and limited to 3 hours of computation and 4 GB of memory.
Runs were performed on 2.5GHz Intel Xeon E5-2670v2 processors using the C++11 code available
from our website.\footnote{\url{https://github.com/name_of_repository/anonymous_name_of_project}}
Each time the run achieved a new best fitness we record current amount of processing time used.
Timing includes the discovery of subgraphs to allow for comparison between different radius values.
When reporting the ``best'' fitness for an instance we mean the best fitness found by any method before
the time limit is reached. On all Nearest Neighbor NKq instances the ``best'' fitness
is also the global optimum, verified using dynamic programming. The same is true of all Ising Spin Glass
problems except for 6 of 50 on N=6,084.

All figures report the median run for either percentage error or seconds to reach the best. A run's percentage error is
equal to how much less its fitness is than the best, divided by the best. When reporting seconds
to reach the best fitness, any run which did not find the best fitness is treated as slower than any run that did.
If the median run was unsuccessful, no data point is drawn.

\subsection{The Effect of Radius}
\label{sec-radius}
\begin{figure*}
  \centering
  \includegraphicswide{fitness}
  \caption{Comparison of how radius effects solution quality at termination. For NKq-Landscapes $N=6,000$ and $K=4$ and
  for Ising Spin Glasses $N=6,084$.}
  \label{fig-fitness}
\end{figure*}

The only algorithm parameter in the HBHC, TUX, and Gray-Box P3
is the radius of the hamming-ball. Therefore our first experiments are designed to determine
the effect of this parameter on solution quality.

Figure~\ref{fig-fitness} shows the effect on final solution fitness as $r$ increases. As expected
from~\cite{chicano:2014:ball} the HBHC obtains higher quality as $r$ increases with the magnitude
of the improvement decreasing. TUX has a similar relationship and
outperforms HBHC on all three problems for all $r$ values. Regardless of $r$, Gray-Box P3 outperforms both, with almost
all $r$ values reaching the same best fitness. For Nearest Neighbor NKq Gray-Box P3 finds the global
optimum in every run for $r < 4$, with only a single unsuccessful run at $r=4$.

\begin{figure}
  \centering
  \includegraphicsfit{p3-seconds}
  \caption{Median time required for Gray-Box P3 to reach the global optimum of Nearest Neighbor NKq instances with $N=6,000$.}
  \label{fig-p3-seconds}
\end{figure}

To further examine the effect of $r$ on Gray-Box-P3 Figure~\ref{fig-p3-seconds} shows the median number of
seconds required to reach the global optimum. Setting $r=1$ was the most efficient configuration for all $K > 1$,
supporting the trend that Gray-Box P3 works best with small $r$ values. With $K=1$, the landscape is smooth enough
that with a sufficiently high $r$ the HBHC is able to find the global optimum.

\subsection{Fitness Over Time}

\begin{figure*}
  \centering
  \includegraphicswide{solver-over}
  \caption{Comparison of solution quality during optimization on a log-log scale for different algorithms. For NKq-Landscapes $N=6,000$ and $K=4$ and
  for Ising Spin Glasses $N=6,084$. Each algorithm uses its best found $r$ value.}
  \label{fig-solver-over}
\end{figure*}

In optimization its sometimes more important how quickly an algorithm reaches high quality solutions than when
it reaches the global optimum. Figure~\ref{fig-solver-over} shows how solution quality progresses during
search for each algorithm. HBHC and TUX have significant early delays caused by their high $r$ values. Larger
$r$'s require a large amount of initial partial evaluation before performing hill climbing. Once that process
is complete HBHC effectively stalls, with TUX improving at a faster rate. Both are eclipsed by Gray-Box P3,
which quickly descends to the global optimum, outperforming HBHC and TUX at every point.

\begin{figure*}
  \centering
  \includegraphicswide{radius-over}
  \caption{Comparison of Gray-Box P3's solution quality during optimization on a log-log scale for different $r$ values.
  For NKq-Landscapes $N=6,000$ and $K=4$ and for Ising Spin Glasses $N=6,084$.}
  \label{fig-radius-over}
\end{figure*}

To further illustrate the effect of $r$ on Gray-Box P3, we provide Figure~\ref{fig-radius-over}. On Nearest Neighbor NKq
and Ising Spin Glasses, increasing $r$ does not change the shape of the curve. Instead the quality reached is simply time shifted,
such that given more time higher $r$ values will reach the same quality. As a result for these problems we conclude
that searching for an optimal value of $r$ is almost certainly going to be more expensive than simply fixing $r=1$.
On Unrestricted NKq this relationship is less certain, with $r=1$ potentially having a different, and worse, shape than $r>1$.
However, due to memory and time restrictions it is difficult to know if this trend continues.

\subsection{Scalability}
\begin{figure}
  \centering
  \includegraphicsfit{length-nn}
  \caption{Comparison of how each algorithm's time required to reach the best fitness found scales with problem size
  on Nearest Neighbor NKq with $K=4$.}
  \label{fig-length-nn}
\end{figure}

\begin{figure}
  \centering
  \includegraphicsfit{length-is}
  \caption{Comparison of how each algorithm's time required to find the best fitness found scales with problem size
  on Ising Spin Glass.}
  \label{fig-length-is}
\end{figure}

Perhaps the most critical test of an optimization algorithm's quality is
how it scales as problem difficulty increases. To test this behavior,
we ran all three algorithms using the best found $r$ values in Section~\ref{sec-radius}
varying $N$ from 200 to 10,000 for NKq and 196 to 6,084 for Ising Spin Glass.
In these plots we also include the black-box version of P3 to show the efficiency
gains available for using gray-box information.

Figure~\ref{fig-length-nn} and Figure~\ref{fig-length-is} show how long each
algorithm required to reach the best found on Nearest Neighbor NKq
and Ising Spin Glass, respectively. For Nearest Neighbor NKq the best found
is the global optimum for all runs of all lengths, while Ising Spin Glass
the best found by any method was worse than the global optimum in 7 runs of
$N=4,096$ and 21 runs of $N=6,084$. The median run of the HBHC was unable to reach the best fitness
for any problems tested using more than 200 bits. TUX performed somewhat better, reaching
the best fitness on problem sizes up to $N=800$ and $N=625$ for Nearest Neighbor NKq and Ising
Spin Glass, respectively. Black-Box P3, which does not utilize partial reevaluation or the HBHC,
was able to consistently reach the best fitness until it it hit the memory limit on $N=2,000$ for
NKq and $N=2,916$ for Ising Spin Glass. This limitation is because unlike the other methods, Black-Box P3
requires \BigO{N^2} memory.

For all sizes of both problems, Gray-Box P3 was the fastest to reach the best fitness. On
Nearest Neighbor NKq the improvement is very significant, with no alternative finishing within
two orders of magnitude. On its largest successful problem size, the mean time to completion for
Black-Box P3 was 375 times slower than Gray-Box P3. This is especially impressive considering
previous work has shown Black-Box P3 is faster to reach the global optimum than other leading black-box
methods. Applying regression, we estimate that Black-Box P3's time to global optimum
on Nearest Neighbor NKq is \BigO{N^{2.75}} while Gray-Box P3's is \BigO{N^{1.98}}.

The results on Ising Spin Glass are similar, with a less extreme difference between
Black-Box P3 and Gray-Box P3. In general Gray-Box is the fastest technique to
find the global optimum by an order of magnitude, with Black-Box P3's mean run finishing
4.6 times slower than Gray-Box on $N=2,025$. The regression line suggests that while
Gray-Box P3 scales at \BigO{N^{3.35}}, Black-Box P3 scales at \BigO{N^{3.05}}.


\begin{figure}
  \centering
  \includegraphicsfit{length-un}
  \caption{Relative qualities of each method as problem size increases on Unrestricted NKq
  with $K=4$.}
  \label{fig-length-un}
\end{figure}

As Unrestricted NKq does not have a known global optimum, and the different algorithms
rarely found the same best fitness, Figure~\ref{fig-length-un} compares the median error
for each technique at termination. Gray-Box P3 in general finds the best fitness,
with TUX occasionally performing better. When $N>2,000$, Gray-Box P3 finds better quality
solutions that all other methods for every single instance.  HBHC and Black-Box P3 only reach similar
qualities as TUX and Gray-Box P3 when $N=200$, doing so in 4 and 7 runs, respectively. As the problem
size increase TUX begins to fall behind Gray-Box P3, with the HBHC stabilizing at about 2.5\% worse than
the best found. Here Black-Box P3 performs worse than the other techniques,
falling further behind as the problem size increases.

\section{Discussion and Conclusions}
In line with previous work, we have found that HBHC cannot effectively find global optima
on problems with even moderate epistasis. In general it also obtains almost no improvement
in fitness after only a few restarts. We designed TUX as a simplistic way of choosing
restart locations based on previously found local optima. Unlike HBHC alone, TUX
was able to continue improving given more time, finding global optima on problems three
times as large.

TUX's effectiveness is likely due to the HBHC acting as a super repair operator for uniform crossover.
Given a sufficiently large $r$ the HBHC can return sections of the crossover offspring to either
parents' original version of a given subfunction. The HBHC is elitist meaning there is a bias toward
returning to the better of the two parent's versions. Furthermore, by being so disruptive,
uniform crossover potentially allows for the HBHC to also find unrelated improvements.

While TUX improves over plain HBHC, Gray-Box P3 is required to perform truly successful
global optimization. Gray-Box P3 replaces na\"{i}ve local search with the HBHC and utilizes
known non-linear relationships instead of statistical linkage learning. On NKq-Landscapes this drastically
improves search effectiveness. A major source of this improvement is likely how difficult it is
for Black-Box P3 to learn linkage relationships on these landscapes. Furthermore, Gray-Box P3
can perform partial reevaluation and efficient hill climbing during the mixing phase.

Gray-Box P3's success is somewhat muted by less extreme improvement on Ising Spin Glass.
While it still outperformed all competitors, Black-Box P3 may actually scale better to larger
problems. One explanation for this deviation is that Ising Spin Glass problems require more
exploration of equal fitness plateaus. For instance in Figure~\ref{fig-solver-over} and Figure~\ref{fig-radius-over}
there is a significant pause in improvement when Gray-Box P3 reaches the second best fitness in the landscape.
Nothing in its design suggests that Gray-Box P3 should be more effective at neutral drift. Another potential
issue is that on these landscapes the importance of each non-linear relationship may be detectably unequal.
As a result the Black-Box linkage learning may be able to better cluster variables which having meaningful
impact on fitness while Gray-Box assumes all are equally important. A useful direction for future work
would be to explore methods of performing efficient learning on top of the known variable interactions.

Somewhat surprising is the difference in behavior between the polynomially solvable problems
and Unrestricted NKq. While Black-Box P3 performed very well in the former, it was the least
successful in the latter. The optimal radius for Gray-Box P3 also shifted from 1 to 2. One
potential explanation is the change in topological bottlenecking. In both Ising Spin Glass
and Nearest Neighbor NKq the number of variables reachable from any one variable in $r$
or less steps is significantly lower than the worst case. This explains why on Unrestricted NKq
even moderately high $r$ values hit our memory limit.
For Black-Box P3 this may also be causing increased difficulty in linkage learning as variables
become indirectly dependent on much larger sets.

While the inclusion of HBHC into Gray-Box P3 introduces a parameter value, it requires
trivial configuration. In the worst case there may be a handful of $r$ values to test.
Furthermore, our evidence suggests setting $r=1$ is quite powerful, with higher values
likely to be only a time shift in quality. This is in contrast to $r$'s role in HBHC,
where low $r$ values are never expected to reach the same quality has higher $r$ values.
Therefore we conclude that Gray-Box P3 maintains the out-of-the-box quality of Black-Box
P3, while drastically improving efficiency for this new domain of problems.

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{../main}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
\balancecolumns
% That's all folks!
\end{document}

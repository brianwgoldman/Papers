
\documentclass{sig-alternate}
%\linespread{2.5}
\usepackage{url}
\usepackage{verbatim}
\usepackage[noend]{algpseudocode}
\newcommand{\includegraphicsfit}[1]
{\includegraphics[width=\columnwidth,height=.4\textheight,keepaspectratio]{#1}}

\newcommand{\includegraphicswide}[1]
{\includegraphics[width=.9\textwidth,height=\textheight,keepaspectratio]{#1}}

\newcommand{\BigO}[1]{$\mathcal{O}{(#1)}$}

\usepackage{bm}

\newfont{\mycrnotice}{ptmr8t at 7pt}
\newfont{\myconfname}{ptmri8t at 7pt}
\let\crnotice\mycrnotice%
\let\confname\myconfname%

\permission{Permission to make digital or hard copies of all or part of this work
for personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear this
notice and the full citation on the first page. Copyrights for components of this
work owned by others than ACM must be honored. Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists,
requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.}
\conferenceinfo{GECCO'15,} {July 11-15, 2015, Madrid, Spain.}
\CopyrightYear{2015}
\crdata{TBA}
\clubpenalty=10000
\widowpenalty = 10000

\begin{document}
\title{Gray Box Optimization using the Parameter-less Population Pyramid}
%\subtitle{[Genetic Algorithms Track]}

\numberofauthors{2} %
\begin{comment}
\author{
% 1st. author
\alignauthor
Brian W. Goldman\\
       \affaddr{BEACON Center for the Study of Evolution in Action}\\
       \affaddr{Michigan State University, U.S.A.}\\
       \email{brianwgoldman@acm.org}
% 2nd. author
\alignauthor
William F. Punch\\
       \affaddr{BEACON Center for the Study of Evolution in Action}\\
       \affaddr{Michigan State University, U.S.A.}\\
       \email{punch@msu.edu}
}
%\end{comment}
%\begin{comment}
\author{
% 1st. author
\alignauthor
Anonymous\\
       \affaddr{Group}\\
       \affaddr{Group}\\
       \affaddr{Organization}\\
       \email{email@site.com}
% 2nd. author
\alignauthor
Anonymous\\
       \affaddr{Group}\\
       \affaddr{Group}\\
       \affaddr{Organization}\\
       \email{email@site.com}
}
%\end{comment}

\maketitle
\begin{abstract}
%Maximum 200 Words

For many challenging problems, the non-linear relationships between variables
are known and bounded. Previous work has developed local search operators
which require a linear factor less time than black box methods. Furthermore,
this Hamming-Ball Hill Climber is capable of efficiently finding $r$-bit local optima.
In this paper we extend this operator to perform efficient global optimization.
We create a simple memetic algorithm to demonstrate how even trivial
extensions can improve search results. We then modify the Parameter-less
Population Pyramid (P3), shown to be highly effective for black box optimization,
to leverage the additional information available in the gray box domain.

We provide experimental evidence on both NKq-Landscapes and Ising Spin Glasses
that Gray Box P3 is effective at finding the global optima even for problems with
thousands of variables. This capability is complemented by its efficiency, with
running time and memory usage decreased by a linear factor from Black Box P3.
On NKq this results in a x374 speedup for problems with at least 1000 variables.
While local search introduces a parameter, we experimentally show this parameter
can likely be fixed to 1 without significant loss in search quality.

\end{abstract}

% A category with the (minimum) three required fields
%\category{Computing Methodologies}{Artificial Intelligence}{Search Methodologies}
\category{I.2.8}{Artificial Intelligence}{Problem Solving, Control Methods, and Search}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{Algorithms, Performance, Experimentation}

\keywords{TODO; Local Search; Parameter-less}

\section{Introduction}

Recent work~\cite{whitley:2013:greedy,chicano:2014:ball} has shown that by
providing local search with more than just an evaluation function can lead
to extraordinary improvements search power and efficiency. These improvements
require information easily derived for a broad range of interesting NP-Hard
problems.

Here we set out to extend these benefits to global optimization by integrating
this local search with additional heuristics~\cite{chen:2011:memetic}.
We introduce a novel algorithm designed to combine local
and global search as simply as possible. To test the true power of this
process we also extend the Parameter-less Population Pyramid~\cite{goldman:2014:p3},
current state-of-the-art in black box optimization. This ``Gray Box P3''
utilizes both efficient local search and the additional problem information
to drastically improve performance and reduce memory usage.

\section{Gray Box Domain}
\label{sec-gray-box}
In black box optimization, the only information available is a specification
for what constitutes a valid solution and a function which returns the quality
of a given solution. While these very simple requirements allow almost any
optimization task to fit into this domain, it may prevent additional knowledge
about a problem from being provided to search algorithms. At the other end of
the spectrum is white box optimization, in which everything about the problem
is known allowing search techniques to specialize at the cost of generality.
Gray box optimization exists between these two extremes, exposing additional
information to be exploited by search and which is available for a variety of problems.

Here we shall consider the gray box optimization domain with the following
characteristics. The function which evaluates the quality of a solution is determined by the summation
of subfunctions. Each subfunction uses at most $k$ variables in the given solution,
such that as the total number of solution variables $N$ increases, $k$ remains constant.
Each subfunction must be independently evaluable, and the variables each uses are known.

While more restrictive than black box optimization, this domain is still very general.
MAX-SAT, and by extension all NP-hard problems, can be represented
as a summation of subfunctions to evaluate each clause~\cite{whitley:2013:greedy}.
Previous approximation studies of Vertex Cover~\cite{oliveto:2009:vertexcover},
Set Cover~\cite{yu:2010:setcover}, MAX-CUT~\cite{festa:2002:maxcut}, and
Ising Spin Glasses~\cite{pelikan:2003:hboaising} all work with problems which fit
in the gray box domain. These relate back to problems of real world interest such
as network security, computational biology, VLSI design, and statistical physics.

In order to obtain efficiency bounds for optimization algorithms, the following
assertions are also included. The total number of subfunctions grows no more than
linearly with $N$, which holds true for randomized MAX-SAT, mesh spin glasses, and NK Landscapes.
Furthermore, each variable participates in at most $c$ subfunctions, which holds true
for mesh spin glasses and Nearest Neighbor NK. If violated, these assertions do not
necessarily prevent the gray box optimization algorithms from solving the problem, but may result
in slower than predicted performance.
We also include the trivial requirements that all problem variables must participate
in at least one subfunction and that the problem is not separable. Any problem which
violates these requirements can be restated either using less variables or as multiple separate problems.

\section{Hamming-Ball Hill Climbing}
\label{sec-hamming}
The first algorithm to rigorously exploit the features of the gray box domain
described in Section~\ref{sec-gray-box} was \cite{whitley:2013:greedy}. In this study
a hill climber was developed which found the approximate next best improving move in \BigO{1} time.
This is achieved by first determining the fitness effect $delta$ of making each move, and then updating
only effected moves each time a change to the solution is made. Due to the requirements of the domain,
at most \BigO{ck} moves can be effected, with each requiring at most \BigO{1} subfunction calls
to update their $delta$. Combined with move binning, this technique is able to perform both
first improvement and next best hill climbing in \BigO{I+N}, where $I$ is the number of improving
moves required to reach a local optimum. In comparison, the black box approach for these searches can require
\BigO{IN^2}.

By again leveraging the properties of this domain, the Hamming-Ball Hill Climber~\cite{chicano:2014:ball} extends this
method to find $r$-bit local optima. While na\"ively this would require testing \BigO{N^r} moves, in the gray box domain only
\BigO{(3ck)^rN} must be checked. This is due to the bounded relationships between variables.
If $i$ and $j$ do not share a subfunction, the effect of flipping both variables
must be equal to the sum of flipping both separately. Therefore only variables which share
a subfunction must be flipped together when checking $r=2$. The problem of determining
which variables must be flipped together is equivalent to finding the connected induced
subgraphs of $G$ with $r$ or fewer vertices, such that each vertex in $G$ is a variable
and an edge exists between two vertices if and only if those variables share a subfunction.
In \cite{chicano:2014:ball} an upper bound is derived for how many moves this could create,
but no algorithm was given to efficiently discover these moves. This process was not included
in their timing calculations as it only has to be performed once per problem.

Under the assertion that $r \ll N$ and that $r$ does not increase with $N$, the Hamming
Ball Hill Climber requires only \BigO{I+N} time to find $r$-bit local optimum starting
from a random solution. As $I$ is likely in \BigO{N} this means finding random $r$-bit local optima
is no more than a constant amount slower than generating random solutions.

While these techniques make it possible to choose the best improving move just as efficiently
as choosing any random improving move, the findings of~\cite{whitley:2013:greedy} suggest that,
especially when paired with subsequent search heuristics, using random improving moves is more effective.
In \cite{chicano:2014:ball} this decision was amended slightly to include the requirement that smaller
distance moves are chosen before larger distance moves.

\subsection{Novel r-order Subgraphs Algorithm}
\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{ConnectedInducedSubgraphs}{}
    \State $closed \leftarrow \emptyset$
    \State $found \leftarrow []$
    \ForAll{$v \in V$}
      \State $closed \leftarrow closed \cup \{v\}$
      \State $found \leftarrow found + $\Call{CISG}{$v$, $\emptyset$, $closed$, $\emptyset$}
    \EndFor
    \State \Return $found$
  \EndProcedure
  \Procedure{CISG}{$v$, $subset$, $closed$, $open$}
    \State $subset' \leftarrow subset \cup \{v\}$
    \State $found \leftarrow [subset']$
    \If{$|subset'| \geq r$}
      \Return $found$
    \EndIf
    \State $closed\_here \leftarrow \emptyset$
    \State $open' \leftarrow open \cup adjacent(v)$
    \ForAll{$v' \in open'$ such that $v' \notin closed$}
        \State $closed\_here \leftarrow closed\_here \cup \{v'\}$
        \State $closed \leftarrow closed \cup \{v'\}$
        \State $recurse \leftarrow $\Call{CISG}{$v'$, $subset'$, $closed$, $open'$}
        \State $found \leftarrow found + recurse$
    \EndFor
    \State $closed \leftarrow closed - closed\_here$
    \State \Return $found$
  \EndProcedure
\end{algorithmic}
  \caption{Algorithm to recursively find all connected induced subgraphs of size $r$ or fewer.}
  \label{fig-connected-subgraphs}
\end{figure}

In order to determine which moves in the hamming-ball must be evaluated,
we developed \Call{ConnectedInducedSubgraphs}{} given in Figure~\ref{fig-connected-subgraphs}.
\Call{CISG}{} is a recursive helper function which finds all subgraphs
which contain a given $subset$ and a given vertex $v$, while excluding
any other vertices added to $closed$. To find all subgraphs, \Call{CISG}{}
is called once for each vertex in the graph, such that $closed$ contains
all previously searched vertices, and $subset=open=\emptyset$. In the initial
call all desired subgraphs which contain $v$ are found, which is why $v$ remains
in $closed$ to prevent duplicate subgraphs from being returned.

At each recursive level \Call{CISG}{} expands $open$ to include any vertices
adjacent to $v$ in the graph. By construction this means that $open$ contains
all possible ways of adding a single vertex to the current $subset'$. As $v'$
are tested they are temporarily added to $closed$ to prevent recursive calls
from creating duplicates.

When applied to the sparse graphs inherent in the gray box domain, this algorithm
requires \BigO{r!(c(k-1))^rN} time, which reduces to \BigO{N}. The time spent
in each call is dominated by the loop over $open'$. In the worst case, $open'$
increases in size by the full adjacency of $v$, which is bounded by $c(k-1)$.
This creates a worse case complexity for a single top level call of
$\prod_{i}^{r} ic(k-1) = r!(c(k-1))^r$. This must be called once for each
of the $N$ variables resulting in \BigO{r!(c(k-1))^rN}.

\section{Tournament Uniform Crossover: TUX}
\label{sec-tux}
\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{Iterate-TUX}{}
    \State Create random $solution$
    \State Hamming-Ball Hill Climb $solution$
    \ForAll{$T_i \in T$}
      \If{$T_i$ is empty}
        \State $T_i \leftarrow solution$
        \State \Return
      \EndIf
      \State Cross $solution$ with $T_i$ to create $2^{i+1}$ offspring
      \State Hamming-Ball Hill Climb each offspring
      \State $solution \leftarrow$ best of offspring, $solution$, and $T_i$
      \State $T_i \leftarrow$ empty
    \EndFor
    \State Add $solution$ to end of $T$
  \EndProcedure
\end{algorithmic}
  \caption{One iteration of TUX optimization. $T$ is an
           ordered list of solution, each of which could be empty,
           awaiting a crossover partner.}
  \label{fig-TUX}
\end{figure}

Hamming-Ball Hill Climbing is not sufficient to efficiently find the global optimum
on problems with even moderate epistasis~\cite{chicano:2014:ball}. This is because,
like all random restart hill climbers, it relies on random initialization to fall
inside the global optimum's basin of attraction.

To remedy this limitation, we set out to develop a minimally complex memetic
algorithm to help increase this probability. Figure~\ref{fig-TUX} presents
the Tournament Uniform Crossover (TUX) algorithm, which combines simplistic
selection with equal probability uniform crossover to generate starting
solutions likely to be in the global optimum's basin of attraction.

Conceptually TUX iteratively builds a structure similar to a single elimination
bracket for solutions. Each ``match'' in the tournament takes in two candidate solutions,
produces offspring via uniform crossover, applies hill climbing to each offspring, with
the ``winner'' being the best of all those solutions. The tournament ``bracket'' is constructed
iteratively, storing a single list of solutions $T$, such that $|T|$ is equal to the height
of the tournament. This is possible because when a sub-bracket is complete only a single solution
emerges and solutions only need to be stored until their partner is found.
TUX is fully elitist but does not prematurely converge. This is because search continuously
integrates new randomly generated solutions through other parts of the bracket. Whenever the
top of the current bracket is reached, TUX doubles the size of the virtual tournament.

When crossing solutions at $T_i$, TUX produces $2^{i+1}$ offspring. This relationship
ensures that in total all levels of the tournament, including random initialization,
perform the same number of hill climbing steps. It also shifts the focus of search toward
areas expected to be of higher fitness. The expectation is also that it becomes progressively
harder to improve solutions the higher up the tournament you advance, so more attempts
are necessary to create new useful solutions.

The primary advantages of TUX is that it does not introduce any new parameters (still
requires an $r$ for the hill climber) and is relatively simple to implement. Even so
it allows for learning from previous local optima and as Section~\ref{sec-experiments}
will show it is quite effective at optimization.

\section{Parameter-less Population Pyramid: P3}
\subsection{Origins}
\begin{figure}
  \begin{algorithmic}
  \Procedure{Iterate-P3}{}
    \State Create random solution
    \State Apply hill climber
    \If{solution $\notin hashset$}
      \State Add solution to $P_0$
      \State Add solution to $hashset$
    \EndIf

    \ForAll{$P_i \in pyramid$}
      \State Mix solution with $P_i$
      \If{solution's fitness has improved}
        \If{solution $\notin hashset$}
          \State Add solution to $P_{i+1}$
          \State Add solution to $hashset$
        \EndIf
      \EndIf
    \EndFor
  \EndProcedure
\end{algorithmic}
  \caption{One iteration of P3 optimization. $pyramid$ is an
           ordered set of populations and $hashset$ is a set
           of all solutions in $pyramid$.}
  \label{fig-p3}
\end{figure}

The Parameter-less Population Pyramid (P3) is a recently introduced
black box optimization method which requires no problem specific configuration~\cite{goldman:2014:p3}.
Unlike previous parameter-less methods it was shown to be more efficient than
competing state-of-the-art algorithms across a number of problem classes.

P3 combines hill climbing and model building using a novel, iteratively constructed, pyramid
of populations. Figure~\ref{fig-p3} provides the high level description of how the algorithm
works. In order to perform solution mixing, P3 learns a linkage tree from pairwise variable
entropy which is then used to perform global optima mixing~\cite{thierens:2011:gomea}. In global
optimal mixing these learned clusters of variables are used to donate genetic information from multiple
sources into a single solution. Each time variables are donated, the modified solution is evaluated,
with the change being reverted if solution quality decreased. In this way P3 performs
multiple evaluations per mixing event, with a single solution receiving genes from randomly chosen
donors in the pyramid level. This also means that unlike TUX, which uses information from only two
solutions to perform crossover, P3 uses information from an entire population.
Due to this model building, P3 requires \BigO{N} amortized time per evaluation and \BigO{N^2}
memory usage.

\subsection{Gray Box Specialization}
\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{SubfunctionTree}{}
    \State $clusters \leftarrow [\{0\}, \{1\}, \{2\}, \dots, \{N-1\}]$
    \State $cluster\_number \leftarrow [0 .. N-1]$
    \ForAll{$subfunction \in shuffled(subfunctions)$}
      \State $to\_merge \leftarrow \emptyset$
      \ForAll{$b \in subfunction$}
        \State $to\_merge \leftarrow to\_merge \cup \{cluster\_number[b]\}$
      \EndFor
      \If{$|to\_merge| > 1$}
        \State $new\_cluster \leftarrow \emptyset$
        \ForAll{$i \in to\_merge$}
          \State $new\_cluster \leftarrow new\_cluster \cup clusters[i]$
        \EndFor
        \ForAll{$b \in new\_cluster$}
          \State $cluster\_number[b] \leftarrow |clusters|$
        \EndFor
        \State $clusters \leftarrow clusters + new\_cluster$
      \EndIf
    \EndFor
    \State Remove first $N~clusters$
    \State Remove any cluster containing all variables
  \EndProcedure
\end{algorithmic}
  \caption{Algorithm used to convert a list of subfunctions into linkage tree clusters.}
  \label{fig-sfx-tree}
\end{figure}

P3 represents a natural method for integrating the Hamming-Ball Hill Climber into
a global optimization algorithm as P3 already utilizes local search. However, there
are also a number of ways in which P3 can be made more efficient by leveraging the
additional information available in the gray box domain.

First and foremost, linkage learning is no longer necessary. By definition
the direct non-linear relationships between variables are known. As a result
P3 no longer needs to store the pairwise frequency information which leads
the black box version to require \BigO{N^2} memory. Instead the subfunction
information itself can be used to construct the linkage clusters.
Figure~\ref{fig-sfx-tree} provides an efficient method for creating a linkage
tree similar to that used in black box P3 given subfunction information.
Each variable starts in its own cluster. Each subfunction in a random order
is used to determine how to link existing clusters. If a subfunction overlaps
multiple top level clusters, all overlapped clusters are merged to create a new
top level cluster. This process creates a linkage tree similar to that learned
for P3, with the difference that a node in the tree can have up to $k$ children.

\Call{SubfunctionTree}{} requires \BigO{|cluster|} time to construct each $cluster$
in the linkage tree. In the gray box domain the total number of subfunctions is required
to be $\Theta(N)$ in order to ensure the problem is not separable. As all variables must
participate in a subfunction, $\Theta(N)$ clusters must be created. Therefore
the only cost which cannot be amortized over the clusters to \BigO{1} is the creation
of each new $cluster$, leading to a time of \BigO{|cluster|} per $cluster$.

This method of constructing clusters has a number of desirable properties beyond its
efficiency. As all non-linear relationships are denoted by subfunctions, mixing
complete subfunctions between individuals has a high likelihood of preserving quality.
Each cluster contains at least one entire subfunction, and two
clusters must differ by at least one entire subfunction. The probability two
variables appear in the same cluster increases with the number of subfunctions
they share. The more paths that exist between two variables in the subfunction
connectivity graph, the more likely those variables will appear in the same cluster.

Due to this change, a few compensatory adjustments to P3's algorithm were required.
First, in black box P3 the number of clusters discovered by linkage learning is
limited by the number of solutions at that level of the pyramid. To duplicate this
behavior, after calling \Call{SubfunctionTree}{} a random subset of the discovered
clusters is chosen, such that the size is limited to the number of solutions
stored at the current level of the pyramid. As the clusters produced do not
rely on the solutions stored in the pyramid, clusters are regenerated before each
mixing event, unlike black box P3 in which they are regenerated only when the stored
solutions change. Finally, unlike previous work, the clusters are applied in random order
to avoid the time required to sort them based on length.

Another efficiency gain possible due to the gray box domain is that each time a
donation is made, only the effected part of the solution's fitness needs to be
recalculated. As a result the number of subfunction evaluations required
to determine the change in fitness is only \BigO{|cluster|}. This also
allows for gray box P3 to efficiently reapply hill climbing after each
donation as only effected moves need to be rechecked. As a result a donation,
and its resulting modifications from hill climbing, are kept only if the
new local optima is at least as fit as the solution before the donation occurred.
All combined a single donation plus returning to a local optimum requires \BigO{|cluster| + I} time,
while just the donation in black box P3 requires \BigO{N}.

\section{Experimentation}
\label{sec-experiments}
To compare these gray box optimization techniques we have chosen
NKq-Landscapes~\cite{chicano:2014:ball}. NKq-Landscapes create
a collection of randomly generated problem instances given a
higher level problem class description. Each instance is described
by a series of $N$ subfunctions, each corresponding to a variable
in the solution. This subfunction uses its variable and $K$ other
variables in the solution to calculate a fitness value. Fitness values
are represented as a randomly generated lookup table, such that table
entries are integers in the range $[0..q-1]$. As each subfunction reads
$K+1$ variables, the table's size and $q$ are set to $2^{K+1}$. The quality
of a solution is equal to the sum of the values returned by these subfunctions.

In this work we shall consider two methods for choosing the $K$ variables
each subfunction depends on: Nearest Neighbor NKq and Unrestricted NKq.
In Nearest Neighbor NKq each variable depends on the $K$ variables which immediately follow
it in the solution, with dependencies wrapping around the end of the solution.
Landscapes of this form can be solved in polynomial
time~\cite{wright:2000:solvingnk}, allowing comparisons of how quickly each optimization
algorithm can find the global optima. Nearest Neighbor NKq also ensures that $c=k=K+1$
and that both $c$ and $k$ do not increase as $N$ increases, meaning the efficiency
conclusions made in Section~\ref{sec-hamming} are applicable.

Unrestricted NKq landscapes draw the $K$ dependencies at random. For $K > 1$ it is
NP-Hard to find the global optimum of these landscapes. This also means that while
$k$ remains fixed, the maximum number of subfunctions a variable appears in ($c$) can increase
as $N$ increases. As a result some of the efficiency claims in Section~\ref{sec-hamming}
may not be applicable.

For each $N$ and $K$ tested, we generated 50 Nearest Neighbor NKq and Unrestricted NKq instances.
Each method was run once on each instance, and limited to 3 hours of computation and 4 GB of memory.
Runs were performed on 2.5GHz Intel Xeon E5-2670v2 processors using the C++11 code provided
from our website.\footnote{\url{https://github.com/name_of_repository/anonymous_name_of_project}}
Each time the run achieved a new best fitness we record current amount of processing time used.
Timing includes the discovery of subgraphs to allow for comparison between different radius values.
When reporting the ``best'' fitness for an instance we mean the best fitness found by any method before
the time limit is reached. On all Nearest Neighbor NKq instances the ``best'' fitness
is also the global optimum, verified using dynamic programming.


\subsection{The Effect of Radius}
The only algorithm parameter in the Hamming-Ball Hill Climber, TUX, and Gray Box P3
is the radius of the hamming-ball.

\begin{figure}
  \centering
  \includegraphicsfit{fitness-nn}
  \caption{Nearest Neighbor NKq}
  \label{fig-fitness-nn}
\end{figure}

\begin{figure}
  \centering
  \includegraphicsfit{fitness-un}
  \caption{Unrestricted NKq}
  \label{fig-fitness-un}
\end{figure}

\begin{figure}
  \centering
  \includegraphicsfit{p3-seconds}
  \caption{Timing}
  \label{fig-p3-seconds}
\end{figure}

TODO Plot for single K value with x=radius, y=fitness, color=solver

TODO Plot for just Pyramid with x=radius, y=seconds to optimum, color=k

TODO Explain k==1

\subsection{Fitness Over Time}
TODO Plot for fixed N, K, and R with x=seconds, y=fitness, color=solver

TODO Explain best Pyramid R versus best TUX R.

\subsection{Scalability}
TODO Plot for seconds to global optimum as N increases, include Black Box P3

\begin{figure}
  \centering
  \includegraphicsfit{length}
  \caption{Length}
  \label{fig-length}
\end{figure}

TODO Consider O(N) statistics

\section{Conclusions and Future Work}
%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{../main}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
\balancecolumns
% That's all folks!
\end{document}

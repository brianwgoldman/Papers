\documentclass[a4paper, 11pt]{article}

\usepackage{fancyhdr}
\usepackage[margin=1in]{geometry}
\usepackage{titlesec}
\usepackage{url}

\titleformat{\section}
{\normalfont\Large\bfseries}{}{0pt}{}
\titleformat{\subsection}
{\normalfont\itshape}{}{0pt}{}

%\linespread{2.5}
\begin{document}
\thispagestyle{empty}

\pagestyle{fancy}
\lhead{Brian W. Goldman}
\rhead{Research Statement}

\begin{center}
{\LARGE \bf RESEARCH STATEMENT}\\
\vspace*{0.1cm}
{\normalsize Brian W. Goldman (brianwgoldman@acm.org)}
\end{center}

\noindent
Machine learning (ML) has made great advances in the last few years, and is gaining wide
acceptance as a way to automate expertise at low cost. Yet most of ML's great successes
have required enormous amounts of training data, and have produced models that
defy human understanding. I believe that overcoming these limitations will lead to the
next big expansion in ML use, enabling applications ranging from fighting poverty and
protecting children from abuse to intrusion detection and mapping the human brain.

%NOTES:
%Small grants to prevent homelessness -> reduce overhead http://science.sciencemag.org/content/353/6300/694
%Social Workers overworked -> automatically filter cases
%Automated Legal Help https://www.engadget.com/2016/06/29/ai-laywer-shoots-down-160000-parking-tickets/
%Policing -> risk assessment http://fivethirtyeight.com/features/prison-reform-risk-assessment/

\section{Previous Work}
The quality of an ML or Artificial Intelligence algorithm is often measured
not by its theoretical rigor but by its empirical effectiveness. This leads
to two problems: its often hard to know why one algorithm is better than
another, and many design decisions are often left up to the user. My previous
work has focused on overcoming these two issues with the goal of making
more powerful algorithms that require less expert involvement to apply.

Cartesian Genetic Programming (CGP) is a method for evolving digital circuits
and other functions that has had continual use for almost two decades. Part of its
success is that unlike other methods it tends to produce terse results. Through
careful analysis, I was able to determine the reason for this desirable outcome
was actually an unintended consequence of a seemingly unrelated design
decision~\cite{goldman:2013:ordering,goldman:2015:cgpanalysis}. From this finding
I was able to tweak that decision to improve performance, maintain
terse solutions, and remove a parameter from user configuration.

The primary focus of my dissertation was the creation of the
Parameter-less Population Pyramid (P3), an optimization algorithm
that requires no problem specific configuration~\cite{goldman:2014:p3,goldman:2015:fastp3,goldman:2016:p3hiff}.
Its design was inspired by my previous analysis of model building optimization algorithms~\cite{goldman:2012:ltga}.
P3 combines model building, local search, and novel population structuring to minimize the amount
of stochastic exploration.
P3 is able to find the global optimum in less time than previous techniques, as well as
maintain a better ``current best'' solution as optimization progresses, across a diverse set of problems.
This quality is on top
of the fact that P3 requires no configuration.
By exploiting additional information on a subset of problems, I was able to further
improve P3's efficiency by two orders of magnitude~\cite{goldman:2015:GBO}.
%Working with a collaborator, we were able to develop a generic method using the same principles
%that solves many common problems in the optimization literature in $O(N)$ time~\cite{whitley:2016:mkl}.

\section{Transitioning Focus}
During my postdoc at Colorado State University, my research interests move from abstract analysis
and design of algorithms to how that pursuit could lead to practical societal benefits.
The project was to investigate new methods for treating Post Traumatic Stress Disorder (PTSD).

PTSD is the result of extreme stress causing the body to develop a new
normal, in which the body's hormones are in a constant state of stress response. The illness is resistant
to treatment as natural homeostatic processes reinforce this state. One way to create a lasting improvement
is to disrupt the complex interaction of hormones and return them to a healthy state. Our collaborators
had developed a model for these interactions, but it was too complex for naive methods to determine what
steady states were possible. In my previous work I developed a tool for analyzing optimization
landscapes~\cite{goldman:2016:hyperplane}. By reformulating their model, my tool was able to complete
the task in seconds.

Recently my interests have centered on deep convolutional neural networks. As a side project I
investigated new ways performing transfer learning, in which an existing highly trained network is
repurposed to a new task with little training data. I am currently in the
process of drafting a publication on my findings. At Google I recently completed the internal course
for ML, and plan to bring a new ML service into production next year.

\section{Future Work}
Any application that requires a large number of expert decisions be made at low
cost can potentially benefit from ML. Unfortunately, our inability to understand
why ML makes the decisions it does can prevent acceptance of its use. This is
especially true when it comes to using ML to help the poorest and most disadvantaged
members of our society.

A recent study in Science~\cite{evans:2016:homelessness} found that
giving a one time payout of about \$1,000 to someone on the brink of homelessness
can keep them out of shelters for two years and save the state \$20,000. Unfortunately the cost
of ensuring only the needy receive benefits creates almost \$10,000 in overhead.
I believe this is a case where ML could help reduce costs and allow more money to go to
those who need it, as long as we can make certain the model is making decisions for the right reasons.
Similarly, I believe ML can help overworked social workers who are
``having to make key decisions based on insufficient
information''\footnote{\url{https://www.theguardian.com/society/2010/oct/06/overworked-social-workers-children-risk}}
about children's safety.
Leveraging my previous experience in understanding how complex systems achieve high performance
will be critical to me in making these applications a reality.

Beyond the need to understand the model, these applications are going to require training
with far smaller datasets than normal; it is expensive to gather data about giving money
to the homeless, and dangerous to experiment on child protective services. This
task is perfect driving new advancements in transfer learning. Breakthroughs
in this area will also benefit other domains that have very limited training samples,
such as intrusion detection from security. Finally, the combination of model understanding
and small training sizes could reach such seemingly unrelated applications as neuroscience
by allowing researchers to build models mapping brain activity from FMRIs (very expensive per sample)
to behavior, and then understanding how that model is making its predictions.
If we can rise to these challenges, I believe ML can greatly expand its reach
and help those who need it most.

%\vspace{0.5cm}
%\newpage

\small

\bibliographystyle{abbrv}
\bibliography{../main}

\end{document}


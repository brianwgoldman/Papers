\documentclass[twoside]{article}
\usepackage{ecj,palatino,epsfig,latexsym,natbib}
\usepackage{url}
\usepackage{verbatim}
\usepackage{subcaption}
\usepackage[noend]{algpseudocode}

\newcommand{\includegraphicswide}[1]
{\includegraphics[width=.9\textwidth,height=\textheight,keepaspectratio]{#1}}

\newcommand{\includegraphicsfit}[1]
{\includegraphics[width=\columnwidth,height=\textheight,keepaspectratio]{#1}}

\usepackage{array}
\newcolumntype{L}{>{\centering\arraybackslash}m{1.9cm}}

%% do not add any other page- or text-size instruction here

\parskip=0.00in

\begin{document}

% 45-character limit on header
\ecjHeader{x}{x}{xxx-xxx}{201X}{Parameter-less Population Pyramid}{B. W. Goldman and W. F. Punch}
\title{\bf Fast and Efficient Black Box Optimization using the Parameter-less Population Pyramid}  

\author{\name{\bf B. W. Goldman} \hfill \addr{brianwgoldman@acm.org}\\ 
        \addr{Department of Computer Science and Engineering, Michigan State University, 
        East Lansing, 48823, United States}
\AND
       \name{\bf W. F. Punch} \hfill \addr{punch@msu.edu}\\
        \addr{Department of Computer Science and Engineering, Michigan State University, 
        East Lansing, 48823, United States}
}

\maketitle

\begin{abstract}
%Should be about 200 words
The Parameter-less Population Pyramid (P3) is a recently introduced method for performing
evolutionary optimization without requiring any user specified parameters.
P3's primary innovation is to replace the generational model with a pyramid of
multiple populations that are iteratively created and expanded. In combination
with local search and advanced crossover P3 scales to problem difficulty, exploiting
previously learned information before adding more diversity.

Across seven problems, each tested using on average 18 problem sizes, P3 outperformed
all five advanced comparison algorithms. This improvement includes requiring less evaluations
to find the global optimum and better fitness when using
the same number of evaluations. Using both algorithm analysis and comparison we find P3's
effectiveness is due to its ability to properly maintain, add, and exploit diversity.

Unlike the best comparison algorithms, P3 was able to achieve this quality without any
problem specific tuning. Thus, unlike previous parameter-less methods, P3 does not
sacrifice quality for applicability. Therefore we conclude that
P3 is an efficient, general, parameter-less approach to black box
optimization which is more effective than existing state-of-the-art techniques.

\end{abstract}

\begin{keywords}

Genetic algorithms, 
linkage learning,
local search,
parameter-less.

\end{keywords}

\section{Introduction}
A primary purpose of evolutionary optimization is to efficiently find good solutions
to challenging real world problems with minimal prior knowledge about the problem itself.
This driving goal has created search algorithms which can escape user bias to create
truly novel results, sometimes publishable or patentable in their own right~\citep{kannappan:2014:humies}.
While it is not possible for any algorithm to do better than random search across all possible
problems~\citep{Wolpert:1997:nfl}, effectiveness can be achieved by assuming the search
landscape has structure and then biasing the algorithm toward exploiting that structure.

In evolutionary optimization, and genetic algorithms~(GAs) in particular, search is often
biased through parameters. This can be beneficial as it allows practitioners to inject their
knowledge about the shape of the search landscape into the algorithm.
However, the quality of solutions found, and the speed at which they are found, is strongly tied to setting these parameters
correctly~\citep{goldberg:1991:gasize}. As such, either expert knowledge or exceedingly
expensive parameter tuning~\citep{grefenstette:1986:optimalga} are required to leverage
this feature to its fullest potential. Furthermore,  parameters such as population size, mutation rate, crossover
rate, tournament size, etc. usually have no clear relationship to the problem being solved, meaning even
domain experts may not understand how the parameters will interact with the problem or with each other.
To further complicate matters, there is mounting evidence that parameter values should change
during search~\citep{goldman:2011:dynamic-parameters,laporte:2014:adaptivepop}.

There have been periodic efforts to reduce or remove the need for parameter tuning.
\cite{rechenberg:1973:es} introduced self-adaptive parameters, in which parameter values
were included in each solution's genome and themselves underwent evolution. This allowed search
to optimize some of its own parameters, resulting in a reduced need for expert tuning.
\cite{harik:1999:parameterlessga} were able to design an entirely parameter-less GA by
leveraging schema theory and parallel populations. Unfortunately these methods were provably less efficient
than directly setting the parameters to optimal values~\citep{pelikan:1999:worstparameter-less}.

One area that has been very effective at reducing the number of algorithm parameters is
model based search. \cite{pelikan:2006:hboa}'s Hierarchical Bayesian Optimization
Algorithm~(hBOA) and \cite{thierens:2010:ltga}'s Linkage Tree Genetic Algorithm~(LTGA)
both require only a single parameter: population size. \cite{posik:2011:parameterless}
leveraged model building to create a fully parameter-less algorithm, but it is restricted to
only order-k, fully decomposable, noiseless problems.

Most recently \cite{goldman:2014:p3} introduced the Parameter-less Population Pyramid~(P3).
This method uses a pyramid structure of populations to combine model based search with local search
to achieve parameter-less optimization. Initial results suggest that unlike
previous parameter-less methods, P3 is actually more efficient than current state-of-the-art
parameterized search algorithms. In this work we shall: extend these results to cover more
comparison algorithms; compare both efficiency in reaching the global optimum and intermediate
fitnesses; analyze algorithm complexity; and provide more in depth analysis of P3 itself.

\section{Comparison Optimizers}
\label{sec-optimizers}

In order to fully understand the effectiveness of P3, we compare it with five advanced algorithms which
have related features to P3. The Random Restart Hill Climber defined by ~\cite{goldman:2014:p3} was chosen as an efficient form of repeated
local search. As P3 combines this hill climber with crossover,
comparing with local search alone shows the advantages of P3's overall approach.
The $1+(\lambda, \lambda)$ algorithm~\citep{doerr:2013:lambdalambda} is the current best theory supported simple genetic algorithm
and its method of crossover is in some sense a macro-mutation just as in P3. hBOA and Parameter-less
hBOA are advanced model building search techniques which are very effective at learning complex
problem structure, designed to achieve similar goals as P3's linkage learning but using very different
methods. Finally LTGA represents the current state-of-the-art in black box search and is the origin
of P3's linkage learning and crossover methods.

Only hBOA and LTGA require any parameters, with each of these only requiring a population
size. This makes knowing the optimal behavior of these algorithms much more tractable. All of the
algorithms are also gene order independent, fitness scale invariant, and unbiased. This means,
for any problem, the order in which problem variables appear in the genome can be changed
without changing the behavior of the search. The fitness can also be manipulated in any fashion
as long as the rank ordering of solutions is unchanged. These algorithms are also unaffected by the meaning
assigned to each bit, such that inverting a predetermined random subset of genes before evaluation
will not impact search efficiency.

Our implementations of all of these algorithms as well as all of the population size information, raw results,
and processing scripts
are available from our website.\footnote{\url{https://github.com/brianwgoldman/FastEfficientP3}}
\subsection{Random Restart Hill Climber}
\label{sec-hill-climber}
Perhaps the simplest black box search heuristic is stochastic local search, or hill climbing.
This optimization technique focuses on improving a single solution until it reaches a local
optimum. Here we use the first improvement hill climber defined by \cite{goldman:2014:p3}
and given in Figure~\ref{fig-hc}. This algorithm works by flipping each bit in a random
order, keeping modifications when fitness is improved, until single bit flips cannot result in
further fitness improvements.

\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{Hill-Climber}{}
    \State $options \leftarrow [0 \dots N-1]$\label{fig-hc-options}
    \State $tried \leftarrow \emptyset$
    \While{$|tried| < |options|$}
      \ForAll{$index \in shuffled(options)$}
        \If{$index \notin tried$}\label{fig-hc-tried}
          \State Flip bit $index$ in solution
          \If{solution's fitness increased}
            \State $tried \leftarrow \emptyset$
          \Else
            \State Revert change
          \EndIf
          \State $tried \leftarrow tried \cup \{index\}$
        \EndIf
      \EndFor
    \EndWhile
  \EndProcedure
\end{algorithmic}
  \caption{Hill climbing algorithm used to improve randomly generated solutions until no single
           bit change results in a fitness improvement.}
  \label{fig-hc}
\end{figure}

The hill climber requires an amortized cost of $O(1)$ operations per evaluation. In order to
terminate, at least one evaluation must be performed for each of the $N$ bits in the solution.
As such any operation that happens only once per search can be amortized over at least $N$
evaluations, covering the initialization of $options$ on Line~\ref{fig-hc-options}.
Line~\ref{fig-hc-tried}, which prevents wasted evaluations, can be called at most twice
per evaluation: once to add $index$ into $tried$ and once to prevent $index$ from being unnecessarily
evaluated again. The only way three or more calls could happen is if
no fitness improvement was made for the entire previous iteration, which contradicts the loop invariant.

Due to its nature, this hill climber cannot escape basins of attraction. Once a solution is reached
such that none of the single bit neighbors are fitness improvements, search stops. Thus
this algorithm requires a restart mechanism to solve multimodal problems. We have
chosen here to na\"{i}vely restart search from a random solution whenever a local optima is found. This
ensures that on all landscapes there is always a non-zero probability of search finding the global optimum.

\subsection{$1+(\lambda, \lambda)$}
\cite{doerr:2013:lambdalambda} presented the first genetic algorithm to provably show
the advantages of performing crossover on One Max. This comparatively simple
algorithm maintains only a single individual and a self-controlled parameter $\lambda$.

Each iteration, the number of bits to flip is chosen from the binomial distribution $b\sim B(N, \frac{\lambda}{N})$,
where $N$ is the number of bits in the genome.
Next, $\lfloor\lambda\rfloor$ offspring are produced by flipping $b$ bits. The
best mutant then produces $\lfloor\lambda\rfloor$ offspring via uniform crossover with the original parent, such that each gene comes from the
mutant with probability $\frac{1}{\lambda}$. In the original algorithm the best
offspring produced by crossover then replaces the original parent if its fitness is no worse.
The $\lambda$ parameter, which is initialized to 1, is decreased if the offspring replaced
its parent and increased otherwise.

The original formulation was designed specifically for unimodal landscapes and as such were
not directly suitable for multimodal problems. \cite{goldman:2014:p3} extended $1+(\lambda, \lambda)$
to include random restarts. As search stagnates, the $\lambda$ parameter increases in value. Eventually
this results in $\lambda \ge N$ causing mutation to always flip all bits of the individual.
As this prevents any future improvement, whenever $\lambda \ge N$ search is restarted from a random solution with $\lambda$
reset to 1.

A few other efficiency modifications were also made. If there is a tie in crossover offspring fitness,
whichever has a larger hamming distance from the parent is retained. This encourages drifting across plateaus.
The ``mod'' control strategy proposed by \cite{doerr:2013:lambdalambda} was not used as it conflicted with
the random restart strategy.
If a crossover individual is identical to either of its parents, it is not evaluated.
If mutation produces an offspring which is better than the best crossover offspring, it is used to compare
against the original parent.


\subsection{Hierarchical Bayesian Optimization Algorithm}

\cite{pelikan:2006:hboa} used statistical principles in combination with a decision tree structure
to create the Hierarchical Bayesian Optimization Algorithm (hBOA). This method creates a model of
epistatic relationships between genes which is then used to stochastically generate new solutions.
Each generation a binary tournament with replacement is used to select $\mu$ solutions from
the population. These solutions are then used to build the model, which in turn is used to generate $\mu$ new
solutions. The new solutions are then integrated into the population using restricted tournament
replacement.

Conceptually, the model built by hBOA is trying to infer rules of the form ``Given that this
subset of genes are set to these values, how frequently is gene $x_i$ set to value v?'' This can
be represented using a directed acyclic decision forest, with each tree in the forest representing one gene
in the solution. In the decision tree $T_i$, which is used to set the value of gene $x_i$,
each internal node represents previous decisions on how to set
some other gene $x_j$, with the children of that node representing how the decision was made. The
leaves of each tree give the probability that $x_i$ should be set to each possible value.

The forest is constructed iteratively, with each tree initially containing a single leaf
and with each leaf storing a pointer for each selected solution. Each iteration the algorithm considers
all possible ways of splitting an existing leaf using another gene $x_j$, such that solutions in the
leaf are moved to the newly created leaves based on their value for $x_j$. The general goal is to
separate the solutions such that all solutions with $x_i = 0$ move to one leaf while solutions with
$x_j = 1$ move to the other.

This goal is formalized using model scoring from Bayesian statistics. In its raw form this
almost always creates near infinitesimal results, calculating fractions which include factorials of $\mu$
and products over $N$. However, through algebraic manipulation discussed in Appendix~\ref{sec-appendix}, we
derived a simplified form shown in Equation~\ref{eq-hboa-final}.
Here $l$ is a leaf in tree $i$, with $l'$ and $l''$ the results of splitting $l$. $m_i(l)$ is the number
of solutions which reach $l$ and $m_i(x_i, l)$ is the number of solutions which reach $l$ with the given value
for $x_i$.
If no proposed split satisfies the inequality, iteration stops.
If multiple splits do, whichever maximizes the right side is chosen.

\begin{equation}
  2^{0.5 log_2\mu} < \frac{(m_i(l) + 1)!}{m_i(0, l)!m_i(1,l)!} \cdot
  \frac{m_i(0, l')!m_i(1,l')!m_i(0, l'')!m_i(1,l'')!}{(m_i(l') + 1)!(m_i(l'') + 1)!}
  \label{eq-hboa-final}
\end{equation}

Initially there are $\Theta(N^2)$ possible ways to split existing leaves, as each of the $N$ single node
trees can be split by any of the other $N-1$ genes. Each iteration a new edge is added to the decision
forest, meaning some of the previously tested splits cannot be used. For instance, if $T_i$, which is used
to decide the value of $x_i$, is split using the value of $x_j$, $T_j$ can no longer be split using $x_i$.
As a split creates two new leaves, $O(N)$ new potential splits must also be tested. Equation~\ref{eq-hboa-final}
parses all solutions which reach a leaf to count gene frequencies, requiring $\mu$ time.
The number of total leaves created depends heavily on the problem and $\mu$.
However, assuming no splits are accepted or that the cost of testing all future splits is less than
the initial $\Theta(N^2)$, constructing the model requires $\Omega(\mu N^2)$ time. Each
model is used to generate $\mu$ solutions, leading to a cost per evaluation of $\Omega(N^2)$.

To generate a solution, the value of each gene $x_i$ is set using its corresponding decision tree $T_i$. Because
the forest is directed acyclic, there must be an ordering of $T_i$ such that before $T_i$ is executed all
$x_j$ it uses to make decisions have already been set. As such, previous decisions made by other trees
are used to follow each $T_i$ until a leaf is reached. The value of $x_i$ is then set based on the
probability that other solutions reached that leaf with each value of $x_i$.

To perform replacement, hBOA uses restricted tournament replacement. After each new solution is generated
and evaluated, a set of $w$ solutions are chosen at random from the population, where $w=\min\{N, \frac{\mu}{20}\}$.
From this set the solution which is most genetically similar to the offspring is chosen. If the offspring
is at least as fit as the chosen solution, it replaces the chosen solution in the population. Otherwise the
offspring is discarded. This method is designed to preserve genetic diversity as only genetically similar
solutions must compete on fitness.

hBOA is designed to work with large population sizes, resulting in a large number of
evaluations per generation. As hBOA utilizes explicit diversity maintenance, standard methods for determining
convergence are not considered very accurate. Therefore the authors suggest that an hBOA run should be
terminated after performing generations equal to $N$.

Like other model based techniques, hBOA has very few parameters. There is no mutation or crossover,
and modeling does not rely on any explicit parameters. Solution selection, generation, and replacement
are all derived from the population size, which must be set by the user.

\subsection{Parameter-less hBOA}
Using the methods first introduced by \cite{harik:1999:parameterlessga} for the Parameter-less GA,
\cite{pelikan:2004:parameterlesshboa} created Parameter-less hBOA which automatically scales its
population size to fit the problem. This is done by maintaining a list of concurrent populations
using exponentially scaled population sizes.

A run of Parameter-less hBOA starts with a single population of size $\mu_0$, conventionally set
to $\mu_0=10$. After two generations are performed, a new population of size $\mu_1 = 2\mu_0$ is created
and performs a generation. Evolution then continues with the $\mu_0$ population performing two generations
for each one performed by $\mu_1$. Each time population $\mu_i$ performs its second generation a new population
$\mu_{i+1}=2\mu_i$ is created, which performs generations half as often as $\mu_i$. In this way an infinite number of
parallel population can be simulated, with each population receiving the same number of total evaluations.

In all other aspects each population is identical to an hBOA population using a fixed $\mu$. No search information
is shared among populations, and each search is independently terminated. As such Parameter-less hBOA cannot
perform better than hBOA using the optimal population size for a given instance, as it must also spend evaluations
on populations of different sizes. This inefficiency is bounded by a log multiple of the total number of
evaluations~\citep{pelikan:1999:worstparameter-less}.

\subsection{Linkage Tree Genetic Algorithm}
\cite{thierens:2010:ltga} introduced the Linkage Tree Genetic Algorithm (LTGA) which automatically
detects and exploits problem epistasis by examining pairwise gene entropy. Due to its enhanced
ability to preserve high fitness gene subsets, LTGA was able to outperform state-of-the-art
GAs across many benchmarks. Since its introduction, many variants of LTGA have been
proposed~\citep{thierens:2011:gomea,goldman:2012:ltga} so for clarity we have chosen the version
presented by \cite{thierens:2013:ltgahiff} as our model.

LTGA's effectiveness comes from its method of performing crossover. Instead of blindly
mixing genes between parents, LTGA attempts to preserve important interrelationships
between genes. Before performing any crossovers in a generation, LTGA first builds
a set of hierarchical gene clusters which are then used to dictate how genes are mixed
during crossover.

\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{Cluster-Creation}{}
    \State $unmerged \leftarrow \{\{0\}, \{1\}, \{2\}, \dots, \{N-1\}\}$
    \State $useful \leftarrow unmerged$
    \While{$|unmerged|>1$}
      \State $C_i, C_j \leftarrow \min_{C_i,C_j \in unmerged} D(C_i, C_j)$
      \State $unmerged \leftarrow unmerged - \{C_i, C_j\} + \{C_i \cup C_j\}$
      \State $useful \leftarrow useful + \{C_i \cup C_j\}$
      \If{$D(C_i, C_j) = 0$}
        \State $useful \leftarrow useful - \{C_i, C_j\}$
      \EndIf
    \EndWhile
    \State Order $useful$ based based on last merged first\label{fig-cluster-creation-ordering}
    \State Remove largest cluster from $useful$

    \Return $useful$
  \EndProcedure
\end{algorithmic}
  \caption{Algorithm describing how LTGA creates clusters using Equation~\ref{eq-distance}
           for a population. $unmerged$ and $useful$ are ordered sets of sets of gene loci.}
  \label{fig-cluster-creation}
\end{figure}

Figure~\ref{fig-cluster-creation} provides the agglomerative method LTGA uses to create gene clusters.
This algorithm creates a tree of sets using pairwise gene entropy, such that the leaves of the tree contain a single gene and
internal nodes are the union of their children's sets. These sets are then used by crossover to specify epistatic
relationships which should be preserved.
The process begins by creating the set of sets $unmerged$ which tracks all top level clusters. Initially
$unmerged$ contains single member sets for each gene. After each iteration the two sets with the minimum average pairwise
distance (given in Equation~\ref{eq-distance}) are merged to create a single cluster. This process is repeated
until only a single set remains in $unmerged$ which contains all of the genes in the genome.

\begin{equation}
  D(C_i,C_j) = \frac{1}{\left | C_i \right |\cdot \left |C_j \right|}\sum_{c_i \in C_i}\sum_{c_j \in C_j}
  2 - \frac{H(c_i) + H(c_j)}{H(c_i \cup c_j)}
  \label{eq-distance}
\end{equation}
\begin{equation}
  H(c) = -\sum_{s\in S} p_c(s)\log(p_c(s))
  \label{eq-entropy}
\end{equation}

Throughout this process $useful$ tracks the set of all gene clusters which should be preserved for use by crossover.
This set begins with all genes in separate clusters, and each time a new cluster is created it is added to $useful$.
However, not all clusters are necessarily worth keeping. For instance, in all versions of LTGA the cluster
containing all genes is removed from $useful$ as preserving all genes during crossover can only create clones.
\cite{thierens:2013:ltgahiff} extended this removal to include any unsupported subsets. If the pairwise distance
between two clusters is 0, this means there are no individuals in the population which disrupt the relationships between the two
clusters. Therefore when performing crossover there is no reason to believe a fitness improvement can be achieved
by breaking the stored pattern. As such a cluster is only kept if its direct superset has a non-zero distance.
As a final step Line~\ref{fig-cluster-creation-ordering} reorders $useful$ such that clusters appear in reversed
order from which they were added to $useful$. Thus the most linked clusters and those containing single genes
appear at the end of the returned list.

\cite{thierens:2013:ltgahiff}'s version of LTGA does not use the entire population when determining pairwise entropy.
Instead, binary tournament is used to select half of the population. This is done to ensure the model is built
using only high quality solutions, even during the first generation.

In order to efficiently perform clustering, a pairwise gene frequency table is constructed from the selected solutions.
To calculate Equation~\ref{eq-distance}, Equation~\ref{eq-entropy} is called for each
gene ($H(c_i)$) and pair of genes ($H(c_i \cup c_j)$). Extracting this information requires $O(\mu N^2)$
time, where $\mu$ is the population size and $N$ is the genome size. The process of converting
this pairwise frequency information into clusters can be achieved in $O(N^2)$ using the bookkeeping
methods presented by \cite{gronau:2007:upgma}. This cost is performed only once per generation,
and is then used to perform approximately $O(\mu N)$ crossover evaluations. As a result, the amortized cost of
LTGA's model building is $O(N)$.

\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{Cluster-Usage}{}
    \ForAll{$C_i \in useful$}
      %\ForAll{$d \in shuffled(P_i)$}
        \State $d \leftarrow rand\_choice(P)$\label{fig-cluster-usage-donate}
        \State Copy $d$'s gene values for $C_i$ into solution
        \If{solution was changed}
          \If{solution's fitness decreased}
            \State Revert changes
          \EndIf
          %\State \textbf{break}
        \EndIf
      %\EndFor
    \EndFor
  \EndProcedure
\end{algorithmic}
  \caption{Algorithm describing how clusters are used to perform crossover.}
  \label{fig-cluster-usage}
\end{figure}

Figure~\ref{fig-cluster-usage} describes how the identified clusters are used by crossover to preserve
gene linkage while still exploring the search space. Unlike more traditional crossover methods, LTGA
crosses each individual with the entire population. Also, to produce a single offspring, multiple evaluations
of the fitness function are performed.

Each generation, each individual in the population undergoes crossover. In a single crossover event, each
cluster of genes $C_i$ in $useful$ is applied as a crossover mask. A random donor $d$
is chosen from the entire population (not just the model selected population), and $d$'s gene's for $C_i$ are copied
into the working solution. If a modification is made, an evaluation is then performed. If the crossover
resulted in no worse fitness then the changes are kept. This allows for neutral drift across plateaus.
The resulting solution, which must be at least as fit as its parent, is then
copied into the next generation.


In total each individual can cause up to $|useful|$ evaluations. If all clusters were kept, even those deemed
unhelpful, and all donations were evaluated, even those which did not change any genes, then \Call{Cluster-Usage}{}
would perform exactly $2N-2$ evaluations for each of the $\mu$ solutions in the population. This provides the amortizing evaluations
required to make clustering only $O(N)$ operations per evaluation. However, by skipping some evaluations, its
possible that clustering may be super-linear.

LTGA has no explicit form of diversity control and has no method for introducing new genetic information once
the population has converged. Therefore an LTGA run is considered converged once two consecutive populations
contain the same unique solutions.

By design, LTGA only has a single parameter: population size. LTGA uses no mutation, and crossover is defined
in terms of the clustering algorithm. Selection between generations is fully elitist and embedded in the crossover,
with selection of model building solutions fixed to a binary tournament. Neither \Call{Cluster-Creation}{} nor
\Call{Cluster-Usage}{} rely on parameter values. LTGA does not provide any method for controlling or setting
the population size, relying instead on a fixed user specified size.

\section{Parameter-less Population Pyramid}
\label{sec-p3}
\cite{goldman:2014:p3} introduced the Parameter-less Population Pyramid (P3) as a method for
performing optimization which does not require the user to provide any parameters. This is
achieved by combining efficient local search with the model building methods of LTGA using
an iteratively constructed hierarchy of populations.

The high level algorithm of P3 is presented in Figure~\ref{fig-p3}. Unlike more traditional
GAs, P3 does not follow a generational model. Instead, it maintains an iteratively
expanding pyramid of expanding populations. Each iteration, a new random solution is generated.
This solution is brought to a local optimum using the hill climbing algorithm in Figure~\ref{fig-hc}. If that
local optimum has not yet been added to any level of the pyramid, the solution is added to the lowest
population $P_0$.

Next, the solution is iteratively improved by applying LTGA's crossover algorithm (Figure~\ref{fig-cluster-usage})
with each population $P_i$ in the pyramid. If this process results in a strict fitness improvement and has
created a solution not yet stored in the pyramid, it is added to the next highest pyramid level $P_{i+1}$.
If $P_{i+1}$ does not yet exist, it is created. In this way populations in the pyramid expand over time,
and the number of populations stored increases over time. Initially the pyramid contains no solutions
or populations, meaning the user does not need to specify a population size.


\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{Iterate-P3}{}
    \State Create random solution
    \State Apply hill climber
    \If{solution $\notin hashset$}
      \State Add solution to $P_0$ and rebuild $P_0$'s model
      \State Add solution to $hashset$
    \EndIf

    \ForAll{$P_i \in pyramid$}
      \State Mix solution with $P_i$
      \If{solution's fitness has improved}
        \If{solution $\notin hashset$}
          \State Add solution to $P_{i+1}$ and rebuild $P_{i+1}$'s model
          \State Add solution to $hashset$
        \EndIf
      \EndIf
    \EndFor
  \EndProcedure
\end{algorithmic}
  \caption{One iteration of P3 optimization. $pyramid$ is an
           ordered set of populations and $hashset$ is a set
           of all solutions in $pyramid$.}
  \label{fig-p3}
\end{figure}

To accommodate P3's unique population structure, some of LTGA's clustering procedures were modified. In LTGA,
clusters are identified at the start of each generation and are used
to create all offspring in that generation. As P3 does not perform serial
generations, P3 instead rebuilds the model each
time a solution is added to a population. Furthermore, unlike
our chosen variant of LTGA, all solutions in the population are used to generate the model, not just the
winners of a binary tournament. We can do this because even the
worst solutions in the pyramid are already high quality due to local search.
Using local search in LTGA was examined by \cite{bosman:2011:lsbbo} and found
to provide no significant improvement. A likely cause was that that study applied
local search to every solution, not just the initial population, resulting in significant overhead.

Beyond the changes in population structuring, P3 modifies
LTGA's version of \Call{Cluster-Creation}{} and \Call{Cluster-Usage}{}.
P3 changes Line~\ref{fig-cluster-creation-ordering} in Figure~\ref{fig-cluster-creation}
from \emph{last merged first} ordering to \emph{smallest first} ordering.
This method applies gene clusters during crossover based on how many genes
are in each cluster,\footnote{Ties are broken randomly.} and not on how tightly linked those genes are.
\cite{goldman:2012:ltga} found that this alternative was better at preserving
diversity, and therefore required smaller populations.

P3 also modified Line~\ref{fig-cluster-usage-donate} in Figure~\ref{fig-cluster-usage}.
Instead of choosing a single genetic donor for each cluster, P3 iterates over the
population in a random order until a solution in the population is found which
has a least one gene different for that cluster of genes from the improving solution.
This process increases the likelihood of an evaluation being performed for every cluster,
and helps test rare gene patterns in the population.

In LTGA the cost of rebuilding the model is $O(\mu N^2)$ as it must collect pairwise
gene frequency information for all $\mu$ solutions in the population. P3 does not store
a single population, and it does not have a fixed $\mu$ size for any population. However,
each time a solution is added to the population, it requires $O(N^2)$ time to update
the table of pairwise frequencies and another $O(N^2)$ time to rebuild the linkage model.
The model is then used immediately to perform up to one evaluation for each of the up
to $2N-2$ clusters. Just as in LTGA, if no evaluation shortcuts were made, P3
has an amortized cost of $O(N)$ modeling cost per evaluation. While P3 does
rebuild the model more frequently per solution in the population, it also performs
a number of local search evaluations which are quite efficient, meaning theoretical
comparisons of their speed are difficult to perform. As a final note, P3's repeated
attempts to find a useful donation make it less likely than LTGA to skip evaluations,
but has an added cost to find these donations. Repeated donations could require as much
as $O(\mu)$ attempts per evaluation, but experimental evidence suggest that this
operation actually saves more overhead than it costs by increasing the number of evaluations
per model rebuild.

Each of the pieces of the P3 algorithm were selected not just for their stand alone efficacy,
but for the ways in which they interact. By using the hill climber to optimize randomly
generated solutions, the underlying pairwise relationships in the problem are exposed. As
a result, detecting clusters for use by crossover is much more effective. The crossover operator
is extremely elitist, as each gene donation must result in no fitness loss, and a solution must
strictly improve to be added to the next level of the pyramid. This is balanced by continual
integration of new random solutions. Furthermore, each random restart decreases the probability
of spurious linkages caused by shared ancestry. This diversity is further preserved by applying
gene clusters in smallest first order during crossover as this reduces the probability of genetic
hitchhikers.

Other algorithms have proposed using multiple concurrent populations.
\cite{hornby:2006:alps} had a hierarchy of populations with solutions periodically advancing
upward. This allows for continuous integration of diversity as the lowest population is reseeded
with random solutions. However, this method resulted in increased parameterization as not only was
a population size required, but also new parameters for how frequently generations advanced between levels and
how many total levels to have. \cite{harik:1999:parameterlessga} used multiple independent
populations of different sizes as a method for removing the population size parameter, but
doing was provably less efficient than using an optimal population size as no information is shared
between the populations.

\section{Problem Descriptions}
\label{sec-problems}

\subsection{Single Instance Problems}
Understanding how a stochastic search algorithm will behave on arbitrary and complex
search landscapes can be exceedingly difficult. Therefore a common practice for
algorithm understanding is to perform search on well defined, well understood
landscapes. To be of interest these landscapes need to represent interesting
and important aspects of real world problems.

Perhaps the most common such landscape is the Deceptive Trap problem \citep{goldberg:1991:gasize}.
In this landscape the genome is broken up into $k$ bit non-overlapping subproblems referred
to as traps.
Each subproblem is scored using Equation~\ref{eq-deceptive-trap}, where $t$ is the number of
bits in the trap set to 1. The global optimum in each trap is a string of all 1s, while all
other solutions lead to a local optima of all 0s. This problem tests an algorithm's
ability to overcome $k$ sized deception and is commonly used to determine how effective crossover
is at preserving building blocks. Any crossover event that mixes bits from different parents in
the same trap will likely result in that trap being optimized to the local optima. For our experiments
we chose $k=7$ to ensure highly deceptive traps.

\begin{equation}
   trap(t) = \left\{
     \begin{array}{rl}
       k-1-t, &  t<k\\
       k,   &  t = k
     \end{array}
   \right.
  \label{eq-deceptive-trap}
\end{equation}

\cite{goldman:2012:ltga} found that mixing local search with linkage learning rendered the Deceptive
Trap problem trivial. This is because local search is able to optimize each trap to one of the two
optima (all 1s or all 0s), and then linkage learning can have perfect knowledge of gene interactions.
In order to make the problem more difficult, the authors proposed the Deceptive
Step Trap problem, given in Equation~\ref{eq-deceptive-step-trap}. This function modifies the results
of Equation~\ref{eq-deceptive-trap} to include plateaus of size $s$, introducing an exponential number
of local optima in each trap.
With $k=7$ and $s=2$, as used in our experiments, all traps with 0, 1, 3, 5, and 7 bits set are local optima.
This means that half of all ways to set the trap are 1 bit local optima.
More generally, the number of local optima grows at $\Theta(2^{k-1})$.
As a result, the Deceptive Step Trap is much more challenging for linkage
learning techniques, while still being highly deceptive.
\begin{equation}
   step\_trap(t) = \left \lfloor \frac{(k-s)\pmod{s} + trap(t)}{s} \right \rfloor
  \label{eq-deceptive-step-trap}
\end{equation}

Another challenging aspect of landscapes can be higher order relationships. The Hierarchical If
and only If (HIFF) problem~\citep{watson:1998:hiff} is designed to capture the difficulties of this class of problem.
In HIFF the genome is broken up into a complete binary tree, such that each gene appears in exactly one
leaf and each internal node is the subset of genes contained in its children. If all genes represented
in a node of the tree are set to the same value, they score equal to the size of the set. In this way
small subsets lead toward solutions to larger subsets. However, a node can score if all genes are either
all 1s or all 0s, meaning that to solve higher order subproblems it is necessary to perform crossovers
that preserve lower order solutions. This problem is a natural fit for LTGA as the linkage tree can
perfectly duplicate the problem's true relationships \citep{thierens:2013:ltgahiff}.

As a final class of well known problems, we have chosen to borrow the Rastrigin problem from real valued
optimization. This problem's landscape, determined by Equation~\ref{eq-rast}, is highly multimodal caused by
the oscillating cosine function. \cite{goldman:2014:p3} proposed the Discretized Rastrigin problem, such
that each floating point $x_i$ in Equation~\ref{eq-rast} is encoded using a 10 bit gray code.
\begin{equation}
  10n + \sum_{i=1}^{n}\left [ x_i^2-10\cos (2\pi x_i) \right ] \forall x\in [-5.12,5.12]
  \label{eq-rast}
\end{equation}

\subsection{Randomly Generated Problem Classes}
While well defined landscapes can provide specific insights into how an algorithm works,
their static nature can be misleading. Specifically, algorithm quality might
be very fragile such that it is only effective at searching well behaved landscapes. A more realistic
test of an algorithm's black box effectiveness is to work with randomly generated instances
drawn from a problem class. When tested over a sufficiently large sample it is then possible
to draw more general conclusions about the algorithms effectiveness. The challenge with these
landscapes is determining the global optimum to gauge if an algorithm was successful.

Perhaps the most common model for generating random rugged landscapes is the NK model. An
NK Landscape determines the fitness of each gene based on epistatic relationships with $K$
other genes in the genome. This fitness is specified using a randomly generated table of
fitness values, were each possible combination of the $K+1$ genes is mapped to some floating
point value $[0-1]$. In unrestricted NK landscapes the relationships between genes are also
randomly chosen and as a result finding the global optimum is $NP$-Hard for $K>1$. However,
if epistasis is set such that each gene depends on the $K$ directly following it
in the genome, the solution can be found in polynomial time~\citep{wright:2000:solvingnk}.
These Nearest Neighbor NK landscapes are therefore ideal for search algorithm testing.
For all of our experiments we fixed $K=5$ to ensure highly rugged landscapes.

\cite{saul:1994:spinglass} presents a combinatorial benchmark problem derived from physics:
Ising Spin Glasses. A spin glass is defined by a weighted graph of interaction terms between vertices.
Each gene assigns a value to each vertex, with the fitness calculated by Equation~\ref{eq-ising}.
In this equation, $E$ is the set of all edges, $e_{ij}$ is the edge weight connecting vertex $i$ to vertex $j$, and
$x_i$ and $x_j$ are the gene values for vertex $i$ and $j$. Optimal fitness is when this sum is minimized.
\begin{equation}
\sum_{e_{ij} \in E} x_ie_{ij}x_j
  \label{eq-ising}
\end{equation}
Similar to NK Landscapes, the general class is $NP$-Hard to optimize, but the $2D\pm J$ subset of
Ising Spin Glasses can be polynomially solved.\footnote{\url{http://www.informatik.uni-koeln.de/spinglass/}}
In this subset the graph is restricted to be a two dimensional torus, edge weights are randomly set
to either -1 or 1, and vertex values must be -1 or 1.

As our final class of randomly generated problems we chose the Maximum Satisfiability (MAX-SAT) problem.
Related to the more common 3-SAT problem, a MAX-SAT instance is defined by a set of three term clauses.
Each term is a randomly chosen variable, which may also be negated. A clause scores if an and only if
at least one term in the clause evaluates to true. In order to make MAX-SAT instances with a known global
optimum, \cite{goldman:2014:p3} proposed constructing clauses around a fixed solution. In this way the
signs of the terms are set to ensure the target solution satisfies the clause. To ensure each
problem is challenging we chose a clause to variable ratio of $4.27$~\citep{selman:1996:maxsat}.

\section{Comparison Algorithm Parameter Tuning}
\label{sec-tuning}
While four of the six algorithms in our experiments do not require any user specified parameters,
hBOA and LTGA both use a population size parameter. To ensure these techniques are not unfairly
handicapped, we extensively tuned each using the bisection method \citep{sastry:2001:bisection}
to determine the optimal population size for each problem size.
Extended by \cite{goldman:2012:ltga}, this method iteratively
doubles the population size until some success criteria is met and then performs bisection
between the lowest successful and highest unsuccessful sizes. In this way the minimum population size
which meets the success criteria is found. \cite{goldman:2014:p3} proposed a success criteria
of performing $r$ successful runs in a row, such that the expected failure rate can be bounded
above by $\frac{3}{r+1}$~\citep{jovanovic:1997:ruleofthree}. As P3 and the other three algorithms
do not prematurely converge, we chose $r=100$ to similarly ensure hBOA and LTGA almost never do.
As bisection can make infinitely large population sizes, any run which had not found the global
optimum after 100 million evaluations or 128 computing hours was considered unsuccessful.

\begin{figure}[t]
  \begin{centering}
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{pop-hboa}
      \end{centering}
      \caption{Tuned Population Sizes for hBOA}
      \label{fig-pop-hboa}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{pop-ltga}
      \end{centering}
      \caption{Tuned Population Sizes for LTGA}
      \label{fig-pop-ltga}
    \end{subfigure}
  \end{centering}
  \caption{Optimal population sizes found using bisection on each size
           for each problem.}
  \label{fig-pop-sizes}
\end{figure}

Figure~\ref{fig-pop-sizes} shows the results from performing bisection. In general hBOA
required population sizes which were at least an order of magnitude larger than LTGA. Due to
runtime and memory overhead, finding the optimal value for hBOA was much less tractable than LTGA
for moderate to large problem sizes. LTGA's population size also grew significantly slower
than hBOA's as problem size increased, especially on the two Trap problems and Rastrigin.
Both algorithms were very ineffective on MAX-SAT, neither able to tune to problems sizes over 60 bits.
This is likely due to the fact that some randomly generated MAX-SAT landscapes are very flat
and highly deceptive~\citep{rana:1998:gamaxsat}.

While not currently treated as a parameter, we also performed preliminary tests of
integrating hill climbing into LTGA and hBOA. To match P3, we applied first improvement
hill climbing to each algorithm's initial population.
We then performed bisection on the modified algorithms for the largest problem sizes
where hBOA without hill climbing was effective. We found that in general both methods
performed worse when combined with hill climbing, in some cases up to an order of
magnitude worse. There were three exceptions: both improved on MAX-SAT and
hBOA improved on Rastrigin. In all cases the inclusion of hill climbing did
not result in either algorithm outperforming P3 in terms of evaluations
required to reach the global optimum. As such, all further experiments
use the unmodified published versions.

\section{Finding the Global Optimum}
\label{sec-optimum}

\begin{figure}
  \begin{center}
  \includegraphicsfit{evals-to-success}
  \end{center}
  \caption{Comparison of the median number of evaluations to reach the global optimum for
           the six different optimization methods with respect
           to problem size.  If the median run did not reach the global optimum no data element
           is shown.  Results given on a log-log scale.}
  \label{fig-evals-to-success}
\end{figure}

Figure~\ref{fig-evals-to-success} shows the median number of evaluations required by each of the six
algorithms to find the global optimum for multiple sizes of each problem. Each data point in
Figure~\ref{fig-evals-to-success} represents the median of 100 runs, where unsuccessful runs
are treated as requiring more evaluations than any successful run. If the median run was not successful
no point is shown.
Medians are used as the data is not normally distributed, and because it allows for more meaningful comparison
between techniques with different success rates.
The maximum problem size used for each problem was set to be the largest size we could
feasibly determine LTGA's optimal population size. For many larger problems results are not shown
for hBOA due to the extreme computational cost required to optimally set the population size.

\subsection{Quantitative Comparison}
Of the 130 tested configurations, P3 found the global optimum using the least median evaluations on 114.
The largest problem size for any problem where P3 was not the most efficient has 49 bits, with P3 achieving the best results on all 92 larger
configurations. hBOA, LTGA, and Parameter-less hBOA only outperform P3 on the smallest 5, 4, and 1 Deceptive
Step Trap instances, respectively. Random Restart Hill Climbing outperforms P3 on the smallest 3 Nearest Neighbor NK instances
and the smallest Ising Spin Glass. $1+(\lambda, \lambda)$ has the most success outperforming P3, doing so
on the smallest 5 Deceptive Traps, 3 smallest Deceptive Step Traps, and 2 smallest Rastrigin.
The likelihood that P3 would achieve these pairwise results assuming its median result is actually worse is $p < 10^{-15}$
according to the binomial test.
Pairwise comparison of LTGA and P3 on the largest problem size using the Mann-Whitney~U test results in
$p < 10^{-5}$ for all problems.

\subsection{Local Search}
The Random Restart Hill Climber and $1+(\lambda, \lambda)$ are both relatively effective on small problem
sizes. This is especially true for the three randomly generated problem classes. These problems
may contain relatively few local optima or just be exceptionally difficult for the model based algorithms.
On Deceptive Trap and Deceptive Step Trap using 4 or less traps, $1+(\lambda, \lambda)$ performs significantly
better than any other algorithm. We believe this is
because $1+(\lambda, \lambda)$ is able to overcome deception by probabilistically
flipping entire traps.
This ability also leads $1+(\lambda, \lambda)$
to outperform the Random Restart Hill Climber on all problems except Nearest Neighbor NK.

On larger problem sizes, the ability for local search to reach the global optimum quickly diminishes.
Only on MAX-SAT are these optimizers competitive
at larger tested problem sizes. However, we believe this is because the largest tested MAX-SAT
was an order of magnitude smaller than the largest size tested for most other problems. As the problem
size increases the number of local optima increases exponentially, which explains why Random Restart Hill
Climbing was unable to scale.
For larger problems it also becomes increasingly unlikely for $1+(\lambda, \lambda)$ to make the right combination
of changes required to reach the global optimum. This
behavior causes high variance in success rate, as evident by the occasional successes on large Deceptive Trap problems.

\subsection{Model Building}
Only techniques which explicitly built models of gene epistasis were able to solve the largest problem
instances. On single instance problems LTGA was more effective than hBOA, with hBOA outperforming
LTGA on Nearest Neighbor NK and Ising Spin Glasses. This may be caused by the differences in modeling method:
unlike the single instance problems, gene epistasis in the randomly generated
problem classes cannot be be perfectly represented with a linkage tree.

Considering how different hBOA and LTGA are in performing optimization, it is somewhat surprising how similar
their results are on HIFF.
However, both techniques rely on populations large enough to support the diversity required to reach the global optimum
and to model epistasis. Both techniques also only rebuild models once per generation. As the subproblems of HIFF
are nested, it is unlikely that either technique can accurately model higher order epistasis before solving
lower order subproblems. Therefore both methods require one generation per subproblem order.

\subsection{P3}
Unlike the other model based methods, P3 generally outperforms
both Random Restart Hill Climber and $1+(\lambda, \lambda)$ even on small problem sizes.
Unlike the other local search methods, P3 outperforms LTGA and hBOA even on large problem sizes.
This implies that P3 is gaining the benefits of each, leveraging local search to solve easy
problems and model building to solve harder ones.

Furthermore, the interaction between these two optimization tools explains some of the reason P3
outperforms each method alone.
On Deceptive Trap P3's use of hill climbing ensures all traps are immediately optimized, allowing for perfect
linkage detection and high quality donation.
On HIFF local search solves all pairwise subproblems, saving P3 a generation over LTGA and hBOA.
In comparison P3 is only a slight improvement on Deceptive Step Trap, which is less amenable to local search.

\section{Fitness Over Time}
\label{sec-overtime}
\begin{figure}
  \begin{center}
  \includegraphicsfit{fitness-over-time}
  \end{center}
  \caption{Compares the median best fitness reached during search for each of the six optimization methods.}
  \label{fig-fitness-over-time}
\end{figure}

For some applications, finding the global optimum is less important than finding good solutions quickly. Therefore
we examine this behavior in Figure~\ref{fig-fitness-over-time}. At regular intervals during optimization
Figure~\ref{fig-fitness-over-time} shows the median of the best fitnesses found at that point of search across
100 runs. For each problem we show the largest problem size for which we were able to successfully gather results
for all six algorithms, but the trends shown are representative of all larger problem sizes. The maximum reporting interval
is set to include the slowest P3 run to reach the global optimum.

% 181 total
% 121 has P3 best
%   9 hc
%  50 lambdalambda
%  20 hboa
%  18 phboa
%  27 LTGA

\subsection{Quantitative Comparison}
Of 181 sample points, P3 had the highest median fitness in 121. In pairwise competition, $1+(\lambda, \lambda)$
was the most likely to outperform P3, doing so on 50 sample points. LTGA, hBOA, and Parameter-less hBOA
were the next best, outperforming P3 on 27, 20, and 18 sample points, respectively. Random Restart Hill Climbing almost
never outperformed P3, doing so only 9 times.
The likelihood that P3 would achieve these pairwise results assuming its median result is actually worse is $p < 10^{-9}$
according to the binomial test.

\subsection{Local Search}
Perhaps the most striking result is the quality of $1+(\lambda, \lambda)$. Until quite far into search this
method performs better than both LTGA and hBOA. Given sufficient evaluations $1+(\lambda, \lambda)$ also outperforms
Random Restart Hill Climbing on all 7 problems. For brief periods in the middle of search it performs the
best of all techniques on: Deceptive Trap; Deceptive Step Trap; HIFF; Ising Spin Glass; and MAX-SAT problems.
$1+(\lambda, \lambda)$'s ability to efficiently incorporate gene modifications of larger
than one bit allows it to overcome the deception and plateaus in Deceptive Trap and Deceptive Step Trap, solve medium sized subproblems
in HIFF, flip the signs on multiple adjacent bits in Ising Spin Glass, and cross plateaus in MAX-SAT. However,
this method is slow in reaching the global optima in many of these problems which causes it to eventually
be overtaken by the model building techniques.

\subsection{Model Building}
Both hBOA and LTGA are marked by periods of little improvement followed by rapid improvement.
In hBOA this is taken to the extreme, with all fitness
improvement made at the very end of search. In both cases this is caused by model building. Before the model
is accurate little improvement is made. Once it is accurate, fitness improves dramatically.

At 58\% of the recording intervals hBOA has the worst fitness of any solver. Most of the exceptions
occur when hBOA is still evaluating its initial population, allowing this random search to temporarily surpass the
local search methods. After $N$ evaluations, however, hBOA and LTGA both fall behind until their models begin
to improve.
Parameter-less hBOA reaches intermediate fitnesses faster than hBOA, doing so on 62\% of intervals, as its models begin
to optimize earlier than hBOA.  However, this trend is reversed after a sufficient number of evaluations, most clearly
on Deceptive Step Trap and Ising Spin Glasses, as hBOA's tuned population overtakes Parameter-less hBOA's parallel populations.

On every problem LTGA has five distinct periods: fitness plateau, near instantaneous improvement, fitness plateau,
and improvement to global optimum. The early period corresponds with
initialization of the population, with the first fitness gain achieved immediately upon completing the first generation.
When using an inaccurate model, LTGA's mixing strategy performs a sort of less effective local search.
Subsequent generations then make only minor fitness improvements. Once the model
becomes accurate and the probability of a crossover using high quality genetic material increases sufficiently, LTGA
enters a second period of rapid improvement.

\begin{comment}
This behavior is easiest to understand on the two Trap problems. LTGA's first generation will push individual traps toward a
local optima, but it requires more than a single generation to do so completely. Until that occurs, the model is likely behaving
no better than random as there is little apparent linkage between bits. Once the model begins to identify individual traps, crossover
can begin to increase the frequency of higher fitness trap settings. This process begins slowly as low fitness local optima are more
likely to be chosen for donation than high fitness local optima due to their frequency in the population. The process becomes
self-catalysing as increased frequency of the global optimum trap genes means increased likelihood of the global optimum being spread by crossover.
\end{comment}

\subsection{P3}
The integration of hill climbing into P3 makes it strictly better than using hill climbing alone.
Early in optimization P3 and the Random Restart Hill Climber have effectively identical quality. This is because
P3 performs the same evaluations as the Hill Climber for the first two restarts. Once P3 begins
performing crossover it immediately improves over the Hill Climber. In 95\% of intervals P3 had a fitness at
least as high as Hill Climbing. As such P3 is better than a simple
hill climber regardless of how long each technique is run and irrespective of how high quality the solution
found has to be.

Unlike the model based methods, which struggle until model accuracy improves, P3's iterative solution
integration allows it to improve much more quickly. This behavior exists in most problems, but is easiest to understand on Deceptive Trap.
On this problem, P3 immediately brings all traps to local optima, equaled only by the Random Restart Hill Climber in quality.
In comparison LTGA must evaluate the entire population and perform multiple generations to reach similar quality.
P3 is able to immediately integrate optimal versions of each
trap into a single individual as they are found by local search, resulting in smoother fitness improvement than LTGA.

\section{Computational Expenses}
While it is common in evolutionary computation to assume the evaluation function will dominate algorithm
complexity, in some domains this will not be true. Model based methods are especially likely to violate
this norm. Therefore, in order to assess P3's quality in solving problems with efficient fitness functions,
we provide data on both its algorithmic complexity and wall clock time.

\subsection{Operation Counting}
\begin{figure}[t]
  \begin{centering}
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{rebuilds}
      \end{centering}
      \caption{Rebuilds}
      \label{fig-rebuilds}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{donations}
      \end{centering}
      \caption{Donations}
      \label{fig-donations}
    \end{subfigure}
  \end{centering}
  \caption{Estimated computation costs incurred by model rebuilding (Figure~\ref{fig-rebuilds}) and
           repeated donations (Figure~\ref{fig-donations}) per evaluation as problem size increases.}
  \label{fig-costs}
\end{figure}

When discussing the asymptotic complexity of P3 in Section~\ref{sec-p3}, two aspects eluded precise
analysis: how expensive is model rebuilding and how many gene donations are made. Figure~\ref{fig-costs}
provides some insight into how often these two aspects of the algorithm are utilized.

Figure~\ref{fig-rebuilds} reports in an algorithmic sense how expensive model rebuilding is for search.
In order to calculate this value we recorded how many times search rebuilt the model during each run.
Figure~\ref{fig-rebuilds} shows the estimated ratio of model rebuilding cost ($N^2$ per rebuild) over evaluation cost ($N$ per evaluation).
If the cost of model building
scaled linearly with evaluations, the relationship plotted for each problem should be asymptotically constant.
For Nearest Neighbor NK, Ising Spin Glasses, and Rastrigin this is the case. For both Trap problems
and HIFF there is slow growth in the ratio. The problem sizes used for MAX-SAT were not sufficient
to accurately gauge the asymptotic behavior. Together this suggests that while the cost of building the model
is almost linear per evaluation, it can grow slowly. However, even in the worst case (HIFF) this growth was
no more than twice the algorithmic cost of an evaluation even using 2048 bits.

When applying a crossover subset, P3 tries random donors from the population until one is found with at least
one bit different from the improving solution. In theory this can result in up to $O(\mu)$ operations.
Figure~\ref{fig-donations} examines the observed average number of donations per evaluation performed.
Ising Spin Glass, HIFF, and Rastrigin all achieve effectively constant behavior here, implying repeated
donation does not impact the asymptotic runtime of P3. Both Trap functions and Nearest Neighbor NK all
increase in number of donations as problem size increases, potentially increasing algorithmic costs. An
important note is that each donation may range in size from a single bit up to $N-1$. However,
repeated donation attempts are far more likely to happen with smaller clusters.
As such this may cause some super-linear growth
in P3, but its unlikely to be very high.

\subsection{Wall Clock Performance}
\begin{figure}
  \begin{center}
  \includegraphicsfit{seconds-to-success}
  \end{center}
  \caption{Comparison of the median number of seconds to reach the global optimum for
           the six different optimization methods with respect
           to problem size.  If the median run did not reach the global optimum no data element
           is shown.  Results given on a log-log scale.}
  \label{fig-seconds-to-success}
\end{figure}


To assess wall clock performance we provide Figure~\ref{fig-seconds-to-success}.
Similar to Figure~\ref{fig-evals-to-success}, each point represents the median
of 100 runs, with unsuccessful runs treated as slower than successful runs.
\begin{comment}
In total these runs
took over 6 computing years to complete. We were therefore forced to use
diverse hardware potentially running multiple processes in parallel.
As such these timings should be considered very skeptically as a number
of sources may contribute to biased error in the results. However, due to
the size of the dataset and the general regularity in the results some general conclusions
can still be made.
\end{comment}
These results were collected using 2.5GHz Intel Xeon E5-2670v2 processors.

\subsubsection{Model Building}
hBOA and Parameter-less hBOA perform much worse when using wall clock time as the unit of comparison than when using
evaluations. This makes sense as hBOA's model building requires $\Omega(N^2)$ time per evaluation while, under reasonable
assumptions, P3 and LTGA require $O(N)$ time per evaluation. This penalty is most clear on Ising Spin Glass where
hBOA goes from being slightly more efficient than LTGA in terms of evaluations to three orders of magnitude worse in terms of seconds.
As P3 and LTGA require a similar asymptotic complexity per
evaluation as the Hill Climber and $1+(\lambda, \lambda)$, no similar change in ordering occurs.

\subsubsection{P3}
When LTGA is optimally tuned to a single instance problem with an efficient evaluation function
it can find the global optimum faster than P3 in terms of wall clock time. However, on randomly
generated problem classes P3's efficient use of evaluations is enough to overtake LTGA.

On the four single instance problems LTGA not only finds the global optimum using less wall clock time,
the factor speedup increases as problem length does. Na\"{i}vely this suggests LTGA is achieving
a lower order of complexity. However, for these experiments LTGA is growing at sub-linear time per
evaluation, which is not asymptotically stable due to (at minimum) the time required to perform an evaluation.
We suspect that the true cause is that $N$ is small enough to be overshadowed by lower order polynomial terms.
For example, LTGA requires $O(N/\mu)$ time per evaluation to rebuild the linkage
model from the frequency table. As a result, for small $\mu$ model building, and not extracting pairwise
frequency, can dominate runtime.

When applied to randomly generated problem classes, the differences in P3 and LTGA's evaluation complexity
dominates runtime complexity. Similar to with Figure~\ref{fig-evals-to-success}, the amount of speedup P3
achieves over LTGA increases with problem size on Nearest Neighbor NK, Ising Spin Glasses, and MAX-SAT.

Across both types of problems we find that P3's time per evaluation grows approximately linearly. As such,
we conclude that P3 requires asymptotically similar amounts of time per evaluation as the other efficient techniques.

\section{Population Sizing}
\begin{figure}[t]
  \begin{centering}
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{pop-p3}
      \end{centering}
      \caption{As problem size increases}
      \label{fig-pop-p3}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{solutions-stored}
      \end{centering}
      \caption{Largest problem size}
      \label{fig-solutions-stored}
    \end{subfigure}
  \end{centering}
  \caption{The total number of solutions stored by P3 when the global optimum is found.
           In Figure~\ref{fig-solutions-stored} the red ``+'' indicates LTGA's tuned population size.}
  \label{fig-p3-storage}
\end{figure}

A major advantage to P3 is that it does not require the user to set a population size parameter.
Beyond making P3 easier to apply, this also conveys two additional advantages: diversity scaled
to initialization and no need to sacrifice intermediate fitness for eventual optimality.

Figure~\ref{fig-pop-p3} shows how the number of total solutions stored in the pyramid changes
as problem size increases, similar to Figure~\ref{fig-pop-sizes} for hBOA and LTGA's tuned population sizes.
As expected, the number of concurrently stored solutions increases as problem difficult increases, with the
exact behavior dependent on the problem landscape. Figure~\ref{fig-solutions-stored} examines how the number
of solutions stored is distributed on the largest problem sizes. Here we see that the behavior depends
on the type of problem. On single instance problems P3's stored variance is relatively low, and generally
higher than optimally tuned LTGA's population size. On randomly generated problem classes P3 has a much
higher variance in stored solutions, but in general requires smaller sizes than LTGA.

\subsection{Problem Instance versus Problem Class}
Our procedure for tuning LTGA and hBOA outlined in Section~\ref{sec-tuning} involved finding
the optimal population size for each class of problem. For real world black box optimization this is
realistically the best either algorithm could hope for as tuning to a problem
instance or population initialization involves repeatedly solving the problem being tuned.
This limitation does not exist in parameter-less methods, which scale their diversity
based on the problem instance without needing to solve that instance repeatedly.

To achieve high success rates on randomly generated problem classes, LTGA and hBOA must use a population size
large enough to solve the hardest instances in that class. Therefore these methods will have
population sizes larger than necessary to solve the easiest instances in the class. Even
on single instance problems, both methods will require population sizes large enough to
ensure the worst random initialization is diverse enough to solve the problem, which may be
much larger than the best random initialization.

\begin{figure}
  \begin{center}
  \includegraphicsfit{evals-to-success-boxplot}
  \end{center}
  \caption{Distribution of evaluations required to reach the global optimum for
           P3 and LTGA on the largest size of each problem.}
  \label{fig-evals-to-success-boxplot}
\end{figure}


Figure~\ref{fig-evals-to-success-boxplot}
highlights how this can effect the required number of evaluations to reach the global optimum, showing
the distribution of results when solving the largest size of each problem. On each problem
LTGA has a much smaller difference between its best and worst runs. This makes sense as LTGA uses the same
population size regardless of instance and progresses search generationally. In contrast P3 has a much
higher split, with many runs finishing very quickly.
On all problems except Deceptive Step Trap, P3's upper quartile is lower than LTGA's lower quartile.
Furthermore, on Deceptive Trap, HIFF, and Ising Spin Glasses, P3's worst run is better than LTGA's best run.
For Nearest Neighbor NK, most of P3's runs finish much faster than the fastest LTGA runs. However, some
of P3's outliers take approximately as long as LTGA's tuned performance.
This supports the hypothesis that P3 is able to scale its diversity not just
to the problem class, but to the problem instance or even problem initialization, something
wholly infeasible for tuned population sizing to do.

This tuning distinction is also apparent when comparing Parameter-less hBOA with hBOA in Figure~\ref{fig-evals-to-success}.
While generally performing worse than hBOA, the difference between the two algorithms is smallest
on randomly generated problem classes. On MAX-SAT, Parameter-less hBOA actually outperformed both hBOA and LTGA,
likely due to its ability to scale diversity to the problem instance instead of the entire problem class.

\subsection{Fast versus Optimal}
\label{sec-fast-vs-optimal}

In Section~\ref{sec-overtime} we examined intermediate fitness qualities of LTGA and hBOA when using
population sizes tuned to reach the global optimum. As a result, both were exceptionally ineffective
at quickly reaching high quality solutions. This is because unlike P3, these methods have an explicit
trade off between optimal performance and intermediate performance caused by their population size parameter.

\begin{figure}[t]
  \begin{centering}
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{small-pop-dst}
      \end{centering}
      \caption{Deceptive Step Trap 203}
      \label{fig-small-pop-dst}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{small-pop-nk}
      \end{centering}
      \caption{Nearest Neighbor NK 200}
      \label{fig-small-pop-nk}
    \end{subfigure}
  \end{centering}
  \caption{Comparison of how reducing LTGA's population size effects
           the median best fitness reached during search.}
  \label{fig-small-pop}
\end{figure}

Figure~\ref{fig-small-pop} examines the effect of population size on LTGA's intermediate fitness by
reducing LTGA's population size to one tenth of the tuned value. The two problems shown are representative of the behavior of using
a smaller population size on the other five problems. Reducing the population size caused LTGA to improve earlier but plateau
at lower fitnesses. This caused LTGA's success rate to drop from 100 to 0 on Deceptive Step Trap and from 98 to 68 on Nearest
Neighbor NK.
Even when using a reduced population size for LTGA, P3 still achieved a fitness at
least as high as LTGA at 80\% of intervals.
The likelihood that P3 would achieve these pairwise results assuming its median result is actually worse is $p < 10^{-15}$
according to the binomial test.



\begin{comment}
It is important to note that hBOA and LTGA were tuned specifically
to find the global optimum and are not necessarily using the optimal population size for finding intermediate fitnesses. Consider
that for both reducing the population size would almost certainly improve their fitness for evaluation steps less than their population
size. To examine the effect of population size we tested LTGA using one tenth of the population size required for reliably finding the
global optimum, with the results given in Figure~\ref{fig-small-pop}.
Reducing the population size resulted in LTGA's initial fitness improvement
occurring earlier, as the first generation is completed much more quickly. On Deceptive Step Trap this means that
LTGA leaps ahead of P3 due to its ability to overcome the two bit fitness plateaus.
%
Across all tested problems using the smaller
population size reduced the quality of LTGA's first fitness plateau, likely due to missing required diversity to reach higher quality.
The second period of improvement also comes earlier and reaches a lower quality fitness. On Deceptive Step Trap 0
runs reach the global optimum, down from 100 successful for the full population size. On Nearest Neighbor NK this drops the number
of successful runs from 98 to 68. As a result we conclude that while reducing the population size of LTGA may improve its quality
at early points during optimization, doing so reduces the robustness of the final solution found. This is in contrast to P3
which balances high quality intermediate fitness without trading away eventual optimality.
\end{comment}

\section{Inner Workings}

\begin{figure}[t]
  \begin{centering}
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{cross}
      \end{centering}
      \caption{Crossover Proportion}
      \label{fig-cross}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{cross-success}
      \end{centering}
      \caption{Crossover Success}
      \label{fig-cross-success}
    \end{subfigure}
  \end{centering}
  \caption{For each problem Figure~\ref{fig-cross} shows the proportion of P3 evaluations spend on crossovers
           and Figure~\ref{fig-cross-success} shows the percentage of fitness improving crossover evaluations.}
\end{figure}

While analysis of optimization speed is useful from a practitioner standpoint, doing so provides very
little insight into algorithm behavior. To better understand how P3 works in detail we present here
a look at some internal features specific to P3.

\subsection{Crossover}
Figure~\ref{fig-cross} shows the proportion of evaluations P3 spends on crossover, as opposed to hill climbing,
and Figure~\ref{fig-cross-success} shows what percentage of crossover evaluations resulted in a fitness improvement.
Together these figures provide some insight into the role of crossover within P3. The behavior
for each is clearly problem dependent and generally asymptoticly stable as problem size increases.

When solving problems where epistasis can be effectively detected and represented by a linkage tree, P3 tends to spend
less evaluations performing crossover and each crossover is more likely to be successful.
Deceptive Trap and Rastrigin are the easiest problems to model epistasis, with local search quickly
reducing pairwise entropy in each. These are also the problems where P3 uses the least evaluations
on crossover and has the highest success rates for crossover. At the other extreme are Nearest Neighbor
NK and Ising Spin Glasses, which both have overlapping linkage not representable by a linkage tree.
These problems have the highest crossover usage and lowest crossover success of any problem except Deceptive
Step Trap.  While Deceptive Step Trap's epistasis can be accurately modeled by a linkage tree, the
exponential number of plateaus makes detecting gene linkage very challenging.

\begin{comment}
P3 performs optimization using a mixture of hill climbing and crossover. Exactly how much time the algorithm
dedicates to each is not clear from the algorithm description alone. As such, Figure~\ref{fig-cross} shows
that the relationship between the two is strongly problem dependent but relatively independent of problem size.
In general, problems which can be more accurately represented by crossover
required less crossover evaluations. Deceptive Trap and Rastrigin spent the least evaluations on crossover, using
15\% and 20\% respectively on the largest problem sizes. Both of these problems are perfectly separable and have relatively
few local optima in each subproblem. HIFF and Ising Spin Glasses use crossover for about 60\% of evaluations. The HIFF structure can
be perfectly learned by the linkage tree, but the higher order relationships require multiple stages of crossover to optimize.
Ising Spin Glasses have an overlapping structure, making them impossible to perfectly represent in a single linkage tree, but
that overlap is relatively minor in comparison with Nearest Neighbor NK, which uses 81\% of evaluations on crossover. Deceptive Step Trap spends the highest
percentage of evaluations on crossover, 92\%. Unlike all of the other problems, the value taken by an individual bit in Deceptive
Step Trap has very little meaning. This is because any trap value is either a local optima or 1 bit flip away from being a local optima.
This has a combined result of meaning it takes very few local search evaluations to find a local optima but very many crossover operations
to proliferate the global optima. Epistatic relationships are also going to be very weak and even small population sizes are likely
to mark all clusters as $useful$.

Solutions are only added to the next highest pyramid level if at least one crossover donation resulted in a fitness
improvement. Figure~\ref{fig-cross-success} examines the percentage of crossover donations that resulted in a fitness
improvement. The ordering in Figure~\ref{fig-cross-success} is an almost perfect inversion of Figure~\ref{fig-cross},
implying that the more successful crossover is at achieving fitness improving donations the lower the proportion of evaluations P3 will
spend performing crossover. P3 achieves an impressive 30\% success rate for crossover donations on the largest Deceptive Trap
problem sizes. This makes sense as crossover is able to immediately and perfectly identify entire traps such that all donations
always contain only complete traps. Furthermore, by forcing crossover to attempt donations of genes different from the current solution,
donations containing a single trap will have a very high success rate, always improving suboptimal traps which are far more frequently
created by local search that optimal traps. Rastrigin and HIFF have relatively high success rates of 11\% and 7\%, respectively. Again
this is likely due to accurate modeling and relatively low diversity of building block alternatives.
Ising Spin Glasses and Deceptive Step Trap both have low success rates near 0.01\%. This follows as both are difficult to model with
a linkage tree. In comparison to Figure~\ref{fig-cross-success} Deceptive Step Trap performs better than expected for crossover.
However, the reason for this is that even exceedingly uninformed crossover can make improvements to Deceptive Step Trap as
flipping two bits in the same trap will move between two local optima. Nearest Neighbor NK had the least successful crossovers,
with only 0.007\% successful on the largest tested problems. In comparison to Ising Spin Glass, NK's overlap is far more extensive.
As a result it makes sense that individual crossovers are very unlikely to be fitness improvements.
\end{comment}

When compared with LTGA, P3's crossover success rates are lower but similar in problem ordering.
Counterintuitively, the use of hill climbing on the initial population reduces
P3's crossover success, not because it reduces model quality or the donation pool, but because it is much more challenging to improve
locally optimal solutions than randomly generated ones. LTGA's crossover benefits from application to unoptimized solutions, which
makes its aggregate crossover success incomparable to P3's.

Even when crossover success rates are quite low, such as Nearest Neighbor NK's 0.007\% success,
the results from Section~\ref{sec-optimum} and Section~\ref{sec-overtime} show it's still critical to optimization. Without
crossover, P3's performance would be identical to the Random Restart Hill Climber, which was unable to solve even moderately sized problems
and quickly fell behind P3 in intermediate fitness quality. Therefore even infrequently successful crossover donations are
critical to success. This does, however, suggest a potential avenue for future improvement by using more successful
modeling and donation algorithms.

\subsection{Pyramid}
\begin{figure}[t]
  \begin{centering}
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{level-size}
      \end{centering}
      \caption{Population Size}
      \label{fig-level-size}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{level-success}
      \end{centering}
      \caption{Crossover Success}
      \label{fig-level-success}
    \end{subfigure}
  \end{centering}
  \caption{For each problem Figure~\ref{fig-level-size} shows the number of solutions stored in each level of the pyramid
           and Figure~\ref{fig-level-success} shows the percentage of fitness improving crossover evaluations at each level.}
\end{figure}

Another feature unique to P3 is the shape and size of the population pyramid
constructed for each problem. Figure~\ref{fig-level-size} shows the number of solutions stored at
each level of the pyramid for the largest tested problem sizes. Each point is the
median size across 100 runs. If a run did not store any solutions at a level it is treated as 0.
No point is drawn if the median run had 0 solutions stored at that level. While pyramid size
is effected by problem size, the overall shape is not. As such the behavior shown in Figure~\ref{fig-level-size}
is representative of that for all other tested problem sizes.

With the exception of the dip in Deceptive Step Trap, all of the pyramids show a monotonic reduction
in size as the level increases. This is because a solution must be a strict fitness improvement
over its previous version to be added to a higher level, which becomes less likely
each time the solution improves. \cite{lobo:2011:dynamicpop} found theoretical evidence
and \cite{goldman:2011:dynamic-parameters} found empirical evidence that the optimal
population size decreases each generation of traditional evolutionary search.
By decreasing in size, P3 implicitly stores more diversity in low levels and focuses
search on high quality solutions at higher levels. In comparison,
LTGA and hBOA suboptimally use a fixed population size at each generation.

Figure~\ref{fig-level-success} examines how crossover success changes at different
levels of the pyramid. At low levels, success gets progressively lower
as solution quality increases faster than the model's ability to improve solutions.
At higher levels modeling becomes more accurate and donations contain higher frequencies
of high quality building blocks, resulting in increased crossover success. The
highest level of most problems has a low crossover success rate, as solutions
crossing with that level have already been improved by previous operations to
the point where the only improvement would be to create the global optimum, which can
only happen once.

\subsubsection{Deceptive Step Trap}
The number of solutions stored at the fourth level of Deceptive Step Trap is
significantly lower than that of the third or fifth levels, breaking the decreasing
trend of the other six problems. Figure~\ref{fig-level-success} has a similar
aberration, with crossover success dropping to  0.0004\% before rebounding and
following the more common trajectory. This behavior exists in all other problem
sizes tested, with the dips occurring at exactly the same level.

This behavior is rooted in the peculiar nature
of this landscape.
After local search, all traps in all solutions have a total
number of 1 bits equal to either 0, 1, 3, 5, or 7 as these correspond to the local
optima when using $k=7$ and $s=2$. Crossover is very likely to overcome the
two bit plateaus, and as a result solutions in the second level generally do not
contain the lowest fitness local optima (5 bits set) and the third
level has very few traps set to the next worst local optima (3 bits set). As a result,
solutions which reach the third level can only be improved by replacing the deceptive
local optima (0 and 1 bits set) with the global optimum (7 bits set).
The global optimum is very rare in the population, and with 8 ways to represent local optima
linkage learning is inaccurate. Therefore it is very unlikely for crossover to be successful,
meaning few solutions will be added to the fourth level. Solutions that do improve by
definition must have a higher frequency of optimal trap settings, meaning level four's model
will be more accurate and donations are more likely to contain optimal trap values.
Thus the level size and crossover success rates increase after contracting around level four.

\section{Conclusions and Future Work}
The Parameter-less Population Pyramid (P3) is a recently introduced method for performing black box
optimization. P3's primary innovation is the replacement of the generational model with a pyramid of populations.
This pyramid is constructed iteratively, with both the number of levels and the number of solutions stored
at each level growing as search progresses. P3 uses a model based crossover method
which learns a linkage tree from gene epistasis. Combined with a simple hill climber, P3's design contains
many synergistic features.

Across a large number of problems and problem sizes P3 required less evaluations to reach the global optimum
than optimally tuned state-of-the-art competitors. On single instance problems P3's improvement was by a
constant factor, while for the three randomly generated problem classes P3's improvement increased with problem size. This
quality extends to intermediate points during evolution, with P3 generally reaching at least as high
of fitness as the competitive techniques when using the same number of evaluations. While P3 does require
modeling overhead, the expense of this overhead is approximately linear with respect to genome size. There
is some evidence that even when compared on wall clock time, P3 performs on par with
the best comparison techniques. All of these achievements are made without any problem specific parameter
tuning, making P3 easier to apply to new domains than its two closets competitors in quality.

P3's quality is due to a number of desirable traits. First, mixing local search with model based
crossover lets search focus on properly mixing high quality solutions. Second, by adding diversity only
as necessary P3 tends to use the minimal amount of random initialization, unlike other techniques which must
overcompensate with larger population sizes on single instance problems and consider the worst instance
when solving problem classes. Third, by heavily exploiting existing diversity before adding more P3 is able
to reach high quality intermediate fitnesses quickly without prematurely converging. Fourth, the very
nature of the pyramid's shape allows search to preserve a desirable proportion of diversity at
each fitness level, similar to a generational model using a decreasing population size.

There are a number of meaningful avenues for future P3 experimentation. Perhaps the most
pressing for practitioner acceptance is to apply P3 to real world problems and compare
its results with other black box or even problem specific heuristics. While parameter-less,
P3 is currently limited to discrete, fixed length genomes evaluated using single objective
fitness. These limitations can be relaxed with future work to make P3 more widely applicable.
While asymptotically linear in problem size, P3's modeling techniques and local search methods are likely going
to be prohibitively expensive for genome sizes in the hundreds of thousands or millions of genes,
and the inability of the model to capture overlapping linkage may be hindering
search efficiency. Overcoming these limitations by using a new modeling technique may allow
the pyramid model even greater flexibility. Similarly, while P3 is able to overcome low
order deception via linkage learning, the iterative improvement method by which crossovers
are made may mislead search on landscapes with higher order deception.

However, even without
these improvements our results show P3 is highly efficient at finding
global optima on black box problems without any problem specific tuning.


\section{Acknowledgements}
This material is based in part upon work supported by the National Science Foundation
under Cooperative Agreement No. DBI-0939454. Any opinions, findings, and conclusions
or recommendations expressed in this material are those of the author(s) and do not
necessarily reflect the views of the National Science Foundation.

\small

\bibliographystyle{apalike}
\bibliography{../main}

\normalsize
\appendix
\section{hBOA Simplification}
\label{sec-appendix}
To measure the quality of a decision forest, hBOA applies Equation~\ref{eq-hboa}.
To favor compact
models, Equation~\ref{eq-hboa} is scaled by Equation~\ref{eq-hboa-stop}, which provides increased cost
for more total leaves.
This quality is used for two purposes: comparison of potential changes from the existing model
and comparison of that change with the existing model. The basis for our simplication
is to rearrange $p(B)BDe(B) < p(B')BDe(B')$ to be $\frac{p(B)}{p(B')}<\frac{BDe(B')}{BDe(B)}$.

\begin{equation}
  BDe(B) = \prod_{i=0}^{N}\prod_{l\in L_i} \frac{\Gamma(m'_i(l))}{\Gamma(m_i(l) + m'_i(l))}
  \prod_{x_i}\frac{\Gamma(m_i(x_i, l) + m'_i(x_i,l))}{\Gamma(m'_i(x_i,l))}
  \label{eq-hboa}
\end{equation}

\begin{equation}
  p(B) = c2^{-0.5(\sum_i|L_i|)log_2\mu}
  \label{eq-hboa-stop}
\end{equation}

The outermost product of Equation~\ref{eq-hboa} iterates over all trees in the forest. However, each split
can modify only one of the trees and therefore the contribution of all others can be canceled. The middle
product is across all leaves in the tree. Again since only one leaf can be changed, all other terms can
be canceled. By convention hBOA uses uninformed Bayesian priors of $m'_i(l)= 2$ and $m'_i(x_i, l)=1$ for
binary alphabets. As $\Gamma(a) = (a-1)!$ this means the top term in the middle product and the bottom
term in the third product reduce to 1. The only remaining terms are then $m_i(l)$ and $m_i(x_i, l)$ which
represent the number of solutions which reached leaf $l$ and the number of solutions which reached leaf $l$
with a specific value for $x_i$, respectively.

Equation~\ref{eq-hboa-stop} can also be simplified when doing comparisons. If model $B'$ has exactly one more
leaf than model $B$ then the ratio $\frac{p(B)}{p(B')}$ simplifies to $2^{0.5 log_2\mu}$ regardless of
total model size.

The resulting simplifications create Equation~\ref{eq-hboa-final},
where $B'$ is different from $B$ by exactly 1 split, such that $l$ was split to create $l'$ and $l''$.
The best split is whichever maximizes its improvement over $B$, which is equal to the right side
of the inequality. Note that these factorials can still be exceedingly large and
therefore it is imperative that implementations avoid rounding errors and overflows.



\end{document}

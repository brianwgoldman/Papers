\documentclass[twoside]{article}
\usepackage{ecj,palatino,epsfig,latexsym,natbib}
\usepackage{url}
\usepackage{verbatim}
\usepackage{subcaption}
\usepackage[noend]{algpseudocode}

\newcommand{\includegraphicswide}[1]
{\includegraphics[width=.9\textwidth,height=\textheight,keepaspectratio]{#1}}

\newcommand{\includegraphicsfit}[1]
{\includegraphics[width=\columnwidth,height=\textheight,keepaspectratio]{#1}}

\usepackage{array}
\newcolumntype{L}{>{\centering\arraybackslash}m{1.9cm}}

%% do not add any other page- or text-size instruction here

\parskip=0.00in

\begin{document}

\ecjHeader{x}{x}{xxx-xxx}{200X}{TODO 45-character paper description}{B. W. Goldman and W. F. Punch}
\title{\bf Fast and Efficient Black Box Optimization using the Parameter-less Population Pyramid}  

\author{\name{\bf B. W. Goldman} \hfill \addr{brianwgoldman@acm.org}\\ 
        \addr{Department of Computer Science and Engineering, Michigan State University, 
        East Lansing, 48823, United States}
\AND
       \name{\bf W. F. Punch} \hfill \addr{punch@msu.edu}\\
        \addr{Department of Computer Science and Engineering, Michigan State University, 
        East Lansing, 48823, United States}
}

\maketitle

\begin{abstract}

TODO About 200 words.

\end{abstract}

\begin{keywords}

Genetic algorithms, 
linkage learning,
local search,
parameter-less.

\end{keywords}

\section{Introduction}
A primary purpose of evolutionary optimization is to efficiently find good solutions
to challenging real world problems with minimal prior knowledge about the problem itself.
This driving goal has created search algorithms which can escape user bias to create
truly novel results, sometimes publishable or patentable in their own right~\citep{kannappan:2014:humies}.
While it is not possible for any algorithm to do better than random search across all possible
problems~\citep{Wolpert:1997:nfl}, effectiveness can be achieved by assuming the search
landscape has structure and then biasing the algorithm toward exploiting that structure.

In evolutionary optimization, and genetic algorithms~(GAs) in particular, search is often
biased through parameters. This can be beneficial as it allows practitioners to inject their
knowledge about the shape of the search landscape into the algorithm.
However, the quality of solutions found, and the speed at which they are found, is strongly tied to setting these parameters
correctly~\citep{goldberg:1991:gasize}. As such expert knowledge or exceedingly
expensive parameter tuning~\citep{grefenstette:1986:optimalga} may be required to leverage
this feature to its fullest potential. Furthermore,  parameters such as population size, mutation rate, crossover
rate, tournament size, etc can have no clear relationship to the problem being solved, meaning even
domain experts may not understand how they will interact with the problem or with each other.

As such there have been periodic efforts to reduce or remove the need for parameter tuning.
\cite{Back:1992:selfadapt} introduced self-adaptive parameters, in which parameter values
were included in each solution's genome and underwent evolution. This allowed search
to optimize some of its own parameters resulting in a reduced the need for expert tuning.
\cite{harik:1999:parameterlessga} were able to design an entirely parameter-less GA by
leveraging schema theory and parallel populations. Unfortunately these methods were provably less efficient
than directly setting the parameters to optimal values~\citep{pelikan:1999:worstparameter-less}.

One area that has been very effective at reducing the number of algorithm parameters is
model based search. \cite{pelikan:2006:hboa}'s Hierarchical Bayesian Optimization
Algorithm~(hBOA) and \cite{thierens:2010:ltga}'s Linkage Tree Genetic Algorithm~(LTGA)
both only require a single parameter: population size. \cite{posik:2011:parameterless}
leveraged model building to create a fully parameter-less algorithm, but it is restricted to
only order-k, fully decomposable, noiseless problems.

Most recently \cite{goldman:2014:p3} introduced the Parameter-less Population Pyramid~(P3).
This method uses a pyramid structure of populations to combine model based search with local search
to achieve parameter-less optimization. Initial results suggest that unlike
previous parameter-less methods, P3 is actually more efficient than current state-of-the-art
parameterized search algorithms. In this work we shall extend these results to cover more
comparison algorithms, compare both efficiency in reaching the global optimum and intermediate
fitnesses, algorithm complexity analysis, and provide more in depth analysis of P3 itself.
\begin{comment}
Section~\ref{sec-optimizers}
explains how each of these algorithms, including P3, perform search. Section~\ref{sec-problems}
provides a description of each test problem. As hBOA and LTGA require a population size parameter
Section~\ref{sec-tuning} provides our methodology to ensure each is optimally tuned to each problem.
\end{comment}

\section{Comparison Optimizers}
\label{sec-optimizers}

In order to fully understand the effectiveness of a black box search algorithm, it is useful
to compare it with other similar algorithms. Therefore here we preset five advanced algorithms with
related features to P3. The Random Restart Hill Climber was chosen as an efficient form of repeated
local search, and because it shows the advantages of performing the more complex portions of P3.
The $1+(\lambda, \lambda)$ algorithm is the current best theory supported simple genetic algorithm
and its method of crossover is in some sense a macro-mutation just as in P3. hBOA and Parameter-less
hBOA are advanced model building search techniques which are very effective at learning complex
problem structure, designed to achieve similar goals as P3's linkage learning but using very different
methods. Finally LTGA represents the current state-of-the-art in black box search and is the origin
of P3's linkage learning and crossover methods.

Finally, only hBOA and LTGA require any parameters, with each of these only requiring a population
size. This makes knowing the optimal behavior of these algorithms much more tractable. All of the
algorithms are also gene order independent, fitness scale invariant, and unbiased. This means
for any problem the order in which problem variables appear in the genome can be changed
without changing the behavior of the search. The fitness can also be manipulated in any fashion
as long as the rank ordering of solutions is unchanged. These algorithms are also unaffected by the meaning
assigned to each bit, such that inverting a predetermined random subset of genes before evaluation
will not impact search efficiency.

\subsection{Random Restart Hill Climber}
\label{sec-hill-climber}
Perhaps the simplest black box search heuristic is stochastic local search, or hill climbing.
This optimization technique focuses on improving a single solution until it reaches a local
optimum. Here we use the first improvement hill climber defined by \cite{goldman:2014:p3}
and given in Figure~\ref{fig-hc}. This algorithm works by flipping each bit in a random
order, keeping modifications when fitness is improved, until doing so cannot result in
further fitness improvements.

\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{Hill-Climber}{}
    \State $options \leftarrow [0 \dots N-1]$
    \State $tried \leftarrow \emptyset$
    \While{$|tried| < |options|$}
      \ForAll{$index \in shuffled(options)$}
        \If{$index \notin tried$}
          \State Flip bit $index$ in solution
          \If{solution's fitness increased}
            \State $tried \leftarrow \emptyset$
          \Else
            \State Revert change
          \EndIf
          \State $tried \leftarrow tried \cup \{index\}$
        \EndIf
      \EndFor
    \EndWhile
  \EndProcedure
\end{algorithmic}
  \caption{Hill climbing algorithm used to improve randomly generated solutions until no single
           bit change results in a fitness improvement.}
  \label{fig-hc}
\end{figure}

The hill climber requires an amortized cost of $O(1)$ operations per evaluation. In order to
terminate, at least one evaluation must be performed for each of the $N$ bits in the solution.
As such any operation that happens only once per search can be amortized over at least $N$
evaluations, covering the initialization of $options$.

With the use of proper hashing data structures, determining if $index \notin tried$ requires $O(1)$
time. While this operation may be called without a directly related evaluation, amortized cost
provides an upper bound. Consider that in order to add an $index$ into $tried$ an evaluation must
be performed. Lets say this evaluation pays for two checks of that $index$, one of which was used
during this loop. If no fitness improving move is found, the next time through the loop the second check
is used. A third check is only necessary if no fitness improving move was found for any index.
This is a contradiction as the loop terminates when no improving move was found. Therefore this check
can only be called twice per evaluation.

Due to its nature, this hill climber cannot escape basins of attraction. Once a solution is reached
such that none of the single bit neighbors are fitness improvements, search stops. As a result to
have any hope of solving multimodal problems this algorithm requires a restart mechanism. We have
chosen here to naively restart search from a random solution whenever a local optima is found. This
ensures that on all landscapes there is always a non-zero probability of search finding the global optimum.

\subsection{$1+(\lambda, \lambda)$}
\cite{doerr:2013:lambdalambda} presented the first genetic algorithm to provably show
the advantages of performing crossover on simple landscapes. This comparatively simple
algorithm maintains only a single individual and a self-controlled parameter $\lambda$.

Each iteration, the number of bits to flip is chosen from the binomial distribution $b\sim B(N, \frac{\lambda}{N})$,
where $N$ is the number of bits in the genome.
Next, $\lfloor\lambda\rfloor$ offspring are produced by flipping $b$ bits. The
best mutant then produces $\lfloor\lambda\rfloor$ offspring via uniform crossover with the original parent, such that each gene comes from the
mutant with probability $\frac{1}{\lambda}$. In the original algorithm the best
offspring produced by crossover then replaces the original parent if its fitness is no worse.
The $\lambda$ parameter, which is initialized to 1, is decreased if the offspring replaced
its parent and increased otherwise.

The original formulation was designed specifically for unimodal landscapes and as such were
not directly suitable for multimodal problems. \cite{goldman:2014:p3} extended $1+(\lambda, \lambda)$
to include random restarts. As search stagnates, the $\lambda$ parameter increases in value. Eventually
this results in $\lambda \ge N$ causing mutation to always flip all bits of the individual.
As this prevents any future improvement, whenever $\lambda \ge N$ search is restarted from a random solution with $\lambda$
reset to 1.

A few other efficiency modifications were also made. If there is a tie in crossover offspring fitness,
whichever has a larger hamming distance from the parent is retained. This encourages drifting across plateaus.
The ``mod'' control strategy proposed by \cite{doerr:2013:lambdalambda} was not used as it conflicted with
the random restart strategy.
If a crossover individual is identical to either of its parents, it is not evaluated.
If mutation produces an offspring which is better than the best crossover offspring, it is used to compare
against the original parent.


\subsection{Hierarchical Bayesian Optimization Algorithm}

\cite{pelikan:2006:hboa} used statistical principles in combination with a decision tree structure
to create the Hierarchical Bayesian Optimization Algorithm (hBOA). This method creates a model of
epistatic relationships between genes which is then used to stochastically generate new solutions.
Each generation a binary tournament with replacement is used to selection $\mu$ solutions from
the population. These solutions are then used to build the model, which in turn is used to generate $\mu$ new
solutions. The new solutions are then integrated into the population using restricted tournament
replacement.

Conceptually, the model built by hBOA is trying to infer rules of the form ``Given that this
subset of genes are set to these values, how frequently is gene $x_i$ set to value v?'' This can
be represented using a directed acyclic decision forest, with each tree in the forest representing one gene
in the solution. In the decision tree $T_i$, which is used to set the value of gene $x_i$,
each internal node represents previous decisions on how to set
some other gene $x_j$, with the children of that node representing how the decision was made. The
leaves of each tree give the probability that $x_i$ should be set to each possible value.
Therefore in binary alphabets binary trees with a single probability $p$ stored at each leaf
can be used, where $p$ is the probability $x_i$ should be set to one.

The forest is constructed iteratively, with each tree initially containing a single leaf
and with each leaf storing a pointer for each selected solution. Each iteration the algorithm considers
all possible ways of splitting an existing leaf using another gene $x_j$, such that solutions in the
leaf are moved to the newly created leaves based on their value for $x_j$. The general goal is to
separate the solutions such that all solutions with $x_i = 0$ move to one leaf while solutions with
$x_j = 1$ move to the other. Whichever split maximizes Equation~\ref{eq-hboa} is then kept.
This process continues until none of the splits result in a higher quality model than the current one. To favor compact
models, Equation~\ref{eq-hboa} is scaled by Equation~\ref{eq-hboa-stop}, which provides increased cost
for more total leaves.

\begin{equation}
  BDe(B) = \prod_{i=0}^{N}\prod_{l\in L_i} \frac{\Gamma(m'_i(l))}{\Gamma(m_i(l) + m'_i(l))}
  \prod_{x_i}\frac{\Gamma(m_i(x_i, l) + m'_i(x_i,l))}{\Gamma(m'_i(x_i,l))}
  \label{eq-hboa}
\end{equation}

\begin{equation}
  p(B) = c2^{-0.5(\sum_i|L_i|)log_2\mu}
  \label{eq-hboa-stop}
\end{equation}

While Equation~\ref{eq-hboa} is very complex and almost always results in near infinitesimal results, many
of the terms can be canceled out as it is only important to know the relative quality between two models:
$p(B)BDe(B) < p(B')BDe(B')$.
The outermost product of Equation~\ref{eq-hboa} iterates over all trees in the forest. However, each split
can modify only one of the trees and therefore the contribution of all others can be canceled. The middle
product is across all leaves in the tree. Again since only one leaf can be changed, all other terms can
be canceled. By convention hBOA uses uninformed Bayesian priors of $m'_i(l)= 2$ and $m'_i(x_i, l)=1$ for
binary alphabets. As $\Gamma(a) = (a-1)!$ this means the top term in the middle product and the bottom
term in the third product reduce to 1. The only remaining terms are then $m_i(l)$ and $m_i(x_i, l)$ which
represent the number of solutions which reached leaf $l$ and the number of solutions which reached leaf $l$
with a specific value for $x_i$, respectively.

Equation~\ref{eq-hboa-stop} can also be simplified when doing comparisons. If model $B'$ has exactly one more
leaf than model $B$ than $p(B)$ and $p(B')$ the ratio $\frac{p(B)}{p(B')}$ simplifies to $2^{0.5 log_2\mu}$ regardless of
total model size.

All combined, this means the expression $p(B)BDe(B) < p(B')BDe(B')$ can be calculated using Equation~\ref{eq-hboa-final},
where $B'$ is different from $B$ by exactly 1 split, such that $l$ was split to create $l'$ and $l''$. Only splits that
satisfy this inequality are considered good enough to keep. Furthermore, whichever split maximizes the right side of the
Equation~\ref{eq-hboa-final} is chosen each iteration. Note that these factorials can be exceedingly large and
therefore it is imperative that implementations avoid rounding errors and overflows.

\begin{equation}
  2^{0.5 log_2\mu} < \frac{(m_i(l) + 1)!}{m_i(0, l)!m_i(1,l)!} \cdot
  \frac{m_i(0, l')!m_i(1,l')!m_i(0, l'')!m_i(1,l'')!}{(m_i(l') + 1)!(m_i(l'') + 1)!}
  \label{eq-hboa-final}
\end{equation}

Initially there are $\Theta(N^2)$ possible ways to split existing leaves, as each of the $N$ single node
trees can be split by any of the other $N-1$ genes. Each iteration a new edge is added to the decision
forest, meaning some of the previously tested splits cannot be used. For instance, if $T_i$, which is used
to decide the value of $x_i$, is split using the value of $x_j$, $T_j$ can no longer be split using $x_i$.
As a split creates two new leaves, $O(N)$ new potential splits must also be tested. Equation~\ref{eq-hboa-final}
parses all solutions which reach a leaf to count gene frequencies, requiring $\mu$ time.
The number of total leaves created depends heavily on the problem and $\mu$.
However, assuming no splits are accepted or that the cost of testing all future splits is less than
the initial $\Theta(N^2)$, constructing the model requires $\Omega(\mu N^2)$ time. Each
model is used to generate $\mu$ solutions, leading to a cost per evaluation of $\Omega(N^2)$.

To generate a solution, the value of each gene $x_i$ is set using its corresponding decision tree $T_i$. Because
the forest is directed acyclic, there must be an ordering of $T_i$ such that before $T_i$ is executed all
$x_j$ it uses to make decisions have already been set. As such, previous decisions made by other trees
are used to follow each $T_i$ until a leaf is reached. The value of $x_i$ is then set based on the
probably that other solutions reached that leaf with each value of $x_i$.

To perform replacement, hBOA uses restricted tournament replacement. After each new solution is generated
and evaluated, $w$ solutions are chosen at random from the population, where $w=\min\{N, \frac{\mu}{20}\}$.
Whichever of the $w$ solutions is the most genetically similar to the offspring is compared with the offspring.
If the fitness of the offspring is no worse, it replaces the genetically similar member of $w$, otherwise the
offspring is discarded. This method is designed to preserve genetic diversity as only genetically similar
solutions must compete on fitness.

To model properly, hBOA is designed to work with large population sizes, resulting in a large number of
evaluations per generation. As hBOA utilizes explicit diversity maintenance, standard methods for determining
convergence are not considered very accurate. Therefore the authors suggest that an hBOA run should be
terminated after performing generations equal to $N$.

Like other model based techniques, hBOA has very few parameters. There is no mutation or crossover,
and modeling does not rely on any explicit parameters. Solution selection, generation, and replacement
are all derived from the population size, which must be set by the user.

\subsection{Parameter-less hBOA}
Using the methods first introduced by \cite{harik:1999:parameterlessga} for the Parameter-less GA,
\cite{pelikan:2004:parameterlesshboa} created Parameter-less hBOA which automatically scales its
population size to fit the problem. This is done by maintaining a list of concurrent populations
using exponentially scaled population sizes.

A run of Parameter-less hBOA starts with a single population of size $\mu_0$, conventionally set
to $\mu_0=10$. After two generations are performed, a new population of size $\mu_1 = 2\mu_0$ is created
and performs a generation. Evolution then continues with the $\mu_0$ population performing two generations
for each one performed by $\mu_1$. Each time population $\mu_i$ performs its second generation a new population
$\mu_{i+1}=2\mu_i$ is created, which performs generations half as often as $\mu_i$. In this way an infinite number of
parallel population can be simulated, with each population receiving the same number of total evaluations.

In all other aspects each population is identical to an hBOA population using a fixed $\mu$. No search information
is shared among populations, and each search is independently terminated. As such Parameter-less hBOA cannot
perform better than hBOA using the optimal population size for a given instance, as it must also spend evaluations
on populations of different sizes. This inefficiency is bounded by a log multiple of the total number of
evaluations~\citep{pelikan:1999:worstparameter-less}.

\subsection{Linkage Tree Genetic Algorithm}
~\cite{thierens:2010:ltga} introduced the Linkage Tree Genetic Algorithm (LTGA) which automatically
detects and exploits problem epistasis by examining pairwise gene entropy. Due to its enhanced
ability to preserve high fitness gene subsets, LTGA was able to outperform state of the art
GAs across many benchmarks. Since its first proposal, many variants of LTGA have been
proposed~\citep{goldman:2012:ltga} so for clarity we have chosen the version
presented by \cite{thierens:2013:ltgahiff} as our model. This variant was chosen as it is
modern and appears to approach the consensus in the literature.

LTGA's effectiveness comes from its method of performing crossover. Instead of blindly
mixing genes between parents, LTGA attempts to preserve important interrelationships
between genes. Before performing any crossovers in a generation, LTGA first builds
a set of hierarchical gene clusters which are then used to dictate how genes are mixed
during crossover.

\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{Cluster-Creation}{}
    \State $unmerged \leftarrow \{\{0\}, \{1\}, \{2\}, \dots, \{N-1\}\}$
    \State $useful \leftarrow unmerged$
    \While{$|unmerged|>1$}
      \State $C_i, C_j \leftarrow \min_{C_i,C_j \in unmerged} D(C_i, C_j)$
      \State $unmerged \leftarrow unmerged - \{C_i, C_j\} + \{C_i \cup C_j\}$
      \State $useful \leftarrow useful + \{C_i \cup C_j\}$
      \If{$D(C_i, C_j) = 0$}
        \State $useful \leftarrow useful - \{C_i, C_j\}$
      \EndIf
    \EndWhile
    \State Order $useful$ based based on last merged first\label{fig-cluster-creation-ordering}
    \State Remove largest cluster from $useful$

    \Return $useful$
  \EndProcedure
\end{algorithmic}
  \caption{Algorithm describing how LTGA creates clusters using Equation~\ref{eq-distance}
           for a population. $unmerged$ and $useful$ are ordered sets of sets of gene loci.}
  \label{fig-cluster-creation}
\end{figure}

Figure~\ref{fig-cluster-creation} provides the agglomerative method LTGA uses to create gene clusters.
This algorithm will create a tree of sets, such that the leaves of the tree contain a single gene and
nodes are the union of their children's sets. These sets are then used by crossover to specify epistatic
relationships which should be preserved.
The process begins by creating the set of sets $unmerged$ which tracks all top level clusters. Initially
$unmerged$ contains single member sets for each gene. After each iteration the two sets with the minimum average pairwise
distance (given in Equation~\ref{eq-distance}) are merged to create a single cluster. This process is repeated
until only a single set remains in $unmerged$ which contains all of the genes in the genome.

\begin{equation}
  D(C_i,C_j) = \frac{1}{\left | C_i \right |\cdot \left |C_j \right|}\sum_{c_i \in C_i}\sum_{c_j \in C_j}
  2 - \frac{H(c_i) + H(c_j)}{H(c_i \cup c_j)}
  \label{eq-distance}
\end{equation}
\begin{equation}
  H(c) = -\sum_{s\in S} p_c(s)\log(p_c(s))
  \label{eq-entropy}
\end{equation}

Throughout this process $useful$ tracks the set of all gene clusters which should be preserved for use by crossover.
This set begins with all genes in separate clusters, and each time a new cluster is created it is added to $useful$.
However, not all clusters are necessarily worth keeping. For instance, in all versions of LTGA the cluster
containing all genes is removed from $useful$ as preserving all genes during crossover can only create clones.
\cite{thierens:2013:ltgahiff} extended this removal to include any unsupported subsets. If the pairwise distance
between two clusters is 0, this means there are no individuals in the population which disrupt the relationships between the two
clusters. Therefore when performing crossover there is no reason to believe a fitness improvement can be achieved
by breaking the stored pattern. As such a cluster is only kept if its direct superset has a non-zero distance.

\cite{thierens:2013:ltgahiff}'s version of LTGA does not use the entire population when determining pairwise entropy.
Instead, binary tournament is used to select half of the population. This is done to ensure the model is built
using only high quality solutions, even during the first generation.

In order to efficiently perform clustering, a pairwise gene frequency table is constructed.
Equation~\ref{eq-entropy} uses how frequently each of the four possible string values for each
pair of genes occurs in the selected solutions. Extracting this information requires $O(\mu N^2)$
time, where $\mu$ is the population size and $N$ is the genome size. The process of converting
this pairwise frequency information into clusters can be achieved in $O(N^2)$ using the bookkeeping
methods presented by \cite{gronau:2007:upgma}. This cost is performed only once per generation,
and is then used to perform approximately $O(\mu N)$ crossover evaluations. As a result, the amortized cost of
LTGA's model building is $O(N)$.

\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{Cluster-Usage}{}
    \ForAll{$C_i \in useful$}
      %\ForAll{$d \in shuffled(P_i)$}
        \State $d \leftarrow rand\_choice(P)$\label{fig-cluster-usage-donate}
        \State Copy $d$'s gene values for $C_i$ into solution
        \If{solution was changed}
          \If{solution's fitness decreased}
            \State Revert changes
          \EndIf
          %\State \textbf{break}
        \EndIf
      %\EndFor
    \EndFor
  \EndProcedure
\end{algorithmic}
  \caption{Algorithm describing how clusters are used to perform crossover.}
  \label{fig-cluster-usage}
\end{figure}

Figure~\ref{fig-cluster-usage} describes how the identified clusters are used by crossover to preserve
gene linkage while still exploring the search space. Unlike more traditional crossover methods, LTGA
crosses each individual with the entire population. Also, to produce a single offspring, multiple evaluations
of the fitness function are performed.

Each generation, each individual in the population undergoes crossover. In a single crossover event, each
cluster of genes $C_i$ in $useful$ is applied in last merged first order as a crossover mask. A random donor $d$
is chosen from the entire population (not just the model selected population), and $d$'s gene's for $C_i$ are copied
into the working solution. If a modification is made, an evaluation is then performed. If the crossover
resulted in no worse fitness then the changes are kept. This allows for neutral drift across plateaus.
The resulting solution, which must be at least as fit as its parent, is then
copied into the next generation.


In total each individual can cause up to $|useful|$ evaluations. If all clusters were kept, even those deemed
unhelpful, and all donations were evaluated, even those which did not change any genes, then \Call{Cluster-Usage}{}
would perform exactly $2N-2$ evaluations for each of the $\mu$ solutions in the population. This provides the amortizing evaluations
required to make clustering only $O(N)$ operations per evaluation. However, by skipping some evaluations, its
possible that clustering may be super-linear.

LTGA has no explicit form of diversity control and has no method for introducing new genetic information once
the population has converged. Therefore an LTGA run is considered converged once two consecutive populations
contain the same unique solutions.

By design, LTGA only has a single parameter: population size. LTGA uses no mutation, and crossover is defined
in terms of the clustering algorithm. Selection between generations is fully elitist and embedded in the crossover,
with selection of model building solutions fixed to a binary tournament. Neither \Call{Cluster-Creation}{} nor
\Call{Cluster-Usage}{} rely on parameter values. LTGA does not provide any method for controlling or setting
the population size, and uses a fixed user specified size for each generation.

\section{Parameter-less Population Pyramid}
\cite{goldman:2014:p3} introduced the Parameter-less Population Pyramid (P3) as a method for
performing optimization which does not require the user to provide any parameters. This is
achieved by combining efficient local search with the model building methods of LTGA using
an iteratively constructed hierarchy of populations.

The high level algorithm of P3 is presented in Figure~\ref{fig-p3}. Unlike more traditional
GAs, P3 does not follow a generational model. Instead, it maintains an iteratively
expanding pyramid of expanding populations. Each iteration, a new random solution is generated.
This solution is brought to a local optimum using the hill climbing algorithm in Figure~\ref{fig-hc}. If that
local optimum has not yet been added to the pyramid, the solution is added to the lowest
population $P_0$.

Next, the solution is iteratively improved by applying LTGA's crossover algorithm (Figure~\ref{fig-cluster-usage})
with each population $P_i$ in the pyramid. If this process results in a strict fitness improvement and has
created a solution not yet stored in the pyramid, it is added to the next highest pyramid level $P_{i+1}$.
If $P_{i+1}$ does not yet exist, it is created. In this way populations in the pyramid expand over time,
and the number of populations stored increases over time. Initially the pyramid contains no solutions
or populations, meaning the user does not need to specify a population size.


\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{Iterate-P3}{}
    \State Create random solution
    \State Apply hill climber
    \If{solution $\notin hashset$}
      \State Add solution to $P_0$
      \State Add solution to $hashset$
    \EndIf

    \ForAll{$P_i \in pyramid$}
      \State Mix solution with $P_i$
      \If{solution's fitness has improved}
        \If{solution $\notin hashset$}
          \State Add solution to $P_{i+1}$
          \State Add solution to $hashset$
        \EndIf
      \EndIf
    \EndFor
  \EndProcedure
\end{algorithmic}
  \caption{One iteration of P3 optimization. $pyramid$ is an
           ordered set of populations and $hashset$ is a set
           of all solutions in $pyramid$.}
  \label{fig-p3}
\end{figure}

To accommodate P3's unique population structure, some of LTGA's clustering procedures were adapted. In LTGA,
clusters are identified at the start of each generation, with those clusters used
to create all solutions produced in that generation. As P3 does not perform serial
generations, this process had to be modified. Instead, P3 updates the model each
time a solution is added to a population. Furthermore, unlike
LTGA all solutions in the population are used to generate the model, not just the
winners of a binary tournament. This selection process is not necessary as the
worst solutions in the pyramid are already high quality due to local search.
Using local search in LTGA was examined by \cite{bosman:2011:lsbbo} and found
to provide no significant improvement. A likely cause was that that study applied
local search to every solution, not just the initial population, resulting in significant overhead.

Beyond the changes in population structuring, P3 also has slight modifications to
LTGA's version of \Call{Cluster-Creation}{} and \Call{Cluster-Usage}{}.
P3 changes Line~\ref{fig-cluster-creation-ordering} in Figure~\ref{fig-cluster-creation}
from \emph{last merged first} ordering to \emph{smallest first} ordering.
This method applies gene clusters during crossover based on how many genes
are in each cluster\footnote{Ties are broken randomly.}, and not on how tightly linked those genes are.
\cite{goldman:2012:ltga} found that this alternative was better at preserving
diversity, and therefore required smaller populations, but has  not been integrated into
our chosen canonical LTGA variant.

P3 also modified Line~\ref{fig-cluster-usage-donate} in Figure~\ref{fig-cluster-usage}.
Instead of choosing a single genetic donor for each cluster, P3 iterates over the
population in a random order until a solution in the population is found which
has a least one gene different for that cluster of genes from the improving solution.
This process increases the likelihood of an evaluation being performed for every cluster,
and helps test rare gene patterns in the population.

In LTGA the cost of rebuilding the model is $O(\mu N^2)$ as it must collect pairwise
gene frequency information for all $\mu$ solutions in the population. P3 does not store
a single population, and it does not have a fixed $\mu$ size for any population. However,
each time a solution is added to the population, it requires $O(N^2)$ time to update
the table of pairwise frequencies and another $O(N^2)$ time to rebuild the linkage model.
The model is then used immediately to perform up to one evaluation for each of the up
to $2N-2$ clusters. Just as in LTGA, if no evaluation shortcuts were made, P3
has an amortized cost of $O(N)$ modeling cost per evaluation. While P3 does
rebuild the model more frequently per solution in the population, it also performs
a number of local search evaluations which are quite efficient, meaning theoretical
comparisons of their speed are difficult to perform. As a final note, P3's repeated
attempts to find a useful donation make it less likely than LTGA to skip evaluations,
but has an added cost to find these donations. Repeated donations could require as much
as $O(\mu)$ attempts per evaluation, but experimental evidence suggest that this
operation actually saves more overhead than it costs by increasing the number of evaluations
per model rebuild.

Each of the pieces of the P3 algorithm were selected not just for their stand alone efficacy,
but for the ways in which they interact. By using the hill climber to ensure each solution
is at a local optima, the underlying pairwise relationships in the problem are exposed. As
a result, detecting clusters for use by crossover is much more effective. The crossover operator
is extremely elitist, as each gene donation must result in no fitness loss, and a solution must
strictly improve to be added to the next level of the pyramid. This is balanced by continual
integration of new random solutions. Furthermore, each random restart decreases the probability
of spurious linkages caused by shared ancestry. This diversity is further preserved by applying
gene clusters in smallest first order during crossover as this reduces the probability of genetic
hitchhikers.

Other algorithms have proposed using multiple concurrent populations.
\cite{hornby:2006:alps} had a hierarchy of populations with solutions periodically advancing
upward. This allows for continuous integration of diversity as the lowest population is reseeded
with random solutions. However, this method resulted in increased parameterization as not only was
a population size required, parameters for how frequently generations advanced between levels and
how many total levels to have were added. \cite{harik:1999:parameterlessga} used multiple independent
populations of different sizes as a method for removing the population size parameter, but
doing was provably less efficient than using an optimal population size as no information is shared
between the populations.

\section{Problem Descriptions}
\label{sec-problems}

\subsection{Single Instance Problems}
Understanding how a stochastic search algorithm will behave on arbitrary and complex
search landscapes can be exceedingly difficult. Therefore a common practice for
algorithm understanding is to perform search on well defined, well understood
landscapes. To be of interest these landscapes need to represent interesting
and important aspects of real world problems.

Perhaps the most common such landscape is the Deceptive Trap problem \citep{goldberg:1991:gasize}.
In this landscape the genome is broken up into $k$ bit non-overlapping subproblems referred
to as traps.
Each subproblem is scored using Equation~\ref{eq-deceptive-trap}, where $t$ is the number of
bits in the trap set to 1. To global optimum in each trap is a string of all 1s, while all
other solutions lead to a local optima of all 0s. As a result this problem tests an algorithm's
ability to overcome $k$ sized deception and is commonly used to determine how effective crossover
is at preserving building blocks. Any crossover event that mixes bits from different parents in
the same trap will likely result in that trap being optimized to the local optima. For our experiments
we chose $k=7$ to ensure highly deceptive traps.

\begin{equation}
   trap(t) = \left\{
     \begin{array}{rl}
       k-1-t, &  t<k\\
       k,   &  t = k
     \end{array}
   \right.
  \label{eq-deceptive-trap}
\end{equation}

\cite{goldman:2012:ltga} found that mixing local search with linkage learning rendered the Deceptive
Trap problem trivial. This is because local search is able to optimize each trap to one of the two
optima (all 1s or all 0s), and then linkage learning can have perfect knowledge of gene interactions.
In order to make the problem more difficult yet still deceptive, the authors proposed the Deceptive
Step Trap problem, given in Equation~\ref{eq-deceptive-step-trap}. This function modifies the results
of Equation~\ref{eq-deceptive-trap} to include plateaus of size $s$, introducing an exponential number
of local optima in each trap. As a result the Deceptive Step Trap is much more challenging for linkage
learning techniques, while still being highly deceptive. We chose to use $s=2$ to create the maximum
number of local optima.
\begin{equation}
   step\_trap(t) = \left \lfloor \frac{(k-s)\pmod{s} + trap(t)}{s} \right \rfloor
  \label{eq-deceptive-step-trap}
\end{equation}

Another challenging aspect of landscapes can be higher order relationships. The Hierarchical If
and only If (HIFF) problem is designed to capture the difficulties of this class of problem.
In HIFF the genome is broken up into a complete binary tree, such that each gene appears in exactly one
leaf and each internal node is the subset of genes contained in its children. If all genes represented
in a node of the tree are set to the same value, they score equal to the size of the set. In this way
small subsets lead toward solutions to larger subsets. However a node can score if all genes are either
all 1s or all 0s, meaning that to solve higher order subproblems it is necessary to perform crossovers
that preserve lower order solutions. This problem is a natural fit for LTGA as the linkage tree can
perfectly duplicate the problem's true relationships \citep{thierens:2013:ltgahiff}.

As a final class of well known problems, we have chosen to borrow the Rastrigin problem from real valued
optimization. This problem's landscape, determined by Equation~\ref{eq-rast}, is highly multimodal caused by
the oscillating cosine function. \cite{goldman:2014:p3} proposed the Discretized Rastrigin problem, such
that each floating point $x_i$ in Equation~\ref{eq-rast} is encoded using a 10 bit gray code.
\begin{equation}
  An + \sum_{i=1}^{n}\left [ x_i^2-A\cos (2\pi x_i) \right ] \forall x\in [-5.12,5.12]
  \label{eq-rast}
\end{equation}

\subsection{Randomly Generated Problem Classes}
While well defined landscapes can provide specific insights into how an algorithm works,
their static nature can create misleading results. Specifically algorithm quality might
be very fragile such that it is only effective at searching well behaved landscapes. A more realistic
test of an algorithm's black box effectiveness is to work with randomly generated instances
drawn from a problem class. When tested over a sufficiently large sample it is then possible
to draw more general conclusions about the algorithms effectiveness. The challenge with these
landscapes is determining the global optimum to know if an algorithm was successful.

Perhaps the most common model for generating random rugged landscapes is the NK model. An
NK Landscape determines the fitness of each gene based on epistatic relationships with $K$
other genes in the genome. This fitness is specified using a randomly generated table of
fitness values, were each possible combination of the $K+1$ genes is mapped to some floating
point value $[0-1]$. In unrestricted NK landscapes the relationships between genes are also
randomly chosen and as a result finding the global optimum is $NP$-Hard for $K>1$. However,
if epistasis is instead set such that each gene depends on the $K$ directly following it
in the genome the solution can be found in polynomial time~\citep{wright:2000:solvingnk}.
These Nearest Neighbor NK landscapes are therefore ideal for search algorithm testing.
For all of our experiments we fixed $K=5$ to ensure highly rugged landscapes.

\cite{saul:1994:spinglass} presents a combinatorial benchmark problem derived from physics:
Ising Spin Glasses. A spin glass is defined by interaction terms between variables with
the genome encoding the sign for each variable and a goal to minimize the total interaction value.
Similar to NK Landscapes the general class is $NP$-Hard to optimize, but the $2D\pm J$ subset of
Ising Spin Glasses can be polynomially solved.\footnote{\url{http://www.informatik.uni-koeln.de/spinglass/}}

As our final class of randomly generated problems we chose the Maximum Satisfiability (MAX-SAT) problem.
Related to the more common 3-SAT problem, a MAX-SAT instance is defined by a set of three term clauses.
Each term is a randomly chosen variable, which may also be negated. A clause scores if an and only if
at least one term in the clause evaluates to true. In order to make MAX-SAT instances with a known global
optimum \cite{goldman:2014:p3} proposed constructing clauses around a fixed solution. In this way the
signs of the terms are set to ensure the target solution satisfies the clause. To ensure each
problem is challenging chose a clause to variable ratio of $4.27$.

\section{Comparison Algorithm Parameter Tuning}
\label{sec-tuning}
While four of the six algorithms in our experiments do not require any user specified parameters,
hBOA and LTGA both use a population size parameter. To ensure these techniques are not unfairly
handicapped, we have extensively tuned each using the bisection method \citep{sastry:2001:bisection}
to determine the optimal population size for each size of each problem.
Extended by \cite{goldman:2012:ltga} this method iteratively
doubles the population size until some success criteria is met and then performs bisection
between the lowest successful and highest unsuccessful sizes. Thus the minimum population size
which meets the success criteria is found. \cite{goldman:2014:p3} proposed a success criteria
of performing $r$ successful runs in a row, such that the expected failure rate can be bounded
above by $\frac{3}{r+1}$~\citep{jovanovic:1997:ruleofthree}. As P3 and the other three algorithms
do not prematurely converge, we chose $r=100$ to similarly ensure hBOA and LTGA almost never do.

\section{Global Optimum}
\label{sec-optimum}

\begin{figure}[t]
  \begin{center}
  \includegraphicsfit{evals-to-success}
  \end{center}
  \caption{Comparison of the median number of evaluations to reach the global optimum for
           the six different optimization methods with respect
           to problem size.  If the median run did not reach the global optimum no data element
           is shown.  Results given on a log-log scale.}
  \label{fig-evals-to-success}
\end{figure}

TODO Compare all 6 optimization techniques on evaluations to reach global optimum.  Figure~\ref{fig-evals-to-success}.


\begin{table}
	\centering
	\begin{tabular}{|c|r|r|r|r|r|r|r|r|}
	  \cline{2-9}
	  \multicolumn{1}{c|}{} & \multicolumn{2}{L|}{Deceptive Trap} & \multicolumn{2}{L|}{Deceptive Step Trap}
	                        & \multicolumn{2}{L|}{HIFF} & \multicolumn{2}{L|}{Rastrigin} \\ \cline{2-9}
	  \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{a} & \multicolumn{1}{c|}{b}
	                        & \multicolumn{1}{c|}{a} & \multicolumn{1}{c|}{b}
	                        & \multicolumn{1}{c|}{a} & \multicolumn{1}{c|}{b}
	                        & \multicolumn{1}{c|}{a} & \multicolumn{1}{c|}{b} \\ \hline
	                          % DT                    % DST                    % HIFF                  % Rast
	  {Hill Climber}          &$<$0.00 &        11.10 &$<$0.00 &        10.60 &$<$0.00 &         9.45 &$<$0.00 &         5.50 \\ \hline
	  {$1+(\lambda,\lambda)$} &   0.02 &         3.66 &$<$0.00 &         6.69 &$<$0.00 &         6.55 &$<$0.00 &         4.50 \\ \hline
	  {hBOA}                  &  18.16 &         2.28 &  40.38 &         2.07 &   4.60 &         1.82 &   3.50 &         2.29 \\ \hline
	  {Parameter-less hBOA}   &  16.92 &         2.72 &  28.71 &         2.59 &   4.94 &         2.25 &   3.55 &         2.61 \\ \hline
	  {LTGA}                  & 324.88 & \textbf{1.28}& 165.27 &         1.72 &   7.02 &         1.66 &  21.05 & \textbf{1.43}\\ \hline
	  {P3}                    &  68.80 &         1.38 & 354.69 & \textbf{1.56}&   4.06 & \textbf{1.59}&   5.29 &         1.59 \\ \hline
  \end{tabular}
	\caption{Results of fitting $y=ax^b$ model where $y$ is evaluations to success
	         and $x$ is problem size. Bold entries are the statistically lowest growth rates.}
	\label{table-bigo}
\end{table}

TODO Table listing empirical $O(N)$ times for each technique on each problem. Include
statistical comparison of log-log regression lines.

\begin{figure}[t]
  \begin{center}
  \includegraphicsfit{evals-to-success-range}
  \end{center}
  \caption{Comparison of the upper and lower quartiles of evaluations required
           to reach the global optimum for P3 and LTGA with respect to problem size.}
  \label{fig-evals-to-success-range}
\end{figure}

TODO Graphic showing quartiles to illustrate P3's scaling on problems. Figure~\ref{fig-evals-to-success-range}.

\section{Stop Anytime}
\begin{figure}[t]
  \begin{center}
  \includegraphicsfit{fitness-over-time}
  \end{center}
  \caption{Compares the median best fitness reached during search for each of the six optimization methods.}
  \label{fig-fitness-over-time}
\end{figure}

TODO Compare all 6 optimization techniques on fitnesses reached at different times
during the run on problem sizes. Explain results same for different sizes. Figure~\ref{fig-fitness-over-time}.

TODO Include graphic for one problem where LTGA was tuned using a significantly higher failure rate.

\begin{figure}[t]
  \begin{centering}
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{rebuilds}
      \end{centering}
      \caption{Rebuilds}
      \label{fig-rebuilds}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{donations}
      \end{centering}
      \caption{Donations}
      \label{fig-donations}
    \end{subfigure}
  \end{centering}
  \caption{Computation costs incurred by model rebuilding (Figure~\ref{fig-rebuilds}) and
           repeated donations (Figure~\ref{fig-donations}) per evaluation as problem size increases.}
\end{figure}

TODO Include graphic of rebuilds per evaluation. Figure~\ref{fig-rebuilds}.

TODO Include graphic of donations per evaluation. Figure~\ref{fig-donations}.

TODO Include a table of $O(N)$ seconds per evaluation and total seconds for all 4 model building techniques on all 7 problems.

\section{Inner Workings}

\begin{figure}[t]
  \begin{centering}
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{cross}
      \end{centering}
      \caption{Crossover Proportion}
      \label{fig-cross}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{cross-success}
      \end{centering}
      \caption{Crossover Success}
      \label{fig-cross-success}
    \end{subfigure}
  \end{centering}
  \caption{For each problem Figure~\ref{fig-cross} shows the proportion of P3 evaluations spend on crossovers
           and Figure~\ref{fig-cross-success} shows the percentage of fitness improving crossover evaluations.}
\end{figure}

TODO Include graphic of proportion of evaluations spent on crossover. Figure~\ref{fig-cross}.

TODO Include graphic of crossover success Figure~\ref{fig-cross-success}.

\begin{figure}[t]
  \begin{centering}
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{level-size}
      \end{centering}
      \caption{Population Size}
      \label{fig-level-size}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{level-success}
      \end{centering}
      \caption{Crossover Success}
      \label{fig-level-success}
    \end{subfigure}
  \end{centering}
  \caption{For each problem Figure~\ref{fig-level-size} shows the number of solutions stored in each level of the pyramid
           and Figure~\ref{fig-level-success} shows the percentage of fitness improving crossover evaluations at each level.}
\end{figure}

TODO Include graphic of pyramid shape (Figure~\ref{fig-level-size}) and crossover success rates (Figure~\ref{fig-level-success}) at each level.

~\cite{lobo:2011:dynamicpop}

~\cite{goldman:2011:dynamic-parameters}

\section{Conclusions and Future Work}

\small

\bibliographystyle{apalike}
\bibliography{../main}


\end{document}

\documentclass[twoside]{article}
\usepackage{ecj,palatino,epsfig,latexsym,natbib}
\usepackage{url}
\usepackage{verbatim}
\usepackage{subcaption}
\usepackage[noend]{algpseudocode}

\newcommand{\includegraphicswide}[1]
{\includegraphics[width=.9\textwidth,height=\textheight,keepaspectratio]{#1}}

\newcommand{\includegraphicsfit}[1]
{\includegraphics[width=\columnwidth,height=\textheight,keepaspectratio]{#1}}

%% do not add any other page- or text-size instruction here

\parskip=0.00in

\begin{document}

\ecjHeader{x}{x}{xxx-xxx}{200X}{TODO 45-character paper description}{B. W. Goldman and W. F. Punch}
\title{\bf Fast and Efficient Black Box Optimization using the Parameter-less Population Pyramid}  

\author{\name{\bf B. W. Goldman} \hfill \addr{brianwgoldman@acm.org}\\ 
        \addr{Department of Computer Science and Engineering, Michigan State University, 
        East Lansing, 48823, United States}
\AND
       \name{\bf W. F. Punch} \hfill \addr{punch@msu.edu}\\
        \addr{Department of Computer Science and Engineering, Michigan State University, 
        East Lansing, 48823, United States}
}

\maketitle

\begin{abstract}

TODO About 200 words.

\end{abstract}

\begin{keywords}

Genetic algorithms, 
linkage learning,
local search,
parameter-less.

\end{keywords}

\section{Introduction}
A primary purpose of evolutionary optimization is to efficiently find good solutions
to challenging real world problems with minimal prior knowledge about the problem itself.
This driving goal has created search algorithms which can escape user bias to create
truly novel results, sometimes publishable or patentable in their own right~\citep{kannappan:2014:humies}.
While it is not possible for any algorithm to do better than random across all possible
problems~\citep{Wolpert:1997:nfl}, effectiveness can be achieved by assuming the search
landscape has structure and then biasing the algorithm toward exploiting those features.

In evolutionary optimization, and genetic algorithms~(GAs) in particular, search is often
biased through parameters. This is beneficial as it allows practitioners to inject their
knowledge about the shape of the search landscape into the algorithm. However, it can require
expert knowledge to leverage this feature to its fullest potential or require exceedingly expensive
parameter tuning~\citep{grefenstette:1986:optimalga}. Furthermore, the quality of solutions found,
and the speed at which they are found, in GAs is strongly tied to setting these parameters
correctly~\citep{goldberg:1991:gasize}. Parameters such as population size, mutation rate, crossover
rate, tournament size, etc can have no clear relationship to the problem being solved, meaning even
domain experts may not understand how they will interact with the problem or each other.

As such there has been periodic efforts to reduce or remove the need for parameter tuning.
\cite{Back:1992:selfadapt} introduced self-adaptive parameters, where parameter values
were included in each solution's genome and underwent evolution. This allowed search
to optimize some of its own parameters and therefore reduced the need for expert tuning.
\cite{harik:1999:parameterlessga} was able to design an entirely parameter-less GA by
designing control strategies which made on line modifications to each parameter based
on how well search was progressing. Unfortunately these methods were provably less efficient
than correctly setting the parameters by up to a logarithmic
factor~\citep{pelikan:1999:worstparameter-less}.

One area that has been very effective at reducing the number of algorithm parameters has been
model based search. \cite{pelikan:2006:hboa}'s Hierarchical Bayesian Optimization
Algorithm~(hBOA) and \cite{thierens:2010:ltga}'s Linkage Tree Genetic Algorithm~(LTGA)
both only require a single parameter: population size. \cite{posik:2011:parameterless}
leveraged these methods to create a fully parameter-less algorithm which was restricted
only to order-k fully decomposable noiseless problems.

Most recently \cite{goldman:2014:p3} introduced the Parameter-less Population Pyramid~(P3).
This method combines model based search with a local search operator using a pyramid structure
of populations to achieve parameter-less optimization. Initial results suggest that unlike
previous parameter-less methods, P3 is actually more efficient than current state-of-the-art
parameterized search algorithms. In this work we shall extend these results to cover more
comparison algorithms, results on both efficiency in reaching the global optimum and intermediate
fitnesses, algorithm complexity analysis, and provide more in depth analysis of P3 itself.
\begin{comment}
Section~\ref{sec-optimizers}
explains how each of these algorithms, including P3, perform search. Section~\ref{sec-problems}
provides a description of each test problem. As hBOA and LTGA require a population size parameter
Section~\ref{sec-tuning} provides our methodology to ensure each is optimally tuned to each problem.
\end{comment}

\section{Optimizers}
\label{sec-optimizers}

\subsection{Hill Climber}
Perhaps the simplest black box search heuristic is stochastic local search, or hill climbing.
This optimization technique focuses on improving a single solution until it reaches a local
optimum. Here we use the first improvement hill climber defined by \cite{goldman:2014:p3}
and given in Figure~\ref{fig-hc}. This algorithm works by flipping each bit in a random
order, keeping modifications when fitness is improved, until doing so cannot result in
further fitness improvements.

The hill climber requires $O(1)$ operations per evaluation amortized cost. In order to
terminate, it must perform at least $N$ evaluations, where $N$ is the number of bits
in the solution, in order to ensure no single bit flip can result in a fitness improvement.
As such any operation that happens only once per search can be amortized over at least $N$
evaluations, covering the initialization of $options$.

Assuming proper hashing data structures, determining if $index \notin tried$ should require only $O(1)$
time. While this operation may be called without a directly related evaluation, amortized cost
provides an upper bound. Consider that in order to add an $index$ into $tried$ an evaluation must
be performed. Lets say this evaluation pays for two checks of that $index$, one of which was used
during this loop. If no fitness improving move is found, the next time through the loop the second check
is used. A third check is only necessary if no fitness improving move was found for any index.
This is a contradiction as the loop terminates when no improving move was found. Therefore this check
can only be called twice per evaluation.



\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{Hill-Climber}{}
    \State $options \leftarrow [0 \dots N-1]$
    \State $tried \leftarrow \emptyset$
    \While{$|tried| < |options|$}
      \ForAll{$index \in shuffled(options)$}
        \If{$index \notin tried$}
          \State Flip bit $index$ in solution
          \If{solution's fitness increased}
            \State $tried \leftarrow \emptyset$
          \Else
            \State Revert change
          \EndIf
          \State $tried \leftarrow tried \cup \{index\}$
        \EndIf
      \EndFor
    \EndWhile
  \EndProcedure
\end{algorithmic}
  \caption{Hill climbing algorithm used to improve randomly generated solutions until no single
           bit change results in a fitness improvement.}
  \label{fig-hc}
\end{figure}



\subsection{Linkage Tree Genetic Algorithm}
~\cite{thierens:2010:ltga} introduced the Linkage Tree Genetic Algorithm (LTGA) which automatically
detects and exploits problem epistasis by examining pairwise gene entropy. Due to its enhanced
ability to preserve high fitness gene subsets, LTGA was able to outperform state of the art
GAs across many benchmarks. Since its first proposal, many variants of LTGA have been
proposed~\citep{goldman:2012:ltga}. Therefore for clarity we have chosen the version
presented by \cite{thierens:2013:ltgahiff} as our model for comparison as it is both
modern and appears to approach the consensus in the literature.

LTGA's effectiveness comes from its method of performing crossover. Instead of blindly
mixing genes between parents, LTGA attempts to preserve important interrelationships
between genes. Before performing any crossovers in a generation, LTGA first builds
a set of hierarchical gene clusters which are then used to dictate how genes are mixed
during crossover.

\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{Cluster-Creation}{}
    \State $unmerged \leftarrow \{\{0\}, \{1\}, \{2\}, \dots, \{N-1\}\}$
    \State $useful \leftarrow unmerged$
    \While{$|unmerged|>1$}
      \State $C_i, C_j \leftarrow \min_{C_i,C_j \in unmerged} D(C_i, C_j)$
      \State $unmerged \leftarrow unmerged - \{C_i, C_j\} + \{C_i \cup C_j\}$
      \State $useful \leftarrow useful + \{C_i \cup C_j\}$
      \If{$D(C_i, C_j) = 0$}
        \State $useful \leftarrow useful - \{C_i, C_j\}$
      \EndIf
    \EndWhile
    \State Order $useful$ based based on last merged first\label{fig-cluster-creation-ordering}
    \State Remove largest cluster from $useful$

    \Return $useful$
  \EndProcedure
\end{algorithmic}
  \caption{Algorithm describing how LTGA creates clusters using Equation~\ref{eq-distance}
           for a population. $unmerged$ and $useful$ are ordered sets of sets of gene loci.}
  \label{fig-cluster-creation}
\end{figure}

Figure~\ref{fig-cluster-creation} provides the agglomerative method LTGA uses to create gene clusters.
This algorithm will create a tree of sets, such that the leaves of the tree contain a single gene and
nodes are the union of their children's sets. These sets are then used by crossover to specify epistatic
relationships which should be preserved.
The process begins by creating the set of sets $unmerged$ which tracks all top level clusters. Initially
$unmerged$ contains single member sets for each gene. Each iteration the two sets with the minimum pairwise
distance (given in Equation~\ref{eq-distance}) are merged to create a single cluster. This process is repeated
until only a single set remains in $unmerged$ which contains all of the genes in the genome.

\begin{equation}
  D(C_i,C_j) = \frac{1}{\left | C_i \right |\cdot \left |C_j \right|}\sum_{c_i \in C_i}\sum_{c_j \in C_j}
  2 - \frac{H(c_i) + H(c_j)}{H(c_i \cup c_j)}
  \label{eq-distance}
\end{equation}
\begin{equation}
  H(c) = -\sum_{s\in S} p_c(s)\log(p_c(s))
  \label{eq-entropy}
\end{equation}

Throughout this process $useful$ tracks the set of all gene clusters which should be preserved for use by crossover.
This set begins with all genes in separate clusters, and each time a new cluster is created it is added to $useful$.
However, not all clusters are necessarily worth keeping. For instance, in all versions of LTGA the cluster
containing all genes is removed from $useful$ as preserving all genes during crossover can only create clones.
\cite{thierens:2013:ltgahiff} extended this removal to include any unsupported subsets. If the pairwise distance
between two clusters is 0, this means there are no individuals in the population which disrupt the values stored in
each cluster. Therefore when performing crossover there is no reason to believe a fitness improvement can be achieved
by breaking the stored pattern. As such only clusters who's direct superset has non-zero distance are kept.

\cite{thierens:2013:ltgahiff}'s version of LTGA does not use the entire population when determining pairwise entropy.
Instead, binary tournament use used to select half of the population. This is done to ensure the model is built
using only high quality solutions, even during the first generation.

In order to efficiently perform clustering, a pairwise gene frequency table is constructed.
Equation~\ref{eq-entropy} uses how frequently each of the four possible string values for each
pair of genes occurs in the selected solutions. Extracting this information requires $O(\mu N^2)$
time, where $\mu$ is the population size and $N$ is the genome size. The process of converting
this pairwise frequency information into clusters can be achieved in $O(N^2)$ using the bookkeeping
methods presented by \cite{gronau:2007:upgma}. This cost is performed only once per generation,
and is then used to perform approximately $O(\mu N)$ crossover evaluations. As a result, the amortized cost of
LTGA's model building is $O(N)$.

\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{Cluster-Usage}{}
    \ForAll{$C_i \in useful$}
      %\ForAll{$d \in shuffled(P_i)$}
        \State $d \leftarrow rand\_choice(P)$\label{fig-cluster-usage-donate}
        \State Copy $d$'s gene values for $C_i$ into solution
        \If{solution was changed}
          \If{solution's fitness decreased}
            \State Revert changes
          \EndIf
          %\State \textbf{break}
        \EndIf
      %\EndFor
    \EndFor
  \EndProcedure
\end{algorithmic}
  \caption{Algorithm describing how clusters are used to perform crossover.}
  \label{fig-cluster-usage}
\end{figure}

Figure~\ref{fig-cluster-usage} describes how the identified clusters are used by crossover to preserve
gene linkage while still exploring the search space. Unlike more traditional crossover methods, LTGA
crosses each individual with the entire population. Also, to produce a single offspring, multiple evaluations
of the fitness function are performed.

Each generation, each individual in the population undergoes crossover. In a single crossover event, each
cluster of genes $C_i$ in $useful$ is applied in last merged first order as a crossover mask. A random donor $d$
is chosen from the entire population (not just the model selected population), and $d$'s gene's for $C_i$ are copied
into the working solution. If a modification is made, an evaluation is then performed. If the crossover
resulted in no worse fitness than the changes are kept. This allows for neutral drift across plateaus.
The resulting solution, which must be at least as fit as its parent, is then
copied into the next generation.


In total each individual can cause up to $|useful|$ evaluations. If all clusters were kept, even those deemed
unhelpful, and all donations were evaluated, even those which did not change any genes, then \Call{Cluster-Usage}{}
would perform exactly $2N-2$ evaluations for each of the $\mu$ in the population. This provides the amortizing evaluations
required to make clustering only $O(N)$ operations per evaluation. However, but skipping some evaluations, its
possible that clustering may be super-linear.

~\cite{bosman:2011:lsbbo} % LTGA with hill climbing

\subsection{P3}
Figure~\ref{fig-p3}.
\begin{figure}
  \begin{algorithmic}[1]
  \Procedure{Iterate-P3}{}
    \State Create random solution
    \State Apply hill climber
    \If{solution $\notin hashset$}
      \State Add solution to $P_0$
      \State Add solution to $hashset$
    \EndIf

    \ForAll{$P_i \in pyramid$}
      \State Mix solution with $P_i$
      \If{solution's fitness has improved}
        \If{solution $\notin hashset$}
          \State Add solution to $P_{i+1}$
          \State Add solution to $hashset$
        \EndIf
      \EndIf
    \EndFor
  \EndProcedure
\end{algorithmic}
  \caption{One iteration of P3 optimization. $pyramid$ is an
           ordered set of populations and $hashset$ is a set
           of all solutions in $pyramid$.}
  \label{fig-p3}
\end{figure}

~\cite{goldman:2014:p3}

Figure~\ref{fig-cluster-creation} Line~\ref{fig-cluster-creation-ordering}.

Figure~\ref{fig-cluster-usage} Line~\ref{fig-cluster-usage-donate}.

~\cite{hornby:2006:alps}

\subsection{hBOA}

~\cite{pelikan:2006:hboa}

\subsection{Parameter-less hBOA}
~\cite{pelikan:2004:parameterlesshboa}

\subsection{$1+(\lambda, \lambda)$}
\cite{doerr:2013:lambdalambda} was the first genetic algorithm to provably show
the advantages of performing crossover on simple landscapes. This comparatively simple
algorithm maintains only a single individual and a self-controlled parameter $\lambda$.

Each iteration, a number of bits to flip is chosen from the binomial distribution $b\sim B(N, \frac{\lambda}{N})$.
Next, $\lfloor\lambda\rfloor$ offspring are produced by flipping $b$ bits. The
best mutant then produces $\lambda$ offspring via uniform crossover with the original parent, such that each gene comes from the
mutant with probability $\frac{1}{\lambda}$. In the original algorithm the best
offspring produced by crossover then replaces the original parent if its fitness is no worse.
The $\lambda$ parameter, which is initialized to 1, is decreased if the offspring replaced
its parent and decreased otherwise.

The original formulation was designed specifically for unimodal landscapes and as such were
not directly suitable for multimodal problems. \cite{goldman:2014:p3} extended the $1+(\lambda, \lambda)$
to include random restarts. As search stagnates, the $\lambda$ parameter increases in value. Eventually
this results in $\lambda \ge N$. This results in mutation flipping all bits of the individual, preventing
useful exploration. Therefore whenever $\lambda \ge N$, search is restarted from a random solution with $\lambda$
reset to 1.

A few other efficiency modifications were also made. If there is a tie in crossover offspring fitness,
whichever has a larger hamming distance from the parent is retained. This encourages drifting across plateaus.
The ``mod'' control strategy proposed by \cite{doerr:2013:lambdalambda} was not used as it conflicted with
the random restart strategy.
If a crossover individual is identical to either of its parents, it is not evaluated.
If mutation produces an offspring which is better than the best crossover offspring, it is used to compare
against the original parent.

\section{Problem Descriptions}
\label{sec-problems}

\subsection{Single Instance Problems}
~\cite{goldberg:1991:gasize} % Deceptive Trap

~\cite{goldman:2012:ltga} % Deceptive Step Trap

~\cite{thierens:2013:ltgahiff} % HIFF

~\cite{goldman:2014:p3} % Rastrigin

\subsection{Randomly Generated Problem Classes}

~\cite{wright:2000:solvingnk}

~\cite{saul:1994:spinglass}
\footnote{\url{http://www.informatik.uni-koeln.de/spinglass/}}

~\cite{goldman:2014:p3} % MAXSAT

\section{Comparison Algorithm Parameter Tuning}
\label{sec-tuning}

~\cite{goldman:2012:ltga} % Bisection with no parameters

~\cite{goldman:2014:p3}

~\cite{jovanovic:1997:ruleofthree}

\section{Global Optimum}
\label{sec-optimum}

\begin{figure}[t]
  \begin{center}
  \includegraphicsfit{evals-to-success}
  \end{center}
  \caption{Comparison of the median number of evaluations to reach the global optimum for
           the six different optimization methods with respect
           to problem size.  If the median run did not reach the global optimum no data element
           is shown.  Results given on a log-log scale.}
  \label{fig-evals-to-success}
\end{figure}

TODO Compare all 6 optimization techniques on evaluations to reach global optimum.  Figure~\ref{fig-evals-to-success}.

TODO Table listing empirical $O(N)$ times for each technique on each problem. Include
statistical comparison of log-log regression lines.

\begin{figure}[t]
  \begin{center}
  \includegraphicsfit{evals-to-success-range}
  \end{center}
  \caption{Comparison of the upper and lower quartiles of evaluations required
           to reach the global optimum for P3 and LTGA with respect to problem size.}
  \label{fig-evals-to-success-range}
\end{figure}

TODO Graphic showing quartiles to illustrate P3's scaling on problems. Figure~\ref{fig-evals-to-success-range}.

\section{Stop Anytime}
\begin{figure}[t]
  \begin{center}
  \includegraphicsfit{fitness-over-time}
  \end{center}
  \caption{Compares the median best fitness reached during search for each of the six optimization methods.}
  \label{fig-fitness-over-time}
\end{figure}

TODO Compare all 6 optimization techniques on fitnesses reached at different times
during the run on problem sizes. Explain results same for different sizes. Figure~\ref{fig-fitness-over-time}.

TODO Include graphic for one problem where LTGA was tuned using a significantly higher failure rate.

\begin{figure}[t]
  \begin{centering}
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{rebuilds}
      \end{centering}
      \caption{Rebuilds}
      \label{fig-rebuilds}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{donations}
      \end{centering}
      \caption{Donations}
      \label{fig-donations}
    \end{subfigure}
  \end{centering}
  \caption{Computation costs incurred by model rebuilding (Figure~\ref{fig-rebuilds}) and
           repeated donations (Figure~\ref{fig-donations}) per evaluation as problem size increases.}
\end{figure}

TODO Include graphic of rebuilds per evaluation. Figure~\ref{fig-rebuilds}.

TODO Include graphic of donations per evaluation. Figure~\ref{fig-donations}.

TODO Include a table of $O(N)$ seconds per evaluation and total seconds for all 4 model building techniques on all 7 problems.

\section{Inner Workings}

\begin{figure}[t]
  \begin{centering}
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{cross}
      \end{centering}
      \caption{Crossover Proportion}
      \label{fig-cross}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{cross-success}
      \end{centering}
      \caption{Crossover Success}
      \label{fig-cross-success}
    \end{subfigure}
  \end{centering}
  \caption{For each problem Figure~\ref{fig-cross} shows the proportion of P3 evaluations spend on crossovers
           and Figure~\ref{fig-cross-success} shows the percentage of fitness improving crossover evaluations.}
\end{figure}

TODO Include graphic of proportion of evaluations spent on crossover. Figure~\ref{fig-cross}.

TODO Include graphic of crossover success Figure~\ref{fig-cross-success}.

\begin{figure}[t]
  \begin{centering}
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{level-size}
      \end{centering}
      \caption{Population Size}
      \label{fig-level-size}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
      \begin{centering}
        \includegraphicsfit{level-success}
      \end{centering}
      \caption{Crossover Success}
      \label{fig-level-success}
    \end{subfigure}
  \end{centering}
  \caption{For each problem Figure~\ref{fig-level-size} shows the number of solutions stored in each level of the pyramid
           and Figure~\ref{fig-level-success} shows the percentage of fitness improving crossover evaluations at each level.}
\end{figure}

TODO Include graphic of pyramid shape (Figure~\ref{fig-level-size}) and crossover success rates (Figure~\ref{fig-level-success}) at each level.

~\cite{lobo:2011:dynamicpop}

~\cite{goldman:2011:dynamic-parameters}

\section{Conclusions and Future Work}

\small

\bibliographystyle{apalike}
\bibliography{../main}


\end{document}
